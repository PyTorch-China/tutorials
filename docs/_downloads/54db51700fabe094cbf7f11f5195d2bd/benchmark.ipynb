{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# PyTorch Benchmark\n\u672c\u6559\u7a0b\u63d0\u4f9b\u4e86\u4f7f\u7528 PyTorch ``benchmark`` \u6a21\u5757\u6765\u6d4b\u91cf\u548c\u6bd4\u8f83\u4ee3\u7801\u6027\u80fd\u7684\u5feb\u901f\u5165\u95e8\u6307\u5357\u3002\n\n## \u4ecb\u7ecd\n\u57fa\u51c6\u6d4b\u8bd5\u662f\u7f16\u5199\u4ee3\u7801\u65f6\u7684\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4\u3002\u5b83\u5e2e\u52a9\u6211\u4eec\u9a8c\u8bc1\u4ee3\u7801\u662f\u5426\u6ee1\u8db3\u6027\u80fd\u9884\u671f,\u6bd4\u8f83\u89e3\u51b3\u540c\u4e00\u95ee\u9898\u7684\u4e0d\u540c\u65b9\u6cd5,\u5e76\u9632\u6b62\u6027\u80fd\u88c2\u5316\u3002\n\n\u5bf9\u4e8e\u57fa\u51c6\u6d4b\u8bd5 PyTorch \u4ee3\u7801\u6709\u8bb8\u591a\u9009\u62e9,\u5305\u62ec Python \u5185\u7f6e\u7684 ``timeit`` \u6a21\u5757\u3002\n\u7136\u800c,\u57fa\u51c6\u6d4b\u8bd5 PyTorch \u4ee3\u7801\u6709\u8bb8\u591a\u5bb9\u6613\u88ab\u5ffd\u89c6\u7684\u6ce8\u610f\u4e8b\u9879,\u4f8b\u5982\u7ba1\u7406\u7ebf\u7a0b\u6570\u91cf\u548c\u540c\u6b65 CUDA \u8bbe\u5907\u3002\n\u6b64\u5916,\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u751f\u6210\u5f20\u91cf\u8f93\u5165\u53ef\u80fd\u76f8\u5f53\u7e41\u7410\u3002\n\n\u672c\u6559\u7a0b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 PyTorch ``benchmark`` \u6a21\u5757\u6765\u907f\u514d\u5e38\u89c1\u9519\u8bef,\u540c\u65f6\u66f4\u5bb9\u6613\u6bd4\u8f83\u4e0d\u540c\u4ee3\u7801\u7684\u6027\u80fd\u3001\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u751f\u6210\u8f93\u5165\u7b49\u3002\n\n## \u8bbe\u7f6e\n\u5728\u5f00\u59cb\u4e4b\u524d,\u5982\u679c\u5c1a\u672a\u5b89\u88c5 ``torch``,\u8bf7\u5148\u5b89\u88c5\u3002\n\n::\n\n   pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5177\u4f53\u6b65\u9aa4\n\n1. \u5b9a\u4e49\u8981\u57fa\u51c6\u6d4b\u8bd5\u7684\u51fd\u6570\n2. \u4f7f\u7528 ``timeit.Timer`` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\n3. \u4f7f\u7528 ``torch.utils.benchmark.Timer`` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\n4. \u4f7f\u7528 ``Blocked Autorange`` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\n5. \u6bd4\u8f83\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\n6. \u4fdd\u5b58/\u52a0\u8f7d\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\n7. \u4f7f\u7528 ``Fuzzed Parameters`` \u751f\u6210\u8f93\u5165\n8. \u4f7f\u7528 ``Callgrind`` \u6536\u96c6\u6307\u4ee4\u8ba1\u6570\n\n### 1. \u5b9a\u4e49\u8981\u57fa\u51c6\u6d4b\u8bd5\u7684\u51fd\u6570\n\n\u5728\u64b0\u5199\u672c\u6587\u65f6, [torch.dot](https://pytorch.org/docs/stable/generated/torch.dot.html?highlight=dot#torch.dot)_\n\u4e0d\u652f\u6301\u6279\u91cf\u6a21\u5f0f,\u56e0\u6b64\u6211\u4eec\u5c06\u6bd4\u8f83\u4f7f\u7528\u73b0\u6709 ``torch`` \u8fd0\u7b97\u7b26\u5b9e\u73b0\u5b83\u7684\u4e24\u79cd\u65b9\u6cd5:\u4e00\u79cd\u65b9\u6cd5\u4f7f\u7528 ``mul`` \u548c ``sum`` \u7684\u7ec4\u5408,\u53e6\u4e00\u79cd\u65b9\u6cd5\u4f7f\u7528 ``bmm``\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\n\ndef batched_dot_mul_sum(a, b):\n    \"\"\"Computes batched dot by multiplying and summing\"\"\"\n    return a.mul(b).sum(-1)\n\n\ndef batched_dot_bmm(a, b):\n    \"\"\"Computes batched dot by reducing to ``bmm``\"\"\"\n    a = a.reshape(-1, 1, a.shape[-1])\n    b = b.reshape(-1, b.shape[-1], 1)\n    return torch.bmm(a, b).flatten(-3)\n\n\n# Input for benchmarking\nx = torch.randn(10000, 64)\n\n# Ensure that both functions compute the same output\nassert batched_dot_mul_sum(x, x).allclose(batched_dot_bmm(x, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. \u4f7f\u7528 ``timeit.Timer`` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\n\u9996\u5148,\u8ba9\u6211\u4eec\u4f7f\u7528 Python \u5185\u7f6e\u7684 ``timeit`` \u6a21\u5757\u5bf9\u4ee3\u7801\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\n\u6211\u4eec\u5728\u8fd9\u91cc\u4fdd\u6301\u57fa\u51c6\u6d4b\u8bd5\u4ee3\u7801\u7b80\u5355,\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u6bd4\u8f83 ``timeit`` \u548c ``torch.utils.benchmark`` \u7684\u9ed8\u8ba4\u8bbe\u7f6e\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import timeit\n\nt0 = timeit.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"from __main__ import batched_dot_mul_sum\",\n    globals={\"x\": x},\n)\n\nt1 = timeit.Timer(\n    stmt=\"batched_dot_bmm(x, x)\",\n    setup=\"from __main__ import batched_dot_bmm\",\n    globals={\"x\": x},\n)\n\nprint(f\"mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us\")\nprint(f\"bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    mul_sum(x, x):  111.6 us\n    bmm(x, x):       70.0 us\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. \u4f7f\u7528 ``torch.utils.benchmark.Timer`` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\nPyTorch ``benchmark``\u6a21\u5757\u7684\u8bbe\u8ba1\u4f7f\u5f97\u5bf9\u4e8e\u90a3\u4e9b\u66fe\u7ecf\u4f7f\u7528\u8fc7 ``timeit`` \u6a21\u5757\u7684\u4eba\u6765\u8bf4,\u5b83\u770b\u8d77\u6765\u5f88\u719f\u6089\u3002\n\u7136\u800c,\u5b83\u7684\u9ed8\u8ba4\u8bbe\u7f6e\u4f7f\u5f97\u5b83\u66f4\u5bb9\u6613\u4e14\u66f4\u5b89\u5168\u5730\u7528\u4e8e\u5bf9 PyTorch \u4ee3\u7801\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\n\u9996\u5148\u8ba9\u6211\u4eec\u5bf9\u6bd4\u4e00\u4e0b\u57fa\u672cAPI\u7684\u4f7f\u7528\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.utils.benchmark as benchmark\n\nt0 = benchmark.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"from __main__ import batched_dot_mul_sum\",\n    globals={\"x\": x},\n)\n\nt1 = benchmark.Timer(\n    stmt=\"batched_dot_bmm(x, x)\",\n    setup=\"from __main__ import batched_dot_bmm\",\n    globals={\"x\": x},\n)\n\nprint(t0.timeit(100))\nprint(t1.timeit(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb10400d0f0>\n    batched_dot_mul_sum(x, x)\n    setup: from __main__ import batched_dot_mul_sum\n      379.29 us\n      1 measurement, 100 runs , 1 thread\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb103d67048>\n    batched_dot_bmm(x, x)\n    setup: from __main__ import batched_dot_bmm\n      716.42 us\n      1 measurement, 100 runs , 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u867d\u7136\u57fa\u672c\u529f\u80fd\u7684API\u662f\u76f8\u540c\u7684,\u4f46\u662f\u8fd8\u662f\u6709\u4e00\u4e9b\u91cd\u8981\u7684\u533a\u522b\u3002\n``benchmark.Timer.timeit()``\u8fd4\u56de\u7684\u662f\u6bcf\u6b21\u8fd0\u884c\u7684\u65f6\u95f4,\u800c\u4e0d\u662f ``timeit.Timer.timeit()`` \u8fd4\u56de\u7684\u603b\u8fd0\u884c\u65f6\u95f4\u3002\nPyTorch ``benchmark``\u6a21\u5757\u8fd8\u63d0\u4f9b\u4e86\u683c\u5f0f\u5316\u7684\u5b57\u7b26\u4e32\u8868\u793a,\u7528\u4e8e\u6253\u5370\u7ed3\u679c\u3002\n\n\u53e6\u4e00\u4e2a\u91cd\u8981\u7684\u533a\u522b,\u4e5f\u662f\u7ed3\u679c\u4e0d\u540c\u7684\u539f\u56e0,\u662fPyTorch\u57fa\u51c6\u6d4b\u8bd5\u6a21\u5757\u9ed8\u8ba4\u5728\u5355\u7ebf\u7a0b\u4e2d\u8fd0\u884c\u3002\n\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528``num_threads``\u53c2\u6570\u6765\u66f4\u6539\u7ebf\u7a0b\u6570\u91cf\u3002\n\n``torch.utils.benchmark.Timer``\u63a5\u53d7\u51e0\u4e2a\u989d\u5916\u7684\u53c2\u6570,\u5305\u62ec: ``label``\u3001``sub_label``\u3001``description``\u548c``env``,\n\u8fd9\u4e9b\u53c2\u6570\u4f1a\u6539\u53d8\u8fd4\u56de\u7684\u6d4b\u91cf\u5bf9\u8c61\u7684__repr__,\u5e76\u7528\u4e8e\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u7ec4(\u7a0d\u540e\u4f1a\u8be6\u7ec6\u4ecb\u7ecd)\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_threads = torch.get_num_threads()\nprint(f\"Benchmarking on {num_threads} threads\")\n\nt0 = benchmark.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"from __main__ import batched_dot_mul_sum\",\n    globals={\"x\": x},\n    num_threads=num_threads,\n    label=\"Multithreaded batch dot\",\n    sub_label=\"Implemented using mul and sum\",\n)\n\nt1 = benchmark.Timer(\n    stmt=\"batched_dot_bmm(x, x)\",\n    setup=\"from __main__ import batched_dot_bmm\",\n    globals={\"x\": x},\n    num_threads=num_threads,\n    label=\"Multithreaded batch dot\",\n    sub_label=\"Implemented using bmm\",\n)\n\nprint(t0.timeit(100))\nprint(t1.timeit(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    Benchmarking on 40 threads\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb103d54080>\n    Multithreaded batch dot: Implemented using mul and sum\n    setup: from __main__ import batched_dot_mul_sum\n      118.47 us\n      1 measurement, 100 runs , 40 threads\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb16935d2e8>\n    Multithreaded batch dot: Implemented using bmm\n    setup: from __main__ import batched_dot_bmm\n      68.21 us\n      1 measurement, 100 runs , 40 threads\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f7f\u7528\u6240\u6709\u53ef\u7528\u7ebf\u7a0b\u8fd0\u884c ``benchmark`` \u4f1a\u5f97\u5230\u4e0e ``timeit`` \u6a21\u5757\u7c7b\u4f3c\u7684\u7ed3\u679c\u3002\n\u66f4\u91cd\u8981\u7684\u662f,\u54ea\u4e2a\u7248\u672c\u66f4\u5feb\u53d6\u51b3\u4e8e\u6211\u4eec\u4f7f\u7528\u591a\u5c11\u7ebf\u7a0b\u8fd0\u884c\u4ee3\u7801\u3002\n\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u5728\u57fa\u51c6\u6d4b\u8bd5\u65f6,\u4f7f\u7528\u4e0e\u5b9e\u9645\u7528\u4f8b\u76f8\u7b26\u7684\u7ebf\u7a0b\u8bbe\u7f6e\u975e\u5e38\u91cd\u8981\u3002\n\u53e6\u4e00\u4e2a\u9700\u8981\u8bb0\u4f4f\u7684\u91cd\u8981\u4e8b\u60c5\u662f,\u5728 GPU \u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u65f6,\u8981\u540c\u6b65CPU\u548cCUDA\u3002\n\u8ba9\u6211\u4eec\u518d\u6b21\u5728CUDA\u5f20\u91cf\u4e0a\u8fd0\u884c\u4e0a\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5,\u770b\u770b\u4f1a\u53d1\u751f\u4ec0\u4e48\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.randn(10000, 1024, device=\"cuda\")\n\nt0 = timeit.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"from __main__ import batched_dot_mul_sum\",\n    globals={\"x\": x},\n)\n\nt1 = timeit.Timer(\n    stmt=\"batched_dot_bmm(x, x)\",\n    setup=\"from __main__ import batched_dot_bmm\",\n    globals={\"x\": x},\n)\n\n# Ran each twice to show difference before/after warm-up\nprint(f\"mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us\")\nprint(f\"mul_sum(x, x):  {t0.timeit(100) / 100 * 1e6:>5.1f} us\")\nprint(f\"bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us\")\nprint(f\"bmm(x, x):      {t1.timeit(100) / 100 * 1e6:>5.1f} us\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    mul_sum(x, x):   27.6 us\n    mul_sum(x, x):   25.3 us\n    bmm(x, x):      2775.5 us\n    bmm(x, x):       22.4 us\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t0 = benchmark.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"from __main__ import batched_dot_mul_sum\",\n    globals={\"x\": x},\n)\n\nt1 = benchmark.Timer(\n    stmt=\"batched_dot_bmm(x, x)\",\n    setup=\"from __main__ import batched_dot_bmm\",\n    globals={\"x\": x},\n)\n\n# Run only once since benchmark module does warm-up for us\nprint(t0.timeit(100))\nprint(t1.timeit(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb10400d080>\n    batched_dot_mul_sum(x, x)\n    setup: from __main__ import batched_dot_mul_sum\n      232.93 us\n      1 measurement, 100 runs , 1 thread\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb10400d0f0>\n    batched_dot_bmm(x, x)\n    setup: from __main__ import batched_dot_bmm\n      181.04 us\n      1 measurement, 100 runs , 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7ed3\u679c\u63ed\u793a\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u4e8b\u60c5\u3002\u4f7f\u7528 `timeit` \u6a21\u5757\u8fd0\u884c `bmm` \u7248\u672c\u7684\u7b2c\u4e00\u6b21\u8fd0\u884c\u6bd4\u7b2c\u4e8c\u6b21\u8fd0\u884c\u6162\u5f88\u591a\u3002\n\u8fd9\u662f\u56e0\u4e3a `bmm` \u9700\u8981\u8c03\u7528 `cuBLAS`,\u7b2c\u4e00\u6b21\u8c03\u7528\u65f6\u9700\u8981\u52a0\u8f7d\u5b83,\u8fd9\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\u3002\n\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e4b\u524d\u505a\u4e00\u6b21\u9884\u70ed\u8fd0\u884c\u5f88\u91cd\u8981,\u5e78\u8fd0\u7684\u662f, PyTorch \u7684 `benchmark` \u6a21\u5757\u4e3a\u6211\u4eec\u5904\u7406\u4e86\u8fd9\u4e2a\u95ee\u9898\u3002\n\n`timeit` \u6a21\u5757\u548c `benchmark` \u6a21\u5757\u4e4b\u95f4\u7ed3\u679c\u7684\u5dee\u5f02\u662f\u56e0\u4e3a `timeit` \u6a21\u5757\u6ca1\u6709\u540c\u6b65 CUDA,\u56e0\u6b64\u53ea\u8ba1\u65f6\u4e86\u542f\u52a8\u5185\u6838\u7684\u65f6\u95f4\u3002\nPyTorch \u7684 `benchmark` \u6a21\u5757\u4e3a\u6211\u4eec\u505a\u4e86\u540c\u6b65\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. \u4f7f\u7528 `Blocked Autorange` \u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\n\n\u867d\u7136 `timeit.Timer.autorange` \u91c7\u53d6\u81f3\u5c11 0.2 \u79d2\u7684\u5355\u6b21\u8fde\u7eed\u6d4b\u91cf,\n\u4f46 `torch.utils.benchmark.blocked_autorange` \u91c7\u53d6\u591a\u6b21\u6d4b\u91cf,\u5176\u603b\u65f6\u95f4\u81f3\u5c11\u4e3a 0.2 \u79d2(\u53ef\u901a\u8fc7 `min_run_time` \u53c2\u6570\u66f4\u6539),\n\u5e76\u4e14\u6d4b\u91cf\u5f00\u9500\u53ea\u5360\u603b\u4f53\u6d4b\u91cf\u7684\u4e00\u5c0f\u90e8\u5206\u3002\n\u8fd9\u662f\u901a\u8fc7\u9996\u5148\u4ee5\u9012\u589e\u7684\u5faa\u73af\u6b21\u6570\u8fd0\u884c,\u76f4\u5230\u8fd0\u884c\u65f6\u95f4\u8fdc\u5927\u4e8e\u6d4b\u91cf\u5f00\u9500(\u8fd9\u4e5f\u8d77\u5230\u4e86\u70ed\u8eab\u7684\u4f5c\u7528),\n\u7136\u540e\u8fdb\u884c\u6d4b\u91cf\u76f4\u5230\u8fbe\u5230\u76ee\u6807\u65f6\u95f4\u3002\u8fd9\u6709\u4e00\u4e2a\u6709\u7528\u7684\u7279\u6027,\u5373\u5b83\u6d6a\u8d39\u7684\u6570\u636e\u66f4\u5c11,\u5e76\u4e14\u5141\u8bb8\u6211\u4eec\u8ba1\u7b97\u7edf\u8ba1\u6570\u636e\u6765\u4f30\u8ba1\u6d4b\u91cf\u7684\u53ef\u9760\u6027\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m0 = t0.blocked_autorange()\nm1 = t1.blocked_autorange()\n\nprint(m0)\nprint(m1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb10400d0f0>\n    batched_dot_mul_sum(x, x)\n    setup: from __main__ import batched_dot_mul_sum\n      231.79 us\n      1 measurement, 1000 runs , 1 thread\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb10400d080>\n    batched_dot_bmm(x, x)\n    setup: from __main__ import batched_dot_bmm\n      Median: 162.08 us\n      2 measurements, 1000 runs per measurement, 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u8fd8\u53ef\u4ee5\u67e5\u770b\u8fd4\u56de\u7684\u6d4b\u91cf\u5bf9\u8c61\u4e2d\u83b7\u5f97\u7684\u5404\u4e2a\u7edf\u8ba1\u6570\u636e\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Mean:   {m0.mean * 1e6:6.2f} us\")\nprint(f\"Median: {m0.median * 1e6:6.2f} us\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    Mean:   231.79 us\n    Median: 231.79 us\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. \u6bd4\u8f83\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\n\n\u5230\u76ee\u524d\u4e3a\u6b62,\u6211\u4eec\u4e00\u76f4\u5728\u6bd4\u8f83\u6211\u4eec\u7684\u4e24\u4e2a\u6279\u91cf\u70b9\u79ef\u7248\u672c\u5bf9\u540c\u4e00\u8f93\u5165\u7684\u8868\u73b0\u3002\n\u5728\u5b9e\u8df5\u4e2d,\u6211\u4eec\u5e0c\u671b\u5c1d\u8bd5\u4e0d\u540c\u7684\u8f93\u5165\u7ec4\u5408\u4ee5\u53ca\u4e0d\u540c\u7684\u7ebf\u7a0b\u6570\u91cf\u3002\n`Compare` \u7c7b\u5e2e\u52a9\u6211\u4eec\u4ee5\u683c\u5f0f\u5316\u8868\u683c\u7684\u5f62\u5f0f\u663e\u793a\u591a\u4e2a\u6d4b\u91cf\u7ed3\u679c\u3002\n\u5b83\u4f7f\u7528\u4e0a\u9762\u63cf\u8ff0\u7684\u6ce8\u91ca( `label`\u3001 `sub_label`\u3001 `num_threads` \u7b49)\u4ee5\u53ca `description` \u6765\u5bf9\u8868\u683c\u8fdb\u884c\u5206\u7ec4\u548c\u7ec4\u7ec7\u3002\n\u8ba9\u6211\u4eec\u4f7f\u7528 `Compare` \u6765\u770b\u770b\u6211\u4eec\u7684\u51fd\u6570\u5728\u4e0d\u540c\u7684\u8f93\u5165\u5927\u5c0f\u548c\u7ebf\u7a0b\u6570\u91cf\u4e0b\u7684\u8868\u73b0\u5982\u4f55\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from itertools import product\n\n# Compare takes a list of measurements which we'll save in results.\nresults = []\n\nsizes = [1, 64, 1024, 10000]\nfor b, n in product(sizes, sizes):\n    # label and sub_label are the rows\n    # description is the column\n    label = \"Batched dot\"\n    sub_label = f\"[{b}, {n}]\"\n    x = torch.ones((b, n))\n    for num_threads in [1, 4, 16, 32]:\n        results.append(\n            benchmark.Timer(\n                stmt=\"batched_dot_mul_sum(x, x)\",\n                setup=\"from __main__ import batched_dot_mul_sum\",\n                globals={\"x\": x},\n                num_threads=num_threads,\n                label=label,\n                sub_label=sub_label,\n                description=\"mul/sum\",\n            ).blocked_autorange(min_run_time=1)\n        )\n        results.append(\n            benchmark.Timer(\n                stmt=\"batched_dot_bmm(x, x)\",\n                setup=\"from __main__ import batched_dot_bmm\",\n                globals={\"x\": x},\n                num_threads=num_threads,\n                label=label,\n                sub_label=sub_label,\n                description=\"bmm\",\n            ).blocked_autorange(min_run_time=1)\n        )\n\ncompare = benchmark.Compare(results)\ncompare.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    [--------------- Batched dot ----------------]\n                          |  mul/sum   |    bmm\n    1 threads: -----------------------------------\n          [1, 1]          |       5.9  |      11.2\n          [1, 64]         |       6.4  |      11.4\n          [1, 1024]       |       6.7  |      14.2\n          [1, 10000]      |      10.2  |      23.7\n          [64, 1]         |       6.3  |      11.5\n          [64, 64]        |       8.6  |      15.4\n          [64, 1024]      |      39.4  |     204.4\n          [64, 10000]     |     274.9  |     748.5\n          [1024, 1]       |       7.7  |      17.8\n          [1024, 64]      |      40.3  |      76.4\n          [1024, 1024]    |     432.4  |    2795.9\n          [1024, 10000]   |   22657.3  |   11899.5\n          [10000, 1]      |      16.9  |      74.8\n          [10000, 64]     |     300.3  |     609.4\n          [10000, 1024]   |   23098.6  |   27246.1\n          [10000, 10000]  |  267073.7  |  118823.7\n    4 threads: -----------------------------------\n          [1, 1]          |       6.0  |      11.5\n          [1, 64]         |       6.2  |      11.2\n          [1, 1024]       |       6.8  |      14.3\n          [1, 10000]      |      10.2  |      23.7\n          [64, 1]         |       6.3  |      16.2\n          [64, 64]        |       8.8  |      18.2\n          [64, 1024]      |      41.5  |     189.1\n          [64, 10000]     |      91.7  |     849.1\n          [1024, 1]       |       7.6  |      17.4\n          [1024, 64]      |      43.5  |      33.5\n          [1024, 1024]    |     135.4  |    2782.3\n          [1024, 10000]   |    7471.1  |   11874.0\n          [10000, 1]      |      16.8  |      33.9\n          [10000, 64]     |     118.7  |     173.2\n          [10000, 1024]   |    7264.6  |   27824.7\n          [10000, 10000]  |  100060.9  |  121499.0\n    16 threads: ----------------------------------\n          [1, 1]          |       6.0  |      11.3\n          [1, 64]         |       6.2  |      11.2\n          [1, 1024]       |       6.9  |      14.2\n          [1, 10000]      |      10.3  |      23.8\n          [64, 1]         |       6.4  |      24.1\n          [64, 64]        |       9.0  |      23.8\n          [64, 1024]      |      54.1  |     188.5\n          [64, 10000]     |      49.9  |     748.0\n          [1024, 1]       |       7.6  |      23.4\n          [1024, 64]      |      55.5  |      28.2\n          [1024, 1024]    |      66.9  |    2773.9\n          [1024, 10000]   |    6111.5  |   12833.7\n          [10000, 1]      |      16.9  |      27.5\n          [10000, 64]     |      59.5  |      73.7\n          [10000, 1024]   |    6295.9  |   27062.0\n          [10000, 10000]  |   71804.5  |  120365.8\n    32 threads: ----------------------------------\n          [1, 1]          |       5.9  |      11.3\n          [1, 64]         |       6.2  |      11.3\n          [1, 1024]       |       6.7  |      14.2\n          [1, 10000]      |      10.5  |      23.8\n          [64, 1]         |       6.3  |      31.7\n          [64, 64]        |       9.1  |      30.4\n          [64, 1024]      |      72.0  |     190.4\n          [64, 10000]     |     103.1  |     746.9\n          [1024, 1]       |       7.6  |      28.4\n          [1024, 64]      |      70.5  |      31.9\n          [1024, 1024]    |      65.6  |    2804.6\n          [1024, 10000]   |    6764.0  |   11871.4\n          [10000, 1]      |      17.8  |      31.8\n          [10000, 64]     |     110.3  |      56.0\n          [10000, 1024]   |    6640.2  |   27592.2\n          [10000, 10000]  |   73003.4  |  120083.2\n\n    Times are in microseconds (us).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e0a\u9762\u7684\u7ed3\u679c\u8868\u660e,\u5bf9\u4e8e\u5728\u591a\u7ebf\u7a0b\u4e0a\u8fd0\u884c\u7684\u8f83\u5927\u5f20\u91cf, `bmm` \u7684\u7248\u672c\u6548\u679c\u66f4\u597d,\n\u800c\u5bf9\u4e8e\u8f83\u5c0f\u548c/\u6216\u5355\u7ebf\u7a0b\u4ee3\u7801,\u53e6\u4e00\u4e2a\u7248\u672c\u6548\u679c\u66f4\u597d\u3002\n\n`Compare` \u8fd8\u63d0\u4f9b\u4e86\u7528\u4e8e\u66f4\u6539\u8868\u683c\u683c\u5f0f\u7684\u51fd\u6570\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "compare.trim_significant_figures()\ncompare.colorize()\ncompare.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. \u4fdd\u5b58/\u52a0\u8f7d\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\n\n`Measurements` (\u548c\u7b2c8\u8282\u4e2d\u63cf\u8ff0\u7684 `CallgrindStats` )\u53ef\u4ee5\u901a\u8fc7 `pickle` \u6a21\u5757\u5e8f\u5217\u5316\u3002\n\u8fd9\u4f7f\u5f97A/B\u6d4b\u8bd5\u53d8\u5f97\u5f88\u5bb9\u6613,\u56e0\u4e3a\u60a8\u53ef\u4ee5\u4ece\u4e24\u4e2a\u72ec\u7acb\u7684\u73af\u5883\u4e2d\u6536\u96c6\u6d4b\u91cf\u7ed3\u679c,\n\u5c06\u5b83\u4eec\u5e8f\u5217\u5316,\u7136\u540e\u5728\u5355\u4e2a\u73af\u5883\u4e2d\u52a0\u8f7d\u4e24\u8005\u3002Timer\u751a\u81f3\u63a5\u53d7\u4e00\u4e2a `env`\n\u6784\u9020\u51fd\u6570\u53c2\u6570,\u4ee5\u4fbf\u8fd9\u79cdA/B\u6d4b\u8bd5\u53ef\u4ee5\u65e0\u7f1d\u8854\u63a5\u3002\n\n\u5047\u8bbe add/sum \u548c `bmm` \u65b9\u6cd5\u4e0d\u662f\u4e24\u4e2aPython\u51fd\u6570,\u800c\u662f PyTorch \u7684\u4e24\u4e2a\u4e0d\u540c\u7248\u672c\u3002\n\u4e0b\u9762\u7684\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u8fdb\u884cA/B\u6d4b\u8bd5\u3002\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1,\u6211\u4eec\u53ea\u4f7f\u7528\u4e86\u4e00\u90e8\u5206\u6570\u636e,\n\u5e76\u7b80\u5355\u5730\u901a\u8fc7pickle\u6765\u56de\u4f20\u7ed3\u679c,\u800c\u4e0d\u662f\u5b9e\u9645\u4f7f\u7528\u591a\u4e2a\u73af\u5883\u5e76\u5c06\u7ed3\u679c\u5199\u5165\u78c1\u76d8\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pickle\n\nab_test_results = []\nfor env in (\"environment A: mul/sum\", \"environment B: bmm\"):\n    for b, n in ((1, 1), (1024, 10000), (10000, 1)):\n        x = torch.ones((b, n))\n        dot_fn = (\n            batched_dot_mul_sum if env == \"environment A: mul/sum\" else batched_dot_bmm\n        )\n        m = benchmark.Timer(\n            stmt=\"batched_dot(x, x)\",\n            globals={\"x\": x, \"batched_dot\": dot_fn},\n            num_threads=1,\n            label=\"Batched dot\",\n            description=f\"[{b}, {n}]\",\n            env=env,\n        ).blocked_autorange(min_run_time=1)\n        ab_test_results.append(pickle.dumps(m))\n\nab_results = [pickle.loads(i) for i in ab_test_results]\ncompare = benchmark.Compare(ab_results)\ncompare.trim_significant_figures()\ncompare.colorize()\ncompare.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    [------------------------------------- Batched dot -------------------------------------]\n                                                   |  [1, 1]  |  [1024, 10000]  |  [10000, 1]\n    1 threads: ------------------------------------------------------------------------------\n      (environment A: mul/sum)  batched_dot(x, x)  |     7    |      36000      |      21\n      (environment B: bmm)      batched_dot(x, x)  |    14    |      40000      |      85\n\n    Times are in microseconds (us).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u4ec5\u4e3a\u5c55\u793a\u53ef\u4ee5\u5c06\u4e4b\u524d\u6240\u6709\u7684\u7ed3\u679c\u901a\u8fc7 pickle \u8fdb\u884c\u56de\u4f20:\nround_tripped_results = pickle.loads(pickle.dumps(results))\nassert str(benchmark.Compare(results)) == str(benchmark.Compare(round_tripped_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. \u4f7f\u7528 `Fuzzed Parameters` \u751f\u6210\u8f93\u5165\n\n\u6b63\u5982\u6211\u4eec\u5728\u4e0a\u4e00\u8282\u4e2d\u770b\u5230\u7684,\u6839\u636e\u8f93\u5165\u5f20\u91cf\u7684\u4e0d\u540c,\u6027\u80fd\u5dee\u5f02\u53ef\u80fd\u4f1a\u5f88\u5927\u3002\n\u56e0\u6b64,\u5728\u591a\u4e2a\u4e0d\u540c\u7684\u8f93\u5165\u4e0a\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u662f\u4e00\u4e2a\u597d\u4e3b\u610f\u3002\n\u4f46\u662f,\u521b\u5efa\u6240\u6709\u8fd9\u4e9b\u8f93\u5165\u5f20\u91cf\u53ef\u80fd\u4f1a\u5f88\u9ebb\u70e6,\u8fd9\u5c31\u662f `torch.utils.benchmark.Fuzzer`\n\u548c\u76f8\u5173\u7c7b\u7684\u7528\u6b66\u4e4b\u5730\u3002\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u4f7f\u7528 `Fuzzer` \u6765\u521b\u5efa\u4e00\u4e9b\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark import FuzzedParameter, FuzzedTensor, Fuzzer, ParameterAlias\n\n# \u751f\u6210\u968f\u673a\u5f20\u91cf,\u5143\u7d20\u6570\u91cf\u5728 128 \u5230 10000000 \u4e4b\u95f4,\u5927\u5c0f k0 \u548c k1 \u4ece [1, 10000] \u7684 `loguniform` \u5206\u5e03\u4e2d\u9009\u62e9,\n# \u5176\u4e2d\u5e73\u5747 40% \u5c06\u662f\u4e0d\u8fde\u7eed\u7684\u3002\nexample_fuzzer = Fuzzer(\n    parameters=[\n        FuzzedParameter(\"k0\", minval=1, maxval=10000, distribution=\"loguniform\"),\n        FuzzedParameter(\"k1\", minval=1, maxval=10000, distribution=\"loguniform\"),\n    ],\n    tensors=[\n        FuzzedTensor(\n            \"x\",\n            size=(\"k0\", \"k1\"),\n            min_elements=128,\n            max_elements=10000000,\n            probability_contiguous=0.6,\n        )\n    ],\n    seed=0,\n)\n\nresults = []\nfor tensors, tensor_params, params in example_fuzzer.take(10):\n    # description is the column label\n    sub_label = f\"{params['k0']:<6} x {params['k1']:<4} {'' if tensor_params['x']['is_contiguous'] else '(discontiguous)'}\"\n    results.append(\n        benchmark.Timer(\n            stmt=\"batched_dot_mul_sum(x, x)\",\n            setup=\"from __main__ import batched_dot_mul_sum\",\n            globals=tensors,\n            label=\"Batched dot\",\n            sub_label=sub_label,\n            description=\"mul/sum\",\n        ).blocked_autorange(min_run_time=1)\n    )\n    results.append(\n        benchmark.Timer(\n            stmt=\"batched_dot_bmm(x, x)\",\n            setup=\"from __main__ import batched_dot_bmm\",\n            globals=tensors,\n            label=\"Batched dot\",\n            sub_label=sub_label,\n            description=\"bmm\",\n        ).blocked_autorange(min_run_time=1)\n    )\n\ncompare = benchmark.Compare(results)\ncompare.trim_significant_figures()\ncompare.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    [--------------------- Batched dot ---------------------]\n                                         |  mul/sum  |   bmm\n    1 threads: ----------------------------------------------\n          725    x 257                   |      87   |    180\n          49     x 383                   |      15   |     30\n          34     x 1468                  |      30   |    118\n          187    x 5039                  |     400   |   1200\n          2140   x 1296 (discontiguous)  |    2000   |  41000\n          78     x 1598                  |      74   |    310\n          519    x 763                   |     190   |   1500\n          141    x 1082                  |      87   |    500\n          78     x 5    (discontiguous)  |       9   |     20\n          187    x 1                     |      12   |     10\n\n    Times are in microseconds (us).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5b9a\u4e49\u81ea\u5df1\u7684 `fuzzers` \u6709\u5f88\u5927\u7684\u7075\u6d3b\u6027,\u8fd9\u5bf9\u4e8e\u521b\u5efa\u5f3a\u5927\u7684\u8f93\u5165\u96c6\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u975e\u5e38\u6709\u7528\u3002\n\u4f46\u4e3a\u4e86\u8ba9\u4e8b\u60c5\u53d8\u5f97\u66f4\u7b80\u5355, PyTorch \u57fa\u51c6\u6d4b\u8bd5\u6a21\u5757\u4e3a\u5e38\u89c1\u7684\u57fa\u51c6\u6d4b\u8bd5\u9700\u6c42\u63d0\u4f9b\u4e86\u4e00\u4e9b\u5185\u7f6e\u7684 `fuzzers`\u3002\n\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a\u5185\u7f6e\u7684 `fuzzers` \u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.benchmark.op_fuzzers import binary\n\nresults = []\nfor tensors, tensor_params, params in binary.BinaryOpFuzzer(seed=0).take(10):\n    sub_label = f\"{params['k0']:<6} x {params['k1']:<4} {'' if tensor_params['x']['is_contiguous'] else '(discontiguous)'}\"\n    results.append(\n        benchmark.Timer(\n            stmt=\"batched_dot_mul_sum(x, x)\",\n            setup=\"from __main__ import batched_dot_mul_sum\",\n            globals=tensors,\n            label=\"Batched dot\",\n            sub_label=sub_label,\n            description=\"mul/sum\",\n        ).blocked_autorange(min_run_time=1)\n    )\n    results.append(\n        benchmark.Timer(\n            stmt=\"batched_dot_bmm(x, x)\",\n            setup=\"from __main__ import batched_dot_bmm\",\n            globals=tensors,\n            label=\"Batched dot\",\n            sub_label=sub_label,\n            description=\"bmm\",\n        ).blocked_autorange(min_run_time=1)\n    )\n\ncompare = benchmark.Compare(results)\ncompare.trim_significant_figures()\ncompare.colorize(rowwise=True)\ncompare.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    [----------------------- Batched dot ------------------------]\n                                             |  mul/sum  |   bmm\n    1 threads: ---------------------------------------------------\n          64     x 473  (discontiguous)      |    10000  |   40000\n          16384  x 12642115 (discontiguous)  |       31  |      78\n          8192   x 892                       |     4800  |   20400\n          512    x 64   (discontiguous)      |   110000  |  400000\n          493    x 27   (discontiguous)      |     1100  |    2440\n          118    x 32   (discontiguous)      |      870  |    2030\n          16     x 495  (discontiguous)      |    23600  |   24000\n          488    x 62374                     |    90000  |  100000\n          240372 x 69                        |    40000  |   16000\n          40156  x 32   (discontiguous)      |     2670  |    5000\n\n    Times are in microseconds (us).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. \u4f7f\u7528 `Callgrind` \u6536\u96c6\u6307\u4ee4\u8ba1\u6570\n\n\u4f18\u5316\u4ee3\u7801\u7684\u4e00\u4e2a\u6311\u6218\u662f\u65f6\u95f4\u7684\u53d8\u5316\u548c\u4e0d\u900f\u660e\u6027\u3002\u6709\u8bb8\u591a\u4e0d\u786e\u5b9a\u6027\u7684\u6765\u6e90,\n\u4ece\u81ea\u9002\u5e94\u65f6\u949f\u901f\u5ea6\u5230\u4e0e\u5176\u4ed6\u8fdb\u7a0b\u7684\u8d44\u6e90\u4e89\u7528\u3002\u6b64\u5916,\u7aef\u5230\u7aef\u65f6\u95f4\u5e76\u4e0d\u80fd\u63ed\u793a\u65f6\u95f4\u82b1\u8d39\u5728\u54ea\u91cc,\n\u800c\u8fd9\u6b63\u662f\u6211\u4eec\u5728\u4f18\u5316\u4ee3\u7801\u65f6\u611f\u5174\u8da3\u7684\u3002\n\n\u4e00\u79cd\u8865\u5145\u65b9\u6cd5\u662f\u4e5f\u6536\u96c6\u6307\u4ee4\u8ba1\u6570\u3002\u8fd9\u4e9b\u8ba1\u6570\u662f\u4e00\u79cd\u4ee3\u7406\u6307\u6807,\u5e76\u4e0d\u80fd\u6355\u83b7\u6027\u80fd\u7684\u6240\u6709\u65b9\u9762\n(\u4f8b\u5982\u5185\u5b58\u6216I/O\u7ed1\u5b9a\u4efb\u52a1),\u4f46\u5b83\u4eec\u786e\u5b9e\u5177\u6709\u4e00\u4e9b\u6709\u7528\u7684\u7279\u6027\u3002\u6307\u4ee4\u8ba1\u6570\u662f\u53ef\u91cd\u590d\u7684,\n\u4e0d\u53d7\u73af\u5883\u53d8\u5316\u7684\u5f71\u54cd,\u5e76\u4e14\u53ef\u4ee5\u63d0\u4f9b\u5bf9\u7a0b\u5e8f\u5728\u54ea\u91cc\u82b1\u8d39\u5468\u671f\u7684\u7ec6\u7c92\u5ea6\u6d1e\u5bdf\u3002\n\n\u4e3a\u4e86\u770b\u5230\u6307\u4ee4\u8ba1\u6570\u7684\u5b9e\u7528\u6027,\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u51cf\u5c11 `batched_dot_mul_sum` \u7684\u5f00\u9500\u3002\n\u663e\u800c\u6613\u89c1\u7684\u89e3\u51b3\u65b9\u6848\u662f\u5c06\u5176\u79fb\u81f3 C++ ,\u8fd9\u6837\u6211\u4eec\u5c31\u53ef\u4ee5\u907f\u514d\u5728 Python \u548c C++ \u4e4b\u95f4\u591a\u6b21\u6765\u56de\u5207\u6362\u3002\n\n\u5e78\u8fd0\u7684\u662f,\u6e90\u4ee3\u7801\u51e0\u4e4e\u662f\u76f8\u540c\u7684\u3002\u5728 C++ \u4e2d\u6211\u4eec\u5fc5\u987b\u95ee\u7684\u4e00\u4e2a\u95ee\u9898\u662f,\n\u6211\u4eec\u662f\u901a\u8fc7\u503c\u8fd8\u662f\u5f15\u7528\u6765\u4f20\u9012\u53c2\u6570\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batched_dot_src = \"\"\"\\\n/* ---- Python ---- */\n// def batched_dot_mul_sum(a, b):\n//     return a.mul(b).sum(-1)\n\ntorch::Tensor batched_dot_mul_sum_v0(\n    const torch::Tensor a,\n    const torch::Tensor b) {\n  return a.mul(b).sum(-1);\n}\n\ntorch::Tensor batched_dot_mul_sum_v1(\n    const torch::Tensor& a,\n    const torch::Tensor& b) {\n  return a.mul(b).sum(-1);\n}\n\"\"\"\n\n\n# PyTorch \u63d0\u4f9b\u4e00\u4e2a\u5b9e\u7528\u7a0b\u5e8f\u6765 JIT \u7f16\u8bd1 C++ \u6e90\u4ee3\u7801\u4e3a Python \u6269\u5c55,\n# \u4f7f\u5f97\u6d4b\u8bd5\u6211\u4eec\u7684 C++ \u5b9e\u73b0\u53d8\u5f97\u5f88\u5bb9\u6613:\nimport os\n\nfrom torch.utils import cpp_extension\n\ncpp_lib = cpp_extension.load_inline(\n    name=\"cpp_lib\",\n    cpp_sources=batched_dot_src,\n    extra_cflags=[\"-O3\"],\n    extra_include_paths=[\n        # `load_inline`\u9700\u8981\u77e5\u9053`pybind11`\u5934\u6587\u4ef6\u7684\u4f4d\u7f6e\u3002\n        os.path.join(os.getenv(\"CONDA_PREFIX\"), \"include\")\n    ],\n    functions=[\"batched_dot_mul_sum_v0\", \"batched_dot_mul_sum_v1\"],\n)\n\n# `load_inline` \u5c06\u521b\u5efa\u4e00\u4e2a\u5171\u4eab\u5bf9\u8c61,\u5e76\u52a0\u8f7d\u5230Python\u4e2d\u3002\u5f53\u6211\u4eec\u6536\u96c6\u6307\u4ee4\u8ba1\u6570\u65f6,\n# Timer\u5c06\u521b\u5efa\u4e00\u4e2a\u5b50\u8fdb\u7a0b,\u56e0\u6b64\u6211\u4eec\u9700\u8981\u91cd\u65b0\u5bfc\u5165\u5b83\u3002\u5bf9\u4e8eC\u6269\u5c55,\u5bfc\u5165\u8fc7\u7a0b\u7565\u6709\u4e0d\u540c,\n# \u4f46\u8fd9\u5c31\u662f\u6211\u4eec\u5728\u8fd9\u91cc\u6240\u505a\u7684\u3002\nmodule_import_str = f\"\"\"\\\n# https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path\nimport importlib.util\nspec = importlib.util.spec_from_file_location(\"cpp_lib\", {repr(cpp_lib.__file__)})\ncpp_lib = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(cpp_lib)\"\"\"\n\nimport textwrap\n\n\ndef pretty_print(result):\n    \"\"\"Import machinery for ``cpp_lib.so`` can get repetitive to look at.\"\"\"\n    print(\n        repr(result).replace(\n            textwrap.indent(module_import_str, \"  \"), \"  import cpp_lib\"\n        )\n    )\n\n\nt_baseline = benchmark.Timer(\n    stmt=\"batched_dot_mul_sum(x, x)\",\n    setup=\"\"\"\\\nfrom __main__ import batched_dot_mul_sum\nx = torch.randn(2, 2)\"\"\",\n)\n\nt0 = benchmark.Timer(\n    stmt=\"cpp_lib.batched_dot_mul_sum_v0(x, x)\",\n    setup=f\"\"\"\\\n{module_import_str}\nx = torch.randn(2, 2)\"\"\",\n)\n\nt1 = benchmark.Timer(\n    stmt=\"cpp_lib.batched_dot_mul_sum_v1(x, x)\",\n    setup=f\"\"\"\\\n{module_import_str}\nx = torch.randn(2, 2)\"\"\",\n)\n\n# \u8f6c\u79fb\u5230 C++ \u786e\u5b9e\u51cf\u5c11\u4e86\u5f00\u9500,\u4f46\u5f88\u96be\u5224\u65ad\u54ea\u79cd\u8c03\u7528\u7ea6\u5b9a\u66f4\u6709\u6548\u3002v1(\u4f7f\u7528\u5f15\u7528\u8c03\u7528)\u4f3c\u4e4e\u7a0d\u5feb\u4e00\u4e9b,\u4f46\u5728\u6d4b\u91cf\u8bef\u5dee\u8303\u56f4\u5185\u3002\npretty_print(t_baseline.blocked_autorange())\npretty_print(t0.blocked_autorange())\npretty_print(t1.blocked_autorange())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code-block:: none\n   :caption: Output\n\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb16935d2e8>\n    batched_dot_mul_sum(x, x)\n    setup:\n      from __main__ import batched_dot_mul_sum\n      x = torch.randn(2, 2)\n\n      6.92 us\n      1 measurement, 100000 runs , 1 thread\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb16935d2e8>\n    cpp_lib.batched_dot_mul_sum_v0(x, x)\n    setup:\n      import cpp_lib\n      x = torch.randn(2, 2)\n\n      5.29 us\n      1 measurement, 100000 runs , 1 thread\n    <torch.utils.benchmark.utils.common.Measurement object at 0x7fb16935d2e8>\n    cpp_lib.batched_dot_mul_sum_v1(x, x)\n    setup:\n      import cpp_lib\n      x = torch.randn(2, 2)\n\n      5.22 us\n      1 measurement, 100000 runs , 1 thread\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u8ba9\u6211\u4eec\u4f7f\u7528 ``Callgrind`` \u6765\u786e\u5b9a\u54ea\u79cd\u65b9\u5f0f\u66f4\u597d\u3002\nstats_v0 = t0.collect_callgrind()\nstats_v1 = t1.collect_callgrind()\n\npretty_print(stats_v0)\npretty_print(stats_v1)\n\n# `.as_standardized` \u79fb\u9664\u4e86\u6587\u4ef6\u540d\u548c\u67d0\u4e9b\u8def\u5f84\u524d\u7f00,\u4f7f\u51fd\u6570\u7b26\u53f7\u66f4\u6613\u8bfb\u3002\nstats_v0 = stats_v0.as_standardized()\nstats_v1 = stats_v1.as_standardized()\n\n# `.delta` \u5bf9\u6307\u4ee4\u8ba1\u6570\u8fdb\u884c\u5dee\u5206, `.denoise` \u5219\u79fb\u9664\u4e86 Python \u89e3\u91ca\u5668\u4e2d\u5df2\u77e5\u5b58\u5728\u663e\u8457\u6296\u52a8\u7684\u51e0\u4e2a\u51fd\u6570\u3002\ndelta = stats_v1.delta(stats_v0).denoise()\n\n# `.transform` \u662f\u4e00\u4e2a\u8f6c\u6362\u51fd\u6570\u540d\u7684\u4fbf\u5229 API\u3002\u5b83\u5728\u8fdb\u884c ``diff-ing`` \u65f6\u5f88\u6709\u7528,\u56e0\u4e3a\u53ef\u4ee5\u589e\u52a0\u62b5\u6d88,\u540c\u65f6\u4e5f\u80fd\u63d0\u9ad8\u53ef\u8bfb\u6027\u3002\nreplacements = (\n    (\"???:void pybind11\", \"pybind11\"),\n    (\"batched_dot_mul_sum_v0\", \"batched_dot_mul_sum_v1\"),\n    (\"at::Tensor, at::Tensor\", \"...\"),\n    (\"at::Tensor const&, at::Tensor const&\", \"...\"),\n    (\"auto torch::detail::wrap_pybind_function_impl_\", \"wrap_pybind_function_impl_\"),\n)\nfor before, after in replacements:\n    delta = delta.transform(lambda l: l.replace(before, after))\n\n# \u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u6253\u5370\u9009\u9879\u6765\u63a7\u5236\u663e\u793a\u51fd\u6570\u7684\u591a\u5c11\u5185\u5bb9\u3002\ntorch.set_printoptions(linewidth=160)\n\n# \u89e3\u6790\u540e,\u6307\u4ee4\u8ba1\u6570\u6e05\u695a\u5730\u8868\u660e,\u901a\u8fc7\u5f15\u7528\u4f20\u9012 `a` \u548c `b` \u66f4\u6709\u6548,\n# \u56e0\u4e3a\u5b83\u8df3\u8fc7\u4e86\u4e00\u4e9b `c10::TensorImpl` \u4e2d\u95f4\u5f20\u91cf\u7684\u7c3f\u8bb0\u64cd\u4f5c,\u5e76\u4e14\u4e0e `pybind11` \u4e5f\u66f4\u517c\u5bb9\u3002\n# \u8fd9\u4e0e\u6211\u4eec\u6709\u566a\u58f0\u65f6\u95f4\u89c2\u5bdf\u7ed3\u679c\u4e00\u81f4\u3002\nprint(delta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n<torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7fb0f06e7630>\ncpp_lib.batched_dot_mul_sum_v0(x, x)\nsetup:\n  import cpp_lib\n  x = torch.randn(2, 2)\n                           All          Noisy symbols removed\n    Instructions:      2392671                    2392671\n    Baseline:             4367                       4367\n100 runs per measurement, 1 thread\nWarning: PyTorch was not built with debug symbols.\n         Source information may be limited. Rebuild with\n         REL_WITH_DEB_INFO=1 for more detailed results.\n<torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7fb10400d208>\ncpp_lib.batched_dot_mul_sum_v1(x, x)\nsetup:\n  import cpp_lib\n  x = torch.randn(2, 2)\n                           All          Noisy symbols removed\n    Instructions:      2378978                    2378978\n    Baseline:             4367                       4367\n    100 runs per measurement, 1 thread\n    Warning: PyTorch was not built with debug symbols.\n             Source information may be limited. Rebuild with\n             REL_WITH_DEB_INFO=1 for more detailed results.\n    <torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7fb1000ab358>\n          86  ???:0x000000000020d9e0\n      56  ???:0x000000000020db10\n   -1100  pybind11::cpp_function::initialize<wrap_pybind_function_impl_<at::Tensor ... r (&)(...), std::integer_sequence<unsigned long, 0ul, 1ul>)::{lambda(...)\n   -1600  ???:wrap_pybind_function_impl_<at::Tensor (&)(...), 0ul, 1ul>(at::Tensor (&)(...), std::integer_sequence<unsigned long, 0ul, 1ul>)::{lambda(...)\n   -5200  ???:c10::intrusive_ptr<c10::TensorImpl, c10::UndefinedTensorImpl>::reset_()\n   -5935  ???:0x000000000022c0e0\nTotal: -13693\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5b66\u4e60\u66f4\u591a\n\n\u67e5\u770b\u5176\u4ed6\u6559\u7a0b\u7ee7\u7eed\u5b66\u4e60:\n\n-  [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler.html)\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}