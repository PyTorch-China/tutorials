{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\u7b80\u4ecb](introyt1_tutorial.html) ||\n[\u5f20\u91cf](tensors_deeper_tutorial.html) ||\n[\u81ea\u52a8\u5fae\u5206](autogradyt_tutorial.html) ||\n[\u6784\u5efa\u6a21\u578b](modelsyt_tutorial.html) ||\n[TensorBoard\u652f\u6301](tensorboardyt_tutorial.html) ||\n[\u8bad\u7ec3\u6a21\u578b](trainingyt.html) ||\n**\u6a21\u578b\u7406\u89e3**\n\n# \u4f7f\u7528 Captum \u8fdb\u884c\u6a21\u578b\u7406\u89e3\n\n\u8ddf\u968f\u4e0b\u9762\u7684\u89c6\u9891\u6216\u5728 [youtube](https://www.youtube.com/watch?v=Am2EF9CLu-g)_ \u4e0a\u89c2\u770b\u3002\u4ece [\u8fd9\u91cc](https://pytorch-tutorial-assets.s3.amazonaws.com/youtube-series/video7.zip)_ \u4e0b\u8f7d\u7b14\u8bb0\u672c\u548c\u76f8\u5e94\u6587\u4ef6\u3002\n\n.. raw:: html\n\n   <div style=\"margin-top:10px; margin-bottom:10px;\">\n     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Am2EF9CLu-g\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n   </div>\n\n[Captum](https://captum.ai/)_ (\u62c9\u4e01\u8bed\u4e2d\u7684\"\u7406\u89e3\")\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u53ef\u6269\u5c55\u7684\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5e93,\u5efa\u7acb\u5728PyTorch\u4e4b\u4e0a\u3002\n\n\u968f\u7740\u6a21\u578b\u590d\u6742\u6027\u7684\u589e\u52a0\u548c\u7531\u6b64\u5e26\u6765\u7684\u900f\u660e\u5ea6\u7684\u7f3a\u4e4f,\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u6a21\u578b\u7406\u89e3\u662f\u4e00\u4e2a\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df,\u4e5f\u662f\u8de8\u884c\u4e1a\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u9645\u5e94\u7528\u7684\u4e00\u4e2a\u5173\u6ce8\u9886\u57df\u3002Captum\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u7b97\u6cd5,\u5305\u62ec\u96c6\u6210\u68af\u5ea6,\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u5f0f\u6765\u7406\u89e3\u54ea\u4e9b\u7279\u5f81\u5bf9\u6a21\u578b\u7684\u8f93\u51fa\u505a\u51fa\u4e86\u8d21\u732e\u3002\n\n\u5b8c\u6574\u7684\u6587\u6863\u3001API\u53c2\u8003\u548c\u4e00\u5957\u5173\u4e8e\u7279\u5b9a\u4e3b\u9898\u7684\u6559\u7a0b\u53ef\u5728 [captum.ai](https://captum.ai/)_ \u7f51\u7ad9\u4e0a\u627e\u5230\u3002\n\n## \u4ecb\u7ecd\n\nCaptum\u5bf9\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u662f\u57fa\u4e8e*\u5f52\u56e0*\u7684\u3002Captum\u4e2d\u6709\u4e09\u79cd\u7c7b\u578b\u7684\u5f52\u56e0:\n\n-  **\u7279\u5f81\u5f52\u56e0**\u8bd5\u56fe\u89e3\u91ca\u7279\u5b9a\u8f93\u51fa\u662f\u7531\u751f\u6210\u5b83\u7684\u8f93\u5165\u7684\u54ea\u4e9b\u7279\u5f81\u4ea7\u751f\u7684\u3002\u7528\u67d0\u4e9b\u8bcd\u6765\u89e3\u91ca\u4e00\u7bc7\u7535\u5f71\u8bc4\u8bba\u662f\u6b63\u9762\u8fd8\u662f\u8d1f\u9762\u7684,\u5c31\u662f\u7279\u5f81\u5f52\u56e0\u7684\u4e00\u4e2a\u4f8b\u5b50\u3002\n-  **\u5c42\u5f52\u56e0**\u68c0\u67e5\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5728\u7279\u5b9a\u8f93\u5165\u4e0b\u7684\u6d3b\u52a8\u3002\u68c0\u67e5\u5377\u79ef\u5c42\u5bf9\u8f93\u5165\u56fe\u50cf\u7684\u7a7a\u95f4\u6620\u5c04\u8f93\u51fa\u5c31\u662f\u5c42\u5f52\u56e0\u7684\u4e00\u4e2a\u4f8b\u5b50\u3002\n-  **\u795e\u7ecf\u5143\u5f52\u56e0**\u7c7b\u4f3c\u4e8e\u5c42\u5f52\u56e0,\u4f46\u5173\u6ce8\u5355\u4e2a\u795e\u7ecf\u5143\u7684\u6d3b\u52a8\u3002\n\n\u5728\u8fd9\u4e2a\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u4e2d,\u6211\u4eec\u5c06\u770b\u770b\u7279\u5f81\u5f52\u56e0\u548c\u5c42\u5f52\u56e0\u3002\n\n\u6bcf\u79cd\u5f52\u56e0\u7c7b\u578b\u90fd\u6709\u591a\u79cd**\u5f52\u56e0\u7b97\u6cd5**\u4e0e\u4e4b\u76f8\u5173\u8054\u3002\u8bb8\u591a\u5f52\u56e0\u7b97\u6cd5\u53ef\u5206\u4e3a\u4e24\u5927\u7c7b:\n\n-  **\u57fa\u4e8e\u68af\u5ea6\u7684\u7b97\u6cd5**\u8ba1\u7b97\u6a21\u578b\u8f93\u51fa\u3001\u5c42\u8f93\u51fa\u6216\u795e\u7ecf\u5143\u6fc0\u6d3b\u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u53cd\u5411\u68af\u5ea6\u3002**\u96c6\u6210\u68af\u5ea6**(\u7528\u4e8e\u7279\u5f81)\u3001**\u5c42\u68af\u5ea6 \\* \u6fc0\u6d3b**\u548c**\u795e\u7ecf\u5143\u4f20\u5bfc**\u90fd\u662f\u57fa\u4e8e\u68af\u5ea6\u7684\u7b97\u6cd5\u3002\n-  **\u57fa\u4e8e\u6270\u52a8\u7684\u7b97\u6cd5**\u68c0\u67e5\u6a21\u578b\u3001\u5c42\u6216\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u5728\u8f93\u5165\u53d1\u751f\u53d8\u5316\u65f6\u7684\u53d8\u5316\u60c5\u51b5\u3002\u8f93\u5165\u6270\u52a8\u53ef\u80fd\u662f\u6709\u9488\u5bf9\u6027\u7684\u6216\u968f\u673a\u7684\u3002**\u906e\u6321**\u3001**\u7279\u5f81\u6d88\u878d**\u548c**\u7279\u5f81\u7f6e\u6362**\u90fd\u662f\u57fa\u4e8e\u6270\u52a8\u7684\u7b97\u6cd5\u3002\n\n\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u68c0\u67e5\u8fd9\u4e24\u79cd\u7c7b\u578b\u7684\u7b97\u6cd5\u3002\n\n\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u578b\u6a21\u578b,\u4ee5\u4e0e\u88ab\u68c0\u67e5\u7684\u8f93\u5165\u7279\u5f81\u76f4\u63a5\u76f8\u5173\u7684\u65b9\u5f0f\u53ef\u89c6\u5316\u5f52\u56e0\u6570\u636e\u662f\u5f88\u6709\u4ef7\u503c\u7684\u3002\u867d\u7136\u5f53\u7136\u53ef\u4ee5\u4f7f\u7528Matplotlib\u3001Plotly\u6216\u7c7b\u4f3c\u5de5\u5177\u521b\u5efa\u81ea\u5df1\u7684\u53ef\u89c6\u5316,\u4f46Captum\u63d0\u4f9b\u4e86\u4e13\u95e8\u7528\u4e8e\u5176\u5f52\u56e0\u7684\u589e\u5f3a\u5de5\u5177:\n\n-  ``captum.attr.visualization``\u6a21\u5757(\u4e0b\u9762\u5bfc\u5165\u4e3a``viz``)\u63d0\u4f9b\u4e86\u6709\u52a9\u4e8e\u53ef\u89c6\u5316\u4e0e\u56fe\u50cf\u76f8\u5173\u7684\u5f52\u56e0\u7684\u51fd\u6570\u3002\n-  **Captum Insights**\u662f\u5efa\u7acb\u5728Captum\u4e4b\u4e0a\u7684\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u53ef\u89e3\u91ca\u6027\u53ef\u89c6\u5316\u5c0f\u90e8\u4ef6,\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e26\u6709\u73b0\u6210\u53ef\u89c6\u5316\u5de5\u5177\u7684\u5c0f\u90e8\u4ef6,\u7528\u4e8e\u56fe\u50cf\u3001\u6587\u672c\u548c\u4efb\u610f\u6a21\u578b\u7c7b\u578b\u3002\n\n\u8fd9\u4e24\u79cd\u53ef\u89c6\u5316\u5de5\u5177\u96c6\u90fd\u5c06\u5728\u672c\u7b14\u8bb0\u672c\u4e2d\u8fdb\u884c\u6f14\u793a\u3002\u524d\u51e0\u4e2a\u793a\u4f8b\u5c06\u96c6\u4e2d\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u7528\u4f8b\u4e0a,\u4f46\u6700\u540e\u7684Captum Insights\u90e8\u5206\u5c06\u6f14\u793a\u89c6\u89c9\u95ee\u7b54\u6a21\u578b\u4e2d\u7684\u5f52\u56e0\u53ef\u89c6\u5316\u3002\n\n## \u5b89\u88c5\n\n\u5728\u5f00\u59cb\u4e4b\u524d,\u4f60\u9700\u8981\u6709\u4e00\u4e2aPython\u73af\u5883,\u5305\u62ec:\n\n-  Python 3.6\u6216\u66f4\u9ad8\u7248\u672c\n-  \u5bf9\u4e8eCaptum Insights\u793a\u4f8b,\u9700\u8981Flask 1.1\u6216\u66f4\u9ad8\u7248\u672c\u548cFlask-Compress(\u63a8\u8350\u4f7f\u7528\u6700\u65b0\u7248\u672c)\n-  PyTorch 1.2\u6216\u66f4\u9ad8\u7248\u672c(\u63a8\u8350\u4f7f\u7528\u6700\u65b0\u7248\u672c)\n-  TorchVision 0.6\u6216\u66f4\u9ad8\u7248\u672c(\u63a8\u8350\u4f7f\u7528\u6700\u65b0\u7248\u672c)\n-  Captum(\u63a8\u8350\u4f7f\u7528\u6700\u65b0\u7248\u672c)\n-  Matplotlib 3.3.4\u7248\u672c,\u56e0\u4e3aCaptum\u76ee\u524d\u4f7f\u7528\u4e86\u4e00\u4e2a\u5728\u66f4\u9ad8\u7248\u672c\u4e2d\u53c2\u6570\u5df2\u88ab\u91cd\u547d\u540d\u7684Matplotlib\u51fd\u6570\n\n\u8981\u5728Anaconda\u6216pip\u865a\u62df\u73af\u5883\u4e2d\u5b89\u88c5Captum,\u8bf7\u4f7f\u7528\u4e0b\u9762\u9002\u7528\u4e8e\u60a8\u73af\u5883\u7684\u547d\u4ee4:\n\n\u4f7f\u7528``conda``:\n\n```sh\nconda install pytorch torchvision captum flask-compress matplotlib=3.3.4 -c pytorch\n```\n\u4f7f\u7528``pip``:\n\n```sh\npip install torch torchvision captum matplotlib==3.3.4 Flask-Compress\n```\n\u5728\u60a8\u8bbe\u7f6e\u7684\u73af\u5883\u4e2d\u91cd\u65b0\u542f\u52a8\u6b64\u7b14\u8bb0\u672c,\u60a8\u5c31\u53ef\u4ee5\u5f00\u59cb\u4e86!\n\n\n## \u7b2c\u4e00\u4e2a\u793a\u4f8b\n \n\u9996\u5148,\u8ba9\u6211\u4eec\u770b\u4e00\u4e2a\u7b80\u5355\u7684\u89c6\u89c9\u793a\u4f8b\u3002\u6211\u4eec\u5c06\u4ece\u4e00\u4e2a\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684ResNet\u6a21\u578b\u5f00\u59cb\u3002\u6211\u4eec\u5c06\u83b7\u53d6\u4e00\u4e2a\u6d4b\u8bd5\u8f93\u5165,\u5e76\u4f7f\u7528\u4e0d\u540c\u7684**\u7279\u5f81\u5f52\u56e0**\u7b97\u6cd5\u6765\u68c0\u67e5\u8f93\u5165\u56fe\u50cf\u5982\u4f55\u5f71\u54cd\u8f93\u51fa,\u5e76\u67e5\u770b\u4e00\u4e9b\u6d4b\u8bd5\u56fe\u50cf\u7684\u8f93\u5165\u5f52\u56e0\u6620\u5c04\u7684\u6709\u7528\u53ef\u89c6\u5316\u3002\n \n\u9996\u5148,\u5bfc\u5165\u4e00\u4e9b\u5305: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nimport captum\nfrom captum.attr import IntegratedGradients, Occlusion, LayerGradCam, LayerAttribution\nfrom captum.attr import visualization as viz\n\nimport os, sys\nimport json\n\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\u6211\u4eec\u5c06\u4f7f\u7528TorchVision\u6a21\u578b\u5e93\u4e0b\u8f7d\u4e00\u4e2a\u9884\u8bad\u7ec3\u7684ResNet\u3002\u7531\u4e8e\u6211\u4eec\u4e0d\u8fdb\u884c\u8bad\u7ec3,\u6211\u4eec\u5c06\u6682\u65f6\u5c06\u5176\u7f6e\u4e8e\u8bc4\u4f30\u6a21\u5f0f\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(weights='IMAGENET1K_V1')\nmodel = model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f60\u4ece\u4e2d\u83b7\u53d6\u8fd9\u4e2a\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u7684\u5730\u65b9\u5e94\u8be5\u4e5f\u6709\u4e00\u4e2a``img``\u6587\u4ef6\u5939,\u5176\u4e2d\u5305\u542b\u4e00\u4e2a``cat.jpg``\u6587\u4ef6\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_img = Image.open('img/cat.jpg')\ntest_img_data = np.asarray(test_img)\nplt.imshow(test_img_data)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u7684ResNet\u6a21\u578b\u662f\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684,\u5b83\u671f\u671b\u56fe\u50cf\u5177\u6709\u4e00\u5b9a\u7684\u5927\u5c0f,\u5e76\u4e14\u901a\u9053\u6570\u636e\u88ab\u5f52\u4e00\u5316\u5230\u7279\u5b9a\u7684\u503c\u8303\u56f4\u3002\u6211\u4eec\u8fd8\u5c06\u83b7\u53d6\u6a21\u578b\u8bc6\u522b\u7684\u7c7b\u522b\u7684\u4eba\u7c7b\u53ef\u8bfb\u6807\u7b7e\u5217\u8868 - \u5b83\u5e94\u8be5\u4e5f\u5728``img``\u6587\u4ef6\u5939\u4e2d\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u6a21\u578b\u671f\u671b224x224 3\u8272\u5f69\u56fe\u50cf\ntransform = transforms.Compose([\n transforms.Resize(224),\n transforms.CenterCrop(224),\n transforms.ToTensor()\n])\n\n# \u6807\u51c6ImageNet\u5f52\u4e00\u5316\ntransform_normalize = transforms.Normalize(\n     mean=[0.485, 0.456, 0.406],\n     std=[0.229, 0.224, 0.225]\n )\n\ntransformed_img = transform(test_img)\ninput_img = transform_normalize(transformed_img)\ninput_img = input_img.unsqueeze(0) # \u6a21\u578b\u9700\u8981\u4e00\u4e2a\u865a\u62df\u7684\u6279\u6b21\u7ef4\u5ea6\n\nlabels_path = 'img/imagenet_class_index.json'\nwith open(labels_path) as json_data:\n    idx_to_labels = json.load(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728,\u6211\u4eec\u53ef\u4ee5\u95ee:\u8fd9\u4e2a\u6a21\u578b\u8ba4\u4e3a\u8fd9\u5f20\u56fe\u50cf\u4ee3\u8868\u4ec0\u4e48?\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output = model(input_img)\noutput = F.softmax(output, dim=1)\nprediction_score, pred_label_idx = torch.topk(output, 1)\npred_label_idx.squeeze_()\npredicted_label = idx_to_labels[str(pred_label_idx.item())][1]\nprint('\u9884\u6d4b:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u5df2\u7ecf\u786e\u8ba4ResNet\u8ba4\u4e3a\u6211\u4eec\u7684\u732b\u7684\u56fe\u50cf\u786e\u5b9e\u662f\u4e00\u53ea\u732b\u3002\u4f46\u662f*\u4e3a\u4ec0\u4e48*\u6a21\u578b\u8ba4\u4e3a\u8fd9\u662f\u4e00\u5f20\u732b\u7684\u56fe\u50cf\u5462?\n\n\u8981\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898,\u6211\u4eec\u5c31\u8981\u6c42\u52a9\u4e8eCaptum\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528\u96c6\u6210\u68af\u5ea6\u8fdb\u884c\u7279\u5f81\u5f52\u56e0\n\n**\u7279\u5f81\u5f52\u56e0**\u8bd5\u56fe\u7528\u751f\u6210\u7279\u5b9a\u8f93\u51fa\u7684\u8f93\u5165\u7684\u7279\u5f81\u6765\u89e3\u91ca\u8be5\u8f93\u51fa\u3002\u5b83\u4f7f\u7528\u7279\u5b9a\u7684\u8f93\u5165 - \u5728\u8fd9\u91cc\u662f\u6211\u4eec\u7684\u6d4b\u8bd5\u56fe\u50cf - \u6765\u751f\u6210\u4e00\u4e2a\u8f93\u5165\u7279\u5f81\u5bf9\u7279\u5b9a\u8f93\u51fa\u7279\u5f81\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u7684\u6620\u5c04\u3002\n\n[\u96c6\u6210\u68af\u5ea6](https://captum.ai/api/integrated_gradients.html)_ \u662fCaptum\u4e2d\u53ef\u7528\u7684\u7279\u5f81\u5f52\u56e0\u7b97\u6cd5\u4e4b\u4e00\u3002\u96c6\u6210\u68af\u5ea6\u901a\u8fc7\u8fd1\u4f3c\u6a21\u578b\u8f93\u51fa\u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u68af\u5ea6\u7684\u79ef\u5206,\u4e3a\u6bcf\u4e2a\u8f93\u5165\u7279\u5f81\u5206\u914d\u4e00\u4e2a\u91cd\u8981\u6027\u5206\u6570\u3002\n\n\u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d,\u6211\u4eec\u5c06\u4f7f\u7528\u8f93\u51fa\u5411\u91cf\u7684\u4e00\u4e2a\u7279\u5b9a\u5143\u7d20 - \u4e5f\u5c31\u662f\u8868\u793a\u6a21\u578b\u5bf9\u6240\u9009\u7c7b\u522b\u7684\u7f6e\u4fe1\u5ea6\u7684\u90a3\u4e2a\u5143\u7d20 - \u5e76\u4f7f\u7528\u96c6\u6210\u68af\u5ea6\u6765\u7406\u89e3\u54ea\u4e9b\u8f93\u5165\u56fe\u50cf\u90e8\u5206\u5bf9\u8fd9\u4e2a\u8f93\u51fa\u505a\u51fa\u4e86\u8d21\u732e\u3002\n\n\u4e00\u65e6\u6211\u4eec\u4ece\u96c6\u6210\u68af\u5ea6\u83b7\u5f97\u4e86\u91cd\u8981\u6027\u6620\u5c04,\u6211\u4eec\u5c06\u4f7f\u7528Captum\u4e2d\u7684\u53ef\u89c6\u5316\u5de5\u5177\u6765\u63d0\u4f9b\u4e0e\u88ab\u68c0\u67e5\u7684\u8f93\u5165\u7279\u5f81\u76f4\u63a5\u76f8\u5173\u7684\u91cd\u8981\u6027\u6620\u5c04\u7684\u6709\u7528\u8868\u793a\u3002Captum\u7684``visualize_image_attr()``\u51fd\u6570\u63d0\u4f9b\u4e86\u5404\u79cd\u81ea\u5b9a\u4e49\u663e\u793a\u5f52\u56e0\u6570\u636e\u7684\u9009\u9879\u3002\u5728\u8fd9\u91cc,\u6211\u4eec\u4f20\u5165\u4e00\u4e2a\u81ea\u5b9a\u4e49\u7684Matplotlib\u989c\u8272\u6620\u5c04\u3002\n\n\u8fd0\u884c\u5e26\u6709``integrated_gradients.attribute()``\u8c03\u7528\u7684\u5355\u5143\u683c\u901a\u5e38\u9700\u8981\u4e00\u4e24\u5206\u949f\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u7528\u6a21\u578b\u521d\u59cb\u5316\u5f52\u56e0\u7b97\u6cd5\nintegrated_gradients = IntegratedGradients(model)\n\n# \u8981\u6c42\u7b97\u6cd5\u5c06\u6211\u4eec\u7684\u8f93\u51fa\u76ee\u6807\u5f52\u56e0\u4e8e\nattributions_ig = integrated_gradients.attribute(input_img, target=pred_label_idx, n_steps=200)\n\n# \u663e\u793a\u539f\u59cb\u56fe\u50cf\u4ee5\u4f9b\u6bd4\u8f83\n_ = viz.visualize_image_attr(None, np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)), \n                      method=\"original_image\", title=\"Original Image\")\n\ndefault_cmap = LinearSegmentedColormap.from_list('custom blue', \n                                                 [(0, '#ffffff'),\n                                                  (0.25, '#0000ff'),\n                                                  (1, '#0000ff')], N=256)\n\n_ = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n                             np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n                             method='heat_map',\n                             cmap=default_cmap,\n                             show_colorbar=True,\n                             sign='positive',\n                             title='\u96c6\u6210\u68af\u5ea6')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u4e0a\u9762\u7684\u56fe\u50cf\u4e2d,\u4f60\u5e94\u8be5\u53ef\u4ee5\u770b\u5230\u96c6\u6210\u68af\u5ea6\u5728\u56fe\u50cf\u4e2d\u732b\u7684\u4f4d\u7f6e\u7ed9\u51fa\u4e86\u6700\u5f3a\u7684\u4fe1\u53f7\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528\u906e\u6321\u8fdb\u884c\u7279\u5f81\u5f52\u56e0\n\n\u57fa\u4e8e\u68af\u5ea6\u7684\u5f52\u56e0\u65b9\u6cd5\u6709\u52a9\u4e8e\u901a\u8fc7\u76f4\u63a5\u8ba1\u7b97\u8f93\u51fa\u76f8\u5bf9\u4e8e\u8f93\u5165\u7684\u53d8\u5316\u6765\u7406\u89e3\u6a21\u578b\u3002*\u57fa\u4e8e\u6270\u52a8\u7684\u5f52\u56e0*\u65b9\u6cd5\u5219\u66f4\u76f4\u63a5\u5730\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898,\u901a\u8fc7\u5bf9\u8f93\u5165\u8fdb\u884c\u53d8\u5316\u6765\u6d4b\u91cf\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002\n[\u906e\u6321](https://captum.ai/api/occlusion.html)_ \u5c31\u662f\u8fd9\u6837\u4e00\u79cd\u65b9\u6cd5\u3002\u5b83\u6d89\u53ca\u66ff\u6362\u8f93\u5165\u56fe\u50cf\u7684\u90e8\u5206\u533a\u57df,\u5e76\u68c0\u67e5\u5bf9\u8f93\u51fa\u4fe1\u53f7\u7684\u5f71\u54cd\u3002\n\n\u4e0b\u9762,\u6211\u4eec\u8bbe\u7f6e\u906e\u6321\u5f52\u56e0\u3002\u4e0e\u914d\u7f6e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7c7b\u4f3c,\u4f60\u53ef\u4ee5\u6307\u5b9a\u76ee\u6807\u533a\u57df\u7684\u5927\u5c0f,\u4ee5\u53ca\u786e\u5b9a\u5355\u4e2a\u6d4b\u91cf\u95f4\u8ddd\u7684\u6b65\u957f\u957f\u5ea6\u3002\u6211\u4eec\u5c06\u4f7f\u7528``visualize_image_attr_multiple()``\u6765\u53ef\u89c6\u5316\u6211\u4eec\u7684\u906e\u6321\u5f52\u56e0\u8f93\u51fa,\u663e\u793a\u6bcf\u4e2a\u533a\u57df\u7684\u6b63\u9762\u548c\u8d1f\u9762\u5f52\u56e0\u7684\u70ed\u56fe,\u5e76\u7528\u6b63\u9762\u5f52\u56e0\u533a\u57df\u63a9\u7801\u539f\u59cb\u56fe\u50cf\u3002\u63a9\u7801\u53ef\u4ee5\u7ed9\u51fa\u4e00\u4e2a\u975e\u5e38\u6709\u542f\u53d1\u6027\u7684\u89c6\u56fe,\u663e\u793a\u6a21\u578b\u53d1\u73b0\u54ea\u4e9b\u533a\u57df\u6700\"\u50cf\u732b\"\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "occlusion = Occlusion(model)\n\nattributions_occ = occlusion.attribute(input_img,\n                                       target=pred_label_idx,\n                                       strides=(3, 8, 8),\n                                       sliding_window_shapes=(3,15, 15),\n                                       baselines=0)\n\n\n_ = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n                                      np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n                                      [\"original_image\", \"heat_map\", \"heat_map\", \"masked_image\"],\n                                      [\"all\", \"positive\", \"negative\", \"positive\"],\n                                      show_colorbar=True,\n                                      titles=[\"Original\", \"Positive Attribution\", \"Negative Attribution\", \"Masked\"],\n                                      fig_size=(18, 6)\n                                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u540c\u6837,\u6211\u4eec\u770b\u5230\u56fe\u50cf\u4e2d\u5305\u542b\u732b\u7684\u533a\u57df\u88ab\u8d4b\u4e88\u4e86\u66f4\u5927\u7684\u91cd\u8981\u6027\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528\u5c42\u68af\u5ea6\u7c7b\u6fc0\u6d3b\u6620\u5c04(Layer GradCAM)\u8fdb\u884c\u5c42\u5f52\u56e0\n\n**\u5c42\u5f52\u56e0**\u5141\u8bb8\u4f60\u5c06\u6a21\u578b\u4e2d\u9690\u85cf\u5c42\u7684\u6d3b\u52a8\u5f52\u56e0\u4e8e\u8f93\u5165\u7684\u7279\u5f81\u3002\u4e0b\u9762,\u6211\u4eec\u5c06\u4f7f\u7528\n\u5c42\u5f52\u56e0\u7b97\u6cd5\u6765\u68c0\u67e5\u6a21\u578b\u4e2d\u4e00\u4e2a\u5377\u79ef\u5c42\u7684\u6d3b\u52a8\u3002\n\nGradCAM\u8ba1\u7b97\u76ee\u6807\u8f93\u51fa\u76f8\u5bf9\u4e8e\u7ed9\u5b9a\u5c42\u7684\u68af\u5ea6,\u5bf9\u6bcf\u4e2a\u8f93\u51fa\u901a\u9053(\u8f93\u51fa\u7684\u7b2c2\u7ef4)\u8fdb\u884c\u5e73\u5747,\n\u5e76\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u5e73\u5747\u68af\u5ea6\u4e58\u4ee5\u5c42\u6fc0\u6d3b\u3002\u7ed3\u679c\u5728\u6240\u6709\u901a\u9053\u4e0a\u6c42\u548c\u3002GradCAM\u4e13\u4e3a\u5377\u79ef\u7f51\u7edc\n\u8bbe\u8ba1;\u7531\u4e8e\u5377\u79ef\u5c42\u7684\u6d3b\u52a8\u901a\u5e38\u5728\u7a7a\u95f4\u4e0a\u6620\u5c04\u5230\u8f93\u5165,\u56e0\u6b64GradCAM\u5f52\u56e0\u901a\u5e38\u4f1a\u88ab\u4e0a\u91c7\u6837\n\u5e76\u7528\u4e8e\u63a9\u76d6\u8f93\u5165\u3002\n\n\u5c42\u5f52\u56e0\u7684\u8bbe\u7f6e\u7c7b\u4f3c\u4e8e\u8f93\u5165\u5f52\u56e0,\u9664\u4e86\u9664\u4e86\u6a21\u578b\u4e4b\u5916,\u4f60\u8fd8\u5fc5\u987b\u6307\u5b9a\u6a21\u578b\u4e2d\u4f60\u5e0c\u671b\u68c0\u67e5\u7684\n\u9690\u85cf\u5c42\u3002\u4e0e\u4e0a\u9762\u4e00\u6837,\u5f53\u6211\u4eec\u8c03\u7528`attribute()`\u65f6,\u6211\u4eec\u6307\u5b9a\u611f\u5174\u8da3\u7684\u76ee\u6807\u7c7b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_gradcam = LayerGradCam(model, model.layer3[1].conv2)\nattributions_lgc = layer_gradcam.attribute(input_img, target=pred_label_idx)\n\n_ = viz.visualize_image_attr(attributions_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n                             sign=\"all\",\n                             title=\"Layer 3 Block 1 Conv 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u5c06\u4f7f\u7528[LayerAttribution](https://captum.ai/api/base_classes.html?highlight=layerattribution#captum.attr.LayerAttribution)_\n\u57fa\u7c7b\u4e2d\u7684\u4fbf\u5229\u65b9\u6cd5`interpolate()`\u6765\u4e0a\u91c7\u6837\u8fd9\u4e9b\u5f52\u56e0\u6570\u636e,\u4ee5\u4fbf\u4e0e\u8f93\u5165\u56fe\u50cf\u8fdb\u884c\u6bd4\u8f83\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upsamp_attr_lgc = LayerAttribution.interpolate(attributions_lgc, input_img.shape[2:])\n\nprint(attributions_lgc.shape)\nprint(upsamp_attr_lgc.shape)\nprint(input_img.shape)\n\n_ = viz.visualize_image_attr_multiple(upsamp_attr_lgc[0].cpu().permute(1,2,0).detach().numpy(),\n                                      transformed_img.permute(1,2,0).numpy(),\n                                      [\"original_image\",\"blended_heat_map\",\"masked_image\"],\n                                      [\"all\",\"positive\",\"positive\"],\n                                      show_colorbar=True,\n                                      titles=[\"Original\", \"Positive Attribution\", \"Masked\"],\n                                      fig_size=(18, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u6837\u7684\u53ef\u89c6\u5316\u53ef\u4ee5\u8ba9\u4f60\u6df1\u5165\u4e86\u89e3\u9690\u85cf\u5c42\u5982\u4f55\u54cd\u5e94\u4f60\u7684\u8f93\u5165\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528Captum Insights\u8fdb\u884c\u53ef\u89c6\u5316\n\nCaptum Insights\u662f\u4e00\u4e2a\u5efa\u7acb\u5728Captum\u4e4b\u4e0a\u7684\u53ef\u89e3\u91ca\u6027\u53ef\u89c6\u5316\u5c0f\u90e8\u4ef6,\u65e8\u5728\u4fc3\u8fdb\u6a21\u578b\u7406\u89e3\u3002\nCaptum Insights\u53ef\u7528\u4e8e\u56fe\u50cf\u3001\u6587\u672c\u548c\u5176\u4ed6\u7279\u5f81,\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u7279\u5f81\u5f52\u56e0\u3002\u5b83\u5141\u8bb8\u4f60\u53ef\u89c6\u5316\n\u591a\u4e2a\u8f93\u5165/\u8f93\u51fa\u5bf9\u7684\u5f52\u56e0,\u5e76\u63d0\u4f9b\u7528\u4e8e\u56fe\u50cf\u3001\u6587\u672c\u548c\u4efb\u610f\u6570\u636e\u7684\u53ef\u89c6\u5316\u5de5\u5177\u3002\n\n\u5728\u672c\u7b14\u8bb0\u672c\u7684\u8fd9\u4e00\u90e8\u5206,\u6211\u4eec\u5c06\u4f7f\u7528Captum Insights\u53ef\u89c6\u5316\u591a\u4e2a\u56fe\u50cf\u5206\u7c7b\u63a8\u7406\u3002\n\n\u9996\u5148,\u8ba9\u6211\u4eec\u6536\u96c6\u4e00\u4e9b\u56fe\u50cf,\u770b\u770b\u6a21\u578b\u5bf9\u5b83\u4eec\u7684\u770b\u6cd5\u3002\u4e3a\u4e86\u589e\u52a0\u591a\u6837\u6027,\u6211\u4eec\u5c06\u4f7f\u7528\u732b\u3001\n\u8336\u58f6\u548c\u4e09\u53f6\u866b\u5316\u77f3:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imgs = ['img/cat.jpg', 'img/teapot.jpg', 'img/trilobite.jpg']\n\nfor img in imgs:\n    img = Image.open(img)\n    transformed_img = transform(img)\n    input_img = transform_normalize(transformed_img)\n    input_img = input_img.unsqueeze(0) # \u6a21\u578b\u9700\u8981\u4e00\u4e2a\u865a\u62df\u7684\u6279\u6b21\u7ef4\u5ea6\n\n    output = model(input_img)\n    output = F.softmax(output, dim=1)\n    prediction_score, pred_label_idx = torch.topk(output, 1)\n    pred_label_idx.squeeze_()\n    predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n    print('Predicted:', predicted_label, '/', pred_label_idx.item(), ' (', prediction_score.squeeze().item(), ')')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...\u770b\u8d77\u6765\u6211\u4eec\u7684\u6a21\u578b\u90fd\u6b63\u786e\u8bc6\u522b\u4e86\u5b83\u4eec - \u4f46\u662f,\u6211\u4eec\u5f53\u7136\u5e0c\u671b\u6df1\u5165\u6316\u6398\u3002\u4e3a\u6b64,\u6211\u4eec\u5c06\n\u4f7f\u7528Captum Insights\u5c0f\u90e8\u4ef6,\u6211\u4eec\u7528\u4e0b\u9762\u5bfc\u5165\u7684`AttributionVisualizer`\u5bf9\u8c61\u5bf9\u5176\u8fdb\u884c\u914d\u7f6e\u3002\n`AttributionVisualizer`\u671f\u671b\u6279\u91cf\u6570\u636e,\u6240\u4ee5\u6211\u4eec\u5c06\u5f15\u5165Captum\u7684`Batch`\u8f85\u52a9\u7c7b\u3002\n\u6211\u4eec\u5c06\u67e5\u770b\u56fe\u50cf,\u56e0\u6b64\u6211\u4eec\u8fd8\u5c06\u5bfc\u5165`ImageFeature`\u3002\n\n\u6211\u4eec\u4f7f\u7528\u4ee5\u4e0b\u53c2\u6570\u914d\u7f6e`AttributionVisualizer`:\n\n- \u8981\u68c0\u67e5\u7684\u6a21\u578b\u6570\u7ec4(\u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d,\u53ea\u6709\u4e00\u4e2a)\n- \u4e00\u4e2a\u8bc4\u5206\u51fd\u6570,\u5141\u8bb8Captum Insights\u4ece\u6a21\u578b\u4e2d\u63d0\u53d6\u524dk\u4e2a\u9884\u6d4b\n- \u6211\u4eec\u6a21\u578b\u8bad\u7ec3\u7684\u7c7b\u522b\u7684\u6709\u5e8f\u3001\u4eba\u7c7b\u53ef\u8bfb\u5217\u8868\n- \u8981\u67e5\u627e\u7684\u7279\u5f81\u5217\u8868 - \u5728\u6211\u4eec\u7684\u4f8b\u5b50\u4e2d,\u662f\u4e00\u4e2a`ImageFeature`\n- \u4e00\u4e2a\u6570\u636e\u96c6,\u5b83\u662f\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61,\u8fd4\u56de\u8f93\u5165\u548c\u6807\u7b7e\u7684\u6279\u6b21 - \u5c31\u50cf\u4f60\u7528\u4e8e\u8bad\u7ec3\u4e00\u6837\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from captum.insights import AttributionVisualizer, Batch\nfrom captum.insights.attr_vis.features import ImageFeature\n\n# \u57fa\u7ebf\u662f\u5168\u96f6\u8f93\u5165 - \u8fd9\u53ef\u80fd\u4f1a\u56e0\u4f60\u7684\u6570\u636e\u800c\u6709\u6240\u4e0d\u540c\ndef baseline_func(input):\n    return input * 0\n\n# \u5408\u5e76\u4e0a\u9762\u7684\u56fe\u50cf\u53d8\u6362\ndef full_img_transform(input):\n    i = Image.open(input)\n    i = transform(i)\n    i = transform_normalize(i)\n    i = i.unsqueeze(0)\n    return i\n\n\ninput_imgs = torch.cat(list(map(lambda i: full_img_transform(i), imgs)), 0)\n\nvisualizer = AttributionVisualizer(\n    models=[model],\n    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n    classes=list(map(lambda k: idx_to_labels[k][1], idx_to_labels.keys())),\n    features=[\n        ImageFeature(\n            \"\u7167\u7247\",\n            baseline_transforms=[baseline_func],\n            input_transforms=[],\n        )\n    ],\n    dataset=[Batch(input_imgs, labels=[282,849,69])]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6ce8\u610f,\u8fd0\u884c\u4e0a\u9762\u7684\u5355\u5143\u683c\u5e76\u6ca1\u6709\u82b1\u8d39\u592a\u591a\u65f6\u95f4,\u4e0d\u50cf\u6211\u4eec\u4e4b\u524d\u7684\u5f52\u56e0\u90a3\u6837\u3002\u8fd9\u662f\u56e0\u4e3a\nCaptum Insights\u5141\u8bb8\u4f60\u5728\u53ef\u89c6\u5316\u5c0f\u90e8\u4ef6\u4e2d\u914d\u7f6e\u4e0d\u540c\u7684\u5f52\u56e0\u7b97\u6cd5,\u4e4b\u540e\u5b83\u5c06\u8ba1\u7b97\u5e76\u663e\u793a\n\u5f52\u56e0\u3002*\u90a3\u4e2a*\u8fc7\u7a0b\u5c06\u9700\u8981\u51e0\u5206\u949f\u65f6\u95f4\u3002\n\n\u8fd0\u884c\u4e0b\u9762\u7684\u5355\u5143\u683c\u5c06\u6e32\u67d3Captum Insights\u5c0f\u90e8\u4ef6\u3002\u7136\u540e\u4f60\u53ef\u4ee5\u9009\u62e9\u5f52\u56e0\u65b9\u6cd5\u53ca\u5176\u53c2\u6570\u3001\n\u6839\u636e\u9884\u6d4b\u7684\u7c7b\u6216\u9884\u6d4b\u7684\u6b63\u786e\u6027\u8fc7\u6ee4\u6a21\u578b\u54cd\u5e94\u3001\u67e5\u770b\u6a21\u578b\u7684\u9884\u6d4b\u53ca\u76f8\u5173\u6982\u7387\u3001\u67e5\u770b\u5f52\u56e0\u4e0e\n\u539f\u59cb\u56fe\u50cf\u7684\u70ed\u529b\u56fe\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "visualizer.render()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}