{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\u7b80\u4ecb](introyt1_tutorial.html) ||\n[\u5f20\u91cf](tensors_deeper_tutorial.html) ||\n[\u81ea\u52a8\u5fae\u5206](autogradyt_tutorial.html) ||\n[\u6784\u5efa\u6a21\u578b](modelsyt_tutorial.html) ||\n**TensorBoard\u652f\u6301** ||\n[\u8bad\u7ec3\u6a21\u578b](trainingyt.html) ||\n[\u6a21\u578b\u7406\u89e3](captumyt.html)\n\n# PyTorch TensorBoard \u652f\u6301\n\n\u8ddf\u968f\u4e0b\u9762\u7684\u89c6\u9891\u6216\u5728 [youtube](https://www.youtube.com/watch?v=6CEld3hZgqc)_ \u4e0a\u89c2\u770b\u3002\n\n.. raw:: html\n\n   <div style=\"margin-top:10px; margin-bottom:10px;\">\n     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6CEld3hZgqc\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n   </div>\n\n## \u5f00\u59cb\u4e4b\u524d\n\n\u8981\u8fd0\u884c\u6b64\u6559\u7a0b\uff0c\u60a8\u9700\u8981\u5b89\u88c5PyTorch\u3001TorchVision\u3001Matplotlib\u548cTensorBoard\u3002\n\n\u4f7f\u7528 ``conda``\uff1a\n\n```sh\nconda install pytorch torchvision -c pytorch\nconda install matplotlib tensorboard\n```\n\u4f7f\u7528 ``pip``\uff1a\n\n```sh\npip install torch torchvision matplotlib tensorboard\n```\n\u5b89\u88c5\u5b8c\u4f9d\u8d56\u9879\u540e\uff0c\u8bf7\u5728\u5b89\u88c5\u5b83\u4eec\u7684Python\u73af\u5883\u4e2d\u91cd\u65b0\u542f\u52a8\u6b64\u7b14\u8bb0\u672c\u3002\n\n\n## \u4ecb\u7ecd\n \n\u5728\u672c\u7b14\u8bb0\u672c\u4e2d\uff0c\u6211\u4eec\u5c06\u8bad\u7ec3LeNet-5\u7684\u53d8\u4f53\uff0c\u9488\u5bf9Fashion-MNIST\u6570\u636e\u96c6\u3002\nFashion-MNIST\u662f\u4e00\u7ec4\u63cf\u7ed8\u5404\u79cd\u670d\u88c5\u7684\u56fe\u50cf\u74e6\u7247\uff0c\u6709\u5341\u4e2a\u7c7b\u6807\u7b7e\u6307\u793a\u6240\u63cf\u7ed8\u7684\u670d\u88c5\u7c7b\u578b\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# PyTorch\u6a21\u578b\u548c\u8bad\u7ec3\u5fc5\u9700\u54c1\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# \u56fe\u50cf\u6570\u636e\u96c6\u548c\u56fe\u50cf\u64cd\u4f5c\nimport torchvision\nimport torchvision.transforms as transforms\n\n# \u56fe\u50cf\u663e\u793a\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# PyTorch TensorBoard\u652f\u6301\nfrom torch.utils.tensorboard import SummaryWriter\n\n# \u5982\u679c\u60a8\u4f7f\u7528\u7684\u73af\u5883\u5b89\u88c5\u4e86TensorFlow\uff08\u5982Google Colab\uff09\uff0c\u8bf7\u53d6\u6d88\u6ce8\u91ca\u4ee5\u4e0b\u4ee3\u7801\u4ee5\u907f\u514d\u5c06\u5d4c\u5165\u4fdd\u5b58\u5230TensorBoard\u76ee\u5f55\u65f6\u51fa\u73b0\u9519\u8bef\n\n# import tensorflow as tf\n# import tensorboard as tb\n# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5728TensorBoard\u4e2d\u663e\u793a\u56fe\u50cf\n\n\u8ba9\u6211\u4eec\u4ece\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u793a\u4f8b\u56fe\u50cf\u6dfb\u52a0\u5230TensorBoard\u5f00\u59cb\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u6536\u96c6\u6570\u636e\u96c6\u5e76\u51c6\u5907\u6d88\u8d39\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))])\n\n# \u5728./data\u4e2d\u5b58\u50a8\u5355\u72ec\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1\u5206\u5272\ntraining_set = torchvision.datasets.FashionMNIST('./data',\n    download=True,\n    train=True,\n    transform=transform)\nvalidation_set = torchvision.datasets.FashionMNIST('./data',\n    download=True,\n    train=False,\n    transform=transform)\n\ntraining_loader = torch.utils.data.DataLoader(training_set,\n                                              batch_size=4,\n                                              shuffle=True,\n                                              num_workers=2)\n\n\nvalidation_loader = torch.utils.data.DataLoader(validation_set,\n                                                batch_size=4,\n                                                shuffle=False,\n                                                num_workers=2)\n\n# \u7c7b\u6807\u7b7e\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# \u5185\u8054\u56fe\u50cf\u663e\u793a\u7684\u8f85\u52a9\u51fd\u6570\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # \u53cd\u5f52\u4e00\u5316\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# \u63d0\u53d6\u4e00\u62794\u5f20\u56fe\u50cf\ndataiter = iter(training_loader)\nimages, labels = next(dataiter)\n\n# \u4ece\u56fe\u50cf\u521b\u5efa\u7f51\u683c\u5e76\u663e\u793a\u5b83\u4eec\nimg_grid = torchvision.utils.make_grid(images)\nmatplotlib_imshow(img_grid, one_channel=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e0a\u9762\uff0c\u6211\u4eec\u4f7f\u7528TorchVision\u548cMatplotlib\u521b\u5efa\u4e86\u4e00\u4e2a\u8f93\u5165\u6570\u636e\u5c0f\u6279\u91cf\u7684\u53ef\u89c6\u7f51\u683c\u3002\u4e0b\u9762\uff0c\u6211\u4eec\u5728``SummaryWriter``\u4e0a\u4f7f\u7528``add_image()``\u8c03\u7528\u6765\u8bb0\u5f55\u56fe\u50cf\uff0c\u4ee5\u4f9bTensorBoard\u4f7f\u7528\uff0c\u6211\u4eec\u8fd8\u8c03\u7528``flush()``\u4ee5\u786e\u4fdd\u5b83\u7acb\u5373\u5199\u5165\u78c1\u76d8\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u9ed8\u8ba4log_dir\u53c2\u6570\u4e3a\"runs\" - \u4f46\u6700\u597d\u660e\u786e\u6307\u5b9a\n# torch.utils.tensorboard.SummaryWriter\u5728\u4e0a\u9762\u5bfc\u5165\nwriter = SummaryWriter('runs/fashion_mnist_experiment_1')\n\n# \u5c06\u56fe\u50cf\u6570\u636e\u5199\u5165TensorBoard\u65e5\u5fd7\u76ee\u5f55\nwriter.add_image('Four Fashion-MNIST Images', img_grid)\nwriter.flush()\n\n# \u8981\u67e5\u770b\uff0c\u8bf7\u5728\u547d\u4ee4\u884c\u4e0a\u542f\u52a8TensorBoard\uff1a\n#   tensorboard --logdir=runs\n# ...\u5e76\u5728\u65b0\u7684\u6d4f\u89c8\u5668\u9009\u9879\u5361\u4e2d\u6253\u5f00http://localhost:6006/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u679c\u60a8\u5728\u547d\u4ee4\u884c\u542f\u52a8TensorBoard\u5e76\u5728\u65b0\u7684\u6d4f\u89c8\u5668\u9009\u9879\u5361\u4e2d\u6253\u5f00\u5b83\uff08\u901a\u5e38\u5728[localhost:6006](localhost:6006)_\uff09\uff0c\u60a8\u5e94\u8be5\u5728IMAGES\u9009\u9879\u5361\u4e0b\u770b\u5230\u56fe\u50cf\u7f51\u683c\u3002\n\n## \u7ed8\u5236\u6807\u91cf\u4ee5\u53ef\u89c6\u5316\u8bad\u7ec3\n\nTensorBoard\u5bf9\u4e8e\u8ddf\u8e2a\u8bad\u7ec3\u7684\u8fdb\u5ea6\u548c\u6548\u679c\u5f88\u6709\u7528\u3002\u4e0b\u9762\uff0c\u6211\u4eec\u5c06\u8fd0\u884c\u4e00\u4e2a\u8bad\u7ec3\u5faa\u73af\uff0c\u8ddf\u8e2a\u4e00\u4e9b\u6307\u6807\uff0c\u5e76\u4fdd\u5b58\u6570\u636e\u4ee5\u4f9bTensorBoard\u4f7f\u7528\u3002\n\n\u8ba9\u6211\u4eec\u5b9a\u4e49\u4e00\u4e2a\u6a21\u578b\u6765\u5bf9\u6211\u4eec\u7684\u56fe\u50cf\u74e6\u7247\u8fdb\u884c\u5206\u7c7b\uff0c\u4ee5\u53ca\u7528\u4e8e\u8bad\u7ec3\u7684\u4f18\u5316\u5668\u548c\u635f\u5931\u51fd\u6570\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n\nnet = Net()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\u8ba9\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2aepoch\uff0c\u5e76\u6bcf1000\u6279\u6b21\u8bc4\u4f30\u4e00\u6b21\u8bad\u7ec3\u4e0e\u9a8c\u8bc1\u96c6\u7684\u635f\u5931\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(len(validation_loader))\nfor epoch in range(1):  # \u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u591a\u6b21\n    running_loss = 0.0\n\n    for i, data in enumerate(training_loader, 0):\n        # \u57fa\u672c\u8bad\u7ec3\u5faa\u73af\n        inputs, labels = data\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 1000 == 999:    # \u6bcf1000\u4e2a\u5c0f\u6279\u91cf...\n            print('Batch {}'.format(i + 1))\n            # \u5bf9\u7167\u9a8c\u8bc1\u96c6\n            running_vloss = 0.0\n            \n            # \u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0c\u53ef\u4ee5\u7701\u7565\u4e00\u4e9b\u7279\u5b9a\u4e8e\u6a21\u578b\u7684\u64cd\u4f5c\uff0c\u4f8b\u5982dropout\u5c42\n            net.train(False) # \u5207\u6362\u5230\u8bc4\u4f30\u6a21\u5f0f\uff0c\u4f8b\u5982\u5173\u95ed\u6b63\u5219\u5316\n            for j, vdata in enumerate(validation_loader, 0):\n                vinputs, vlabels = vdata\n                voutputs = net(vinputs)\n                vloss = criterion(voutputs, vlabels)\n                running_vloss += vloss.item()\n            net.train(True) # \u5207\u6362\u56de\u8bad\u7ec3\u6a21\u5f0f\uff0c\u4f8b\u5982\u6253\u5f00\u6b63\u5219\u5316\n            \n            avg_loss = running_loss / 1000\n            avg_vloss = running_vloss / len(validation_loader)\n            \n            # \u8bb0\u5f55\u6bcf\u6279\u6b21\u5e73\u5747\u7684\u8fd0\u884c\u635f\u5931\n            writer.add_scalars('Training vs. Validation Loss',\n                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n                            epoch * len(training_loader) + i)\n\n            running_loss = 0.0\nprint('Finished Training')\n\nwriter.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5207\u6362\u5230\u60a8\u6253\u5f00\u7684TensorBoard\uff0c\u67e5\u770bSCALARS\u9009\u9879\u5361\u3002\n\n## \u53ef\u89c6\u5316\u60a8\u7684\u6a21\u578b\n\nTensorBoard\u8fd8\u53ef\u7528\u4e8e\u68c0\u67e5\u6a21\u578b\u5185\u7684\u6570\u636e\u6d41\u3002\u4e3a\u6b64\uff0c\u8bf7\u4f7f\u7528\u6a21\u578b\u548c\u793a\u4f8b\u8f93\u5165\u8c03\u7528``add_graph()``\u65b9\u6cd5\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u518d\u6b21\u83b7\u53d6\u4e00\u4e2a\u5c0f\u6279\u91cf\u7684\u56fe\u50cf\ndataiter = iter(training_loader)\nimages, labels = next(dataiter)\n\n# add_graph()\u5c06\u901a\u8fc7\u60a8\u7684\u6a21\u578b\u8ddf\u8e2a\u793a\u4f8b\u8f93\u5165\uff0c\n# \u5e76\u5c06\u5176\u6e32\u67d3\u4e3a\u56fe\u5f62\u3002\nwriter.add_graph(net, images)\nwriter.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5f53\u60a8\u5207\u6362\u5230TensorBoard\u65f6\uff0c\u60a8\u5e94\u8be5\u4f1a\u770b\u5230\u4e00\u4e2aGRAPHS\u9009\u9879\u5361\u3002\u53cc\u51fb\"NET\"\u8282\u70b9\u53ef\u67e5\u770b\u6a21\u578b\u5185\u7684\u5c42\u548c\u6570\u636e\u6d41\u3002\n\n## \u4f7f\u7528\u5d4c\u5165\u53ef\u89c6\u5316\u60a8\u7684\u6570\u636e\u96c6\n\n\u6211\u4eec\u4f7f\u7528\u768428x28\u56fe\u50cf\u74e6\u7247\u53ef\u4ee5\u5efa\u6a21\u4e3a784\u7ef4\u5411\u91cf\uff0828 * 28 = 784\uff09\u3002\u5c06\u5176\u6295\u5f71\u5230\u8f83\u4f4e\u7ef4\u5ea6\u7684\u8868\u793a\u5f62\u5f0f\u53ef\u80fd\u4f1a\u5f88\u6709\u542f\u53d1\u6027\u3002``add_embedding()``\u65b9\u6cd5\u5c06\u4e00\u7ec4\u6570\u636e\u6295\u5f71\u5230\u5177\u6709\u6700\u9ad8\u65b9\u5dee\u7684\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\uff0c\u5e76\u5c06\u5b83\u4eec\u663e\u793a\u4e3a\u4ea4\u4e92\u5f0f3D\u56fe\u8868\u3002``add_embedding()``\u65b9\u6cd5\u901a\u8fc7\u6295\u5f71\u5230\u5177\u6709\u6700\u9ad8\u65b9\u5dee\u7684\u4e09\u4e2a\u7ef4\u5ea6\u6765\u81ea\u52a8\u6267\u884c\u6b64\u64cd\u4f5c\u3002\n\n\u4e0b\u9762\uff0c\u6211\u4eec\u5c06\u91c7\u6837\u6570\u636e\uff0c\u5e76\u751f\u6210\u8fd9\u6837\u4e00\u4e2a\u5d4c\u5165\uff1a\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u9009\u62e9\u968f\u673a\u5b50\u96c6\u7684\u6570\u636e\u548c\u76f8\u5e94\u7684\u6807\u7b7e\ndef select_n_random(data, labels, n=100):\n    assert len(data) == len(labels)\n\n    perm = torch.randperm(len(data))\n    return data[perm][:n], labels[perm][:n]\n\n# \u63d0\u53d6\u968f\u673a\u5b50\u96c6\u7684\u6570\u636e\nimages, labels = select_n_random(training_set.data, training_set.targets)\n\n# \u83b7\u53d6\u6bcf\u4e2a\u56fe\u50cf\u7684\u7c7b\u6807\u7b7e\nclass_labels = [classes[label] for label in labels]\n\n# \u8bb0\u5f55\u5d4c\u5165\nfeatures = images.view(-1, 28 * 28)\nwriter.add_embedding(features,\n                    metadata=class_labels,\n                    label_img=images.unsqueeze(1))\nwriter.flush()\nwriter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u73b0\u5728\uff0c\u5982\u679c\u60a8\u5207\u6362\u5230TensorBoard\u5e76\u9009\u62e9PROJECTOR\u9009\u9879\u5361\uff0c\u60a8\u5e94\u8be5\u4f1a\u770b\u5230\u6295\u5f71\u76843D\u8868\u793a\u3002\u60a8\u53ef\u4ee5\u65cb\u8f6c\u548c\u7f29\u653e\u6a21\u578b\u3002\u5728\u5927\u5c0f\u4e0d\u540c\u7684\u5c3a\u5ea6\u4e0a\u68c0\u67e5\u5b83\uff0c\u770b\u770b\u60a8\u662f\u5426\u53ef\u4ee5\u53d1\u73b0\u6295\u5f71\u6570\u636e\u548c\u6807\u7b7e\u805a\u7c7b\u4e2d\u7684\u6a21\u5f0f\u3002\n\n\u4e3a\u4e86\u66f4\u597d\u7684\u53ef\u89c1\u6027\uff0c\u5efa\u8bae\uff1a\n\n- \u4ece\u5de6\u4fa7\u7684\"Color by\"\u4e0b\u62c9\u83dc\u5355\u4e2d\u9009\u62e9\"label\"\u3002\n- \u5207\u6362\u9876\u90e8\u7684Night Mode\u56fe\u6807\uff0c\u5c06\u6d45\u8272\u56fe\u50cf\u7f6e\u4e8e\u6df1\u8272\u80cc\u666f\u4e0a\u3002\n\n## \u5176\u4ed6\u8d44\u6e90\n\n\u6709\u5173\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u67e5\u770b\uff1a\n\n- PyTorch\u5173\u4e8e[torch.utils.tensorboard.SummaryWriter](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter)_\u7684\u6587\u6863\n- [PyTorch.org\u6559\u7a0b](https://pytorch.org/tutorials/)_ \u4e2d\u7684TensorBoard\u6559\u7a0b\u5185\u5bb9\n- \u6709\u5173TensorBoard\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605[TensorBoard\u6587\u6863](https://www.tensorflow.org/tensorboard)_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}