{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\u57fa\u7840\u77e5\u8bc6](intro.html) ||\n[\u5feb\u901f\u5165\u95e8](quickstart_tutorial.html) ||\n[\u5f20\u91cf](tensorqs_tutorial.html) ||\n[\u6570\u636e\u96c6\u4e0e\u6570\u636e\u52a0\u8f7d\u5668](data_tutorial.html) ||\n[Transforms](transforms_tutorial.html) ||\n[\u6784\u5efa\u795e\u7ecf\u7f51\u7edc](buildmodel_tutorial.html) ||\n**\u81ea\u52a8\u5fae\u5206** ||\n[\u4f18\u5316\u6a21\u578b\u53c2\u6570](optimization_tutorial.html) ||\n[\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b](saveloadrun_tutorial.html)\n\n# \u81ea\u52a8\u5fae\u5206\n\n\u5728\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u6700\u5e38\u7528\u7684\u7b97\u6cd5\u662f**\u53cd\u5411\u4f20\u64ad**\u3002\n\u5728\u8fd9\u4e2a\u7b97\u6cd5\u4e2d\uff0c\u53c2\u6570\uff08\u6a21\u578b\u6743\u91cd\uff09\u6839\u636e\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u4e8e\u7ed9\u5b9a\u53c2\u6570\u7684**\u68af\u5ea6**\u8fdb\u884c\u8c03\u6574\u3002\n\n\u4e3a\u4e86\u8ba1\u7b97\u8fd9\u4e9b\u68af\u5ea6\uff0cPyTorch \u63d0\u4f9b\u4e86\u4e00\u4e2a\u5185\u7f6e\u7684\u5fae\u5206\u5f15\u64ce\uff0c\u79f0\u4e3a ``torch.autograd``\u3002\n\u5b83\u652f\u6301\u5bf9\u4efb\u4f55\u8ba1\u7b97\u56fe\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\u3002\n\n\u8003\u8651\u6700\u7b80\u5355\u7684\u5355\u5c42\u795e\u7ecf\u7f51\u7edc\uff0c\u5177\u6709\u8f93\u5165 ``x``\u3001\u53c2\u6570 ``w`` \u548c ``b``\uff0c\u4ee5\u53ca\u4e00\u4e9b\u635f\u5931\u51fd\u6570\u3002\n\u53ef\u4ee5\u5728 PyTorch \u4e2d\u6309\u4ee5\u4e0b\u65b9\u5f0f\u5b9a\u4e49\u5b83\uff1a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nx = torch.ones(5)  # input tensor\ny = torch.zeros(3)  # expected output\nw = torch.randn(5, 3, requires_grad=True)\nb = torch.randn(3, requires_grad=True)\nz = torch.matmul(x, w)+b\nloss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5f20\u91cf\u3001\u51fd\u6570\u548c\u8ba1\u7b97\u56fe\n\n\u8fd9\u6bb5\u4ee3\u7801\u5b9a\u4e49\u4e86\u4ee5\u4e0b**\u8ba1\u7b97\u56fe**:\n\n.. figure:: /_static/img/basics/comp-graph.png\n   :alt:\n\n\u5728\u8fd9\u4e2a\u7f51\u7edc\u4e2d\uff0c``w`` \u548c ``b`` \u662f**\u53c2\u6570**\uff0c\u6211\u4eec\u9700\u8981\u5bf9\u5b83\u4eec\u8fdb\u884c\u4f18\u5316\u3002\n\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u80fd\u591f\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u4e8e\u8fd9\u4e9b\u53d8\u91cf\u7684\u68af\u5ea6\u3002\u4e3a\u4e86\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\n\u6211\u4eec\u8bbe\u7f6e\u4e86\u8fd9\u4e9b\u5f20\u91cf\u7684 ``requires_grad`` \u5c5e\u6027\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. \u63d0\u793a:: \u53ef\u5728\u521b\u5efatensor\u7684\u65f6\u5019\u914d\u7f6e ``requires_grad`` \u53c2\u6570,\n\u6216\u5728\u521b\u5efa\u540e\u4f7f\u7528 ``x.requires_grad_(True)`` \u65b9\u6cd5\u6765\u8bbe\u7f6e\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u5e94\u7528\u4e8e\u5f20\u91cf\u4ee5\u6784\u5efa\u8ba1\u7b97\u56fe\u7684\u51fd\u6570\u5b9e\u9645\u4e0a\u662f ``Function`` \u7c7b\u7684\u5bf9\u8c61\u3002\n\u8fd9\u4e2a\u5bf9\u8c61\u77e5\u9053\u5982\u4f55\u5728*\u524d\u5411*\u65b9\u5411\u8ba1\u7b97\u51fd\u6570\uff0c\u4e5f\u77e5\u9053\u5982\u4f55\u5728*\u53cd\u5411\u4f20\u64ad*\u6b65\u9aa4\u4e2d\u8ba1\u7b97\u5176\u5bfc\u6570\u3002\n\u5bf9\u4e8e\u53cd\u5411\u4f20\u64ad\u51fd\u6570\u7684\u5f15\u7528\u5b58\u50a8\u5728\u5f20\u91cf\u7684 ``grad_fn``` \u5c5e\u6027\u4e2d\u3002\n\u60a8\u53ef\u4ee5\u5728[\u6587\u6863](https://pytorch.org/docs/stable/autograd.html#function)_ \u4e2d\u627e\u5230\u6709\u5173 ``Function`` \u7684\u66f4\u591a\u4fe1\u606f\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\nprint(f\"Gradient function for loss = {loss.grad_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u8ba1\u7b97\u68af\u5ea6\n\n\u4e3a\u4e86\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u53c2\u6570\u6743\u91cd\uff0c\u6211\u4eec\u9700\u8981\u8ba1\u7b97\u635f\u5931\u51fd\u6570\u76f8\u5bf9\u4e8e\u53c2\u6570\u7684\u5bfc\u6570\uff0c\n\u5373\u5728\u67d0\u4e9b\u56fa\u5b9a\u7684 ``x`` \u548c ``y`` \u503c\u4e0b\uff0c\u6211\u4eec\u9700\u8981 `\\frac{\\partial loss}{\\partial w}`\n\u548c `\\frac{\\partial loss}{\\partial b}`\u3002\u8981\u8ba1\u7b97\u8fd9\u4e9b\u5bfc\u6570\uff0c\u6211\u4eec\u8c03\u7528 ``loss.backward()``\uff0c\n\u7136\u540e\u4ece ``w.grad`` \u548c ``b.grad`` \u4e2d\u68c0\u7d22\u503c\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss.backward()\nprint(w.grad)\nprint(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. \u63d0\u793a::\n  - \u6211\u4eec\u53ea\u80fd\u83b7\u53d6\u8ba1\u7b97\u56fe\u7684\u53f6\u8282\u70b9 ``grad`` \u5c5e\u6027\uff0c\u8fd9\u4e9b\u53f6\u8282\u70b9\u7684 ``requires_grad`` \u5c5e\u6027\u8bbe\u7f6e\u4e3a ``True``\u3002\n    \u5bf9\u4e8e\u8ba1\u7b97\u56fe\u4e2d\u7684\u6240\u6709\u5176\u4ed6\u8282\u70b9\uff0c\u68af\u5ea6\u5c06\u4e0d\u53ef\u7528\u3002\n  - \u51fa\u4e8e\u6027\u80fd\u539f\u56e0\uff0c\u6211\u4eec\u53ea\u80fd\u5728\u7ed9\u5b9a\u7684\u8ba1\u7b97\u56fe\u4e0a\u6267\u884c\u4e00\u6b21 ``backward`` \u68af\u5ea6\u8ba1\u7b97\u3002\u5982\u679c\u6211\u4eec\u9700\u8981\u5728\u540c\u4e00\u56fe\u4e0a\u8fdb\u884c\u591a\u6b21\n    ``backward`` \u8c03\u7528\uff0c\u6211\u4eec\u9700\u8981\u5728 ``backward`` \u8c03\u7528\u4e2d\u4f20\u9012 ``retain_graph=True``\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u7981\u7528\u68af\u5ea6\u8ddf\u8e2a\n\n\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u5177\u6709 ``requires_grad=True`` \u7684\u5f20\u91cf\u90fd\u5728\u8ddf\u8e2a\u5b83\u4eec\u7684\u8ba1\u7b97\u5386\u53f2\u5e76\u652f\u6301\u68af\u5ea6\u8ba1\u7b97\u3002\n\u7136\u800c\uff0c\u6709\u4e9b\u60c5\u51b5\u4e0b\u6211\u4eec\u4e0d\u9700\u8981\u8fd9\u6837\u505a\uff0c\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u5df2\u7ecf\u8bad\u7ec3\u597d\u6a21\u578b\u5e76\u53ea\u60f3\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u4e9b\u8f93\u5165\u6570\u636e\u65f6\uff0c\n\u5373\u6211\u4eec\u53ea\u60f3\u901a\u8fc7\u7f51\u7edc\u8fdb\u884c*\u524d\u5411*\u8ba1\u7b97\u3002\n\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5c06\u6211\u4eec\u7684\u8ba1\u7b97\u4ee3\u7801\u5305\u88f9\u5728 ``torch.no_grad()`` \u5757\u4e2d\u6765\u505c\u6b62\u8ddf\u8e2a\u8ba1\u7b97\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.matmul(x, w)+b\nprint(z.requires_grad)\n\nwith torch.no_grad():\n    z = torch.matmul(x, w)+b\nprint(z.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u53e6\u4e00\u79cd\u5b9e\u73b0\u76f8\u540c\u7ed3\u679c\u7684\u65b9\u6cd5\u662f\u5bf9\u5f20\u91cf\u4f7f\u7528 ``detach()`` \u65b9\u6cd5\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.matmul(x, w)+b\nz_det = z.detach()\nprint(z_det.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5e0c\u671b\u7981\u7528\u68af\u5ea6\u8ddf\u8e2a\u7684\u539f\u56e0\u53ef\u80fd\u5982\u4e0b\uff1a\n- \u5c06\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u67d0\u4e9b\u53c2\u6570\u6807\u8bb0\u4e3a**\u51bb\u7ed3\u53c2\u6570**\u3002\n- \u5728\u4ec5\u8fdb\u884c\u524d\u5411\u4f20\u9012\u65f6**\u52a0\u901f\u8ba1\u7b97**\uff0c\u56e0\u4e3a\u4e0d\u8ddf\u8e2a\u68af\u5ea6\u7684\u5f20\u91cf\u4e0a\u7684\u8ba1\u7b97\u4f1a\u66f4\u9ad8\u6548\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u66f4\u591a\u5173\u4e8e\u8ba1\u7b97\u56fe\n\n\u6982\u5ff5\u4e0a\uff0cautograd \u5728\u4e00\u4e2a\u7531 [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)_ \u5bf9\u8c61\n\u7ec4\u6210\u7684\u6709\u5411\u65e0\u73af\u56fe (DAG) \u4e2d\u8bb0\u5f55\u6570\u636e\uff08\u5f20\u91cf\uff09\u548c\u6240\u6709\u6267\u884c\u7684\u64cd\u4f5c\uff08\u4ee5\u53ca\u4ea7\u751f\u7684\u65b0\u5f20\u91cf\uff09\u3002\n\u5728\u8fd9\u4e2a DAG \u4e2d\uff0c\u53f6\u5b50\u8282\u70b9\u662f\u8f93\u5165\u5f20\u91cf\uff0c\u6839\u8282\u70b9\u662f\u8f93\u51fa\u5f20\u91cf\u3002\u901a\u8fc7\u4ece\u6839\u5230\u53f6\u8ddf\u8e2a\u8fd9\u4e2a\u56fe\uff0c\u53ef\u4ee5\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\u81ea\u52a8\u8ba1\u7b97\u68af\u5ea6\u3002\n\n\u5728\u524d\u5411\u4f20\u9012\u4e2d\uff0cautograd \u540c\u65f6\u505a\u4e24\u4ef6\u4e8b\uff1a\n\n- \u6267\u884c\u8bf7\u6c42\u7684\u64cd\u4f5c\u4ee5\u8ba1\u7b97\u7ed3\u679c\u5f20\u91cf\n- \u5728 DAG \u4e2d\u7ef4\u62a4\u64cd\u4f5c\u7684*\u68af\u5ea6\u51fd\u6570*\u3002\n\n\u5f53\u5728 DAG \u6839\u8282\u70b9\u4e0a\u8c03\u7528 ``.backward()`` \u65f6\uff0c\u53cd\u5411\u4f20\u9012\u5f00\u59cb\u3002\u7136\u540e\uff0c``autograd``\uff1a\n\n- \u4ece\u6bcf\u4e2a ```.grad_fn``` \u8ba1\u7b97\u68af\u5ea6\uff0c\n- \u5c06\u5b83\u4eec\u7d2f\u79ef\u5230\u5404\u81ea\u5f20\u91cf\u7684 ```.grad`` \u5c5e\u6027\u4e2d\uff0c\n- \u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\uff0c\u4e00\u76f4\u4f20\u64ad\u5230\u53f6\u5b50\u5f20\u91cf\u3002\n\n.. \u63d0\u793a::\n  **PyTorch\u4e2d\u7684DAGs \u662f\u52a8\u6001\u7684**\n  \u9700\u8981\u6ce8\u610f\u7684\u4e00\u70b9\u662f\uff0c\u8ba1\u7b97\u56fe\u662f\u4ece\u5934\u5f00\u59cb\u91cd\u65b0\u521b\u5efa\u7684\uff1b\u5728\u6bcf\u6b21\u8c03\u7528\n  ``.backward()`` \u4e4b\u540e\uff0cautograd \u4f1a\u5f00\u59cb\u586b\u5145\u4e00\u4e2a\u65b0\u7684\u8ba1\u7b97\u56fe\u3002\n  \u8fd9\u6b63\u662f\u5141\u8bb8\u60a8\u5728\u6a21\u578b\u4e2d\u4f7f\u7528\u63a7\u5236\u6d41\u8bed\u53e5\u7684\u539f\u56e0\uff1b\u5982\u679c\u9700\u8981\uff0c\u60a8\u53ef\u4ee5\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u66f4\u6539\u5f62\u72b6\u3001\u5927\u5c0f\u548c\u64cd\u4f5c\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u53ef\u9009\u9605\u8bfb\uff1a\u5f20\u91cf\u68af\u5ea6(Tensor Gradients)\u548c\u96c5\u53ef\u6bd4\u4e58\u79ef(Jacobian Products)\n\n\u5728\u5f88\u591a\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u6807\u91cf\u635f\u5931\u51fd\u6570\uff0c\u9700\u8981\u8ba1\u7b97\u76f8\u5bf9\u4e8e\u67d0\u4e9b\u53c2\u6570\u7684\u68af\u5ea6\u3002\n\u7136\u800c\uff0c\u4e5f\u6709\u4e00\u4e9b\u60c5\u51b5\u4e0b\uff0c\u8f93\u51fa\u51fd\u6570\u662f\u4e00\u4e2a\u4efb\u610f\u7684\u5f20\u91cf\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cPyTorch \u5141\u8bb8\u60a8\u8ba1\u7b97\u6240\u8c13\u7684**\u96c5\u53ef\u6bd4\u4e58\u79ef**\uff0c\n\u800c\u4e0d\u662f\u5b9e\u9645\u7684\u68af\u5ea6\u3002\n\nFor a vector function $\\vec{y}=f(\\vec{x})$, where\n$\\vec{x}=\\langle x_1,\\dots,x_n\\rangle$ and\n$\\vec{y}=\\langle y_1,\\dots,y_m\\rangle$, a gradient of\n$\\vec{y}$ with respect to $\\vec{x}$ is given by **Jacobian\nmatrix**:\n\n\\begin{align}J=\\left(\\begin{array}{ccc}\n      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n      \\vdots & \\ddots & \\vdots\\\\\n      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n      \\end{array}\\right)\\end{align}\n\nInstead of computing the Jacobian matrix itself, PyTorch allows you to\ncompute **Jacobian Product** $v^T\\cdot J$ for a given input vector\n$v=(v_1 \\dots v_m)$. This is achieved by calling ``backward`` with\n$v$ as an argument. The size of $v$ should be the same as\nthe size of the original tensor, with respect to which we want to\ncompute the product:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)\nout = (inp+1).pow(2).t()\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"First call\\n{inp.grad}\")\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"\\nSecond call\\n{inp.grad}\")\ninp.grad.zero_()\nout.backward(torch.ones_like(out), retain_graph=True)\nprint(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that when we call ``backward`` for the second time with the same\nargument, the value of the gradient is different. This happens because\nwhen doing ``backward`` propagation, PyTorch **accumulates the\ngradients**, i.e. the value of computed gradients is added to the\n``grad`` property of all leaf nodes of computational graph. If you want\nto compute the proper gradients, you need to zero out the ``grad``\nproperty before. In real-life training an *optimizer* helps us to do\nthis.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Previously we were calling ``backward()`` function without\n          parameters. This is essentially equivalent to calling\n          ``backward(torch.tensor(1.0))``, which is a useful way to compute the\n          gradients in case of a scalar-valued function, such as loss during\n          neural network training.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Further Reading\n- [Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}