{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n**\u7b80\u4ecb** ||\n[\u5f20\u91cf](tensors_deeper_tutorial.html) ||\n[\u81ea\u52a8\u5fae\u5206](autogradyt_tutorial.html) ||\n[\u6784\u5efa\u6a21\u578b](modelsyt_tutorial.html) ||\n[TensorBoard\u652f\u6301](tensorboardyt_tutorial.html) ||\n[\u8bad\u7ec3\u6a21\u578b](trainingyt.html) ||\n[\u6a21\u578b\u7406\u89e3](captumyt.html)\n\n# PyTorch \u7b80\u4ecb\n\n\u8ddf\u968f\u4e0b\u9762\u7684\u89c6\u9891\u6216\u5728 [youtube](https://www.youtube.com/watch?v=IC0_FRiX-sw)_ \u4e0a\u89c2\u770b\u3002\n\n.. raw:: html\n\n   <div style=\"margin-top:10px; margin-bottom:10px;\">\n     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IC0_FRiX-sw\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n   </div>\n\n## PyTorch \u5f20\u91cf\n\n\u4ece\u89c6\u9891\u7684 [03:50](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=230s)_ \u5f00\u59cb\u3002\n\n\u9996\u5148\uff0c\u6211\u4eec\u5c06\u5bfc\u5165 pytorch\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8ba9\u6211\u4eec\u770b\u4e00\u4e9b\u57fa\u672c\u7684\u5f20\u91cf\u64cd\u4f5c\u3002\u9996\u5148\uff0c\u521b\u5efa\u5f20\u91cf\u7684\u51e0\u79cd\u65b9\u5f0f:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = torch.zeros(5, 3)\nprint(z)\nprint(z.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e0a\u9762\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a 5x3 \u7684\u96f6\u77e9\u9635\uff0c\u5e76\u67e5\u8be2\u5176\u6570\u636e\u7c7b\u578b\uff0c\u53d1\u73b0\u96f6\u662f 32 \u4f4d\u6d6e\u70b9\u6570\uff0c\u8fd9\u662f PyTorch \u7684\u9ed8\u8ba4\u8bbe\u7f6e\u3002\n\n\u5982\u679c\u4f60\u60f3\u8981\u6574\u6570\u5462?\u53ef\u4ee5\u8986\u76d6\u9ed8\u8ba4\u8bbe\u7f6e:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "i = torch.ones((5, 3), dtype=torch.int16)\nprint(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4f60\u53ef\u4ee5\u770b\u5230\uff0c\u5f53\u6211\u4eec\u6539\u53d8\u9ed8\u8ba4\u8bbe\u7f6e\u65f6\uff0c\u5728\u6253\u5370\u5f20\u91cf\u65f6\u4f1a\u6709\u6240\u63d0\u793a\u3002\n\n\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4f1a\u4f7f\u7528\u7279\u5b9a\u7684\u79cd\u5b50\u521d\u59cb\u5316\u5b66\u4e60\u6743\u91cd\uff0c\u4ee5\u786e\u4fdd\u7ed3\u679c\u7684\u53ef\u91cd\u590d\u6027:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1729)\nr1 = torch.rand(2, 2)\nprint('A random tensor:')\nprint(r1)\n\nr2 = torch.rand(2, 2)\nprint('\\nA different random tensor:')\nprint(r2) # \u65b0\u7684\u503c\n\ntorch.manual_seed(1729)\nr3 = torch.rand(2, 2)\nprint('\\nShould match r1:')\nprint(r3) # \u7531\u4e8e\u91cd\u65b0\u8bbe\u7f6e\u79cd\u5b50\uff0c\u6240\u4ee5\u4e0e r1 \u7684\u503c\u76f8\u540c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch \u5f20\u91cf\u6267\u884c\u7b97\u672f\u8fd0\u7b97\u5f88\u76f4\u89c2\u3002\u5f62\u72b6\u76f8\u4f3c\u7684\u5f20\u91cf\u53ef\u4ee5\u76f8\u52a0\u3001\u76f8\u4e58\u7b49\u3002\n\u4e0e\u6807\u91cf\u7684\u8fd0\u7b97\u4f1a\u5728\u6574\u4e2a\u5f20\u91cf\u4e0a\u5206\u5e03\u5f0f\u8fdb\u884c:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ones = torch.ones(2, 3)\nprint(ones)\n\ntwos = torch.ones(2, 3) * 2 # \u6bcf\u4e2a\u5143\u7d20\u90fd\u4e58\u4ee5 2\nprint(twos)\n\nthrees = ones + twos       # \u5f62\u72b6\u76f8\u4f3c\uff0c\u56e0\u6b64\u5141\u8bb8\u76f8\u52a0\nprint(threes)              # \u5f20\u91cf\u6309\u5143\u7d20\u76f8\u52a0\nprint(threes.shape)        # \u8fd9\u4e0e\u8f93\u5165\u5f20\u91cf\u5177\u6709\u76f8\u540c\u7684\u7ef4\u5ea6\n\nr1 = torch.rand(2, 3)\nr2 = torch.rand(3, 2)\n# \u53d6\u6d88\u6ce8\u91ca\u8fd9\u4e00\u884c\u4f1a\u5bfc\u81f4\u8fd0\u884c\u65f6\u9519\u8bef\n# r3 = r1 + r2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u91cc\u662f\u4e00\u4e9b\u53ef\u7528\u7684\u6570\u5b66\u8fd0\u7b97\u793a\u4f8b:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r = (torch.rand(2, 2) - 0.5) * 2 # \u503c\u5728 -1 \u548c 1 \u4e4b\u95f4\nprint('A random matrix, r:')\nprint(r)\n\n# \u652f\u6301\u5e38\u89c1\u7684\u6570\u5b66\u8fd0\u7b97:\nprint('\\nAbsolute value of r:')\nprint(torch.abs(r))\n\n# ...\u4ee5\u53ca\u4e09\u89d2\u51fd\u6570:\nprint('\\nInverse sine of r:')\nprint(torch.asin(r))\n\n# ...\u548c\u7ebf\u6027\u4ee3\u6570\u8fd0\u7b97\uff0c\u5982\u884c\u5217\u5f0f\u548c\u5947\u5f02\u503c\u5206\u89e3\nprint('\\nDeterminant of r:')\nprint(torch.det(r))\nprint('\\nSingular value decomposition of r:')\nprint(torch.svd(r))\n\n# ...\u4ee5\u53ca\u7edf\u8ba1\u548c\u805a\u5408\u8fd0\u7b97:\nprint('\\nAverage and standard deviation of r:')\nprint(torch.std_mean(r))\nprint('\\nMaximum value of r:')\nprint(torch.max(r))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5173\u4e8e PyTorch \u5f20\u91cf\u7684\u5f3a\u5927\u529f\u80fd\u8fd8\u6709\u5f88\u591a\u9700\u8981\u4e86\u89e3\uff0c\u5305\u62ec\u5982\u4f55\u4e3a GPU \u4e0a\u7684\u5e76\u884c\u8ba1\u7b97\u8bbe\u7f6e\u5b83\u4eec - \u6211\u4eec\u5c06\u5728\u53e6\u4e00\u4e2a\u89c6\u9891\u4e2d\u6df1\u5165\u63a2\u8ba8\u3002\n\n## PyTorch \u6a21\u578b\n\n\u4ece\u89c6\u9891\u7684 [10:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=600s)_ \u5f00\u59cb\u3002\n\n\u8ba9\u6211\u4eec\u8ba8\u8bba\u4e00\u4e0b\u5982\u4f55\u5728 PyTorch \u4e2d\u8868\u793a\u6a21\u578b\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch                     \nimport torch.nn as nn            # PyTorch \u6a21\u578b\u7684\u7236\u5bf9\u8c61\nimport torch.nn.functional as F  # \u7528\u4e8e\u6fc0\u6d3b\u51fd\u6570"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure:: /_static/img/mnist.png\n   :alt: le-net-5 diagram\n\n*\u56fe: LeNet-5*\n\n\u4e0a\u56fe\u662f LeNet-5 \u7684\u793a\u610f\u56fe\uff0c\u5b83\u662f\u6700\u65e9\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e4b\u4e00\uff0c\u4e5f\u662f\u6df1\u5ea6\u5b66\u4e60\u7206\u53d1\u5f0f\u53d1\u5c55\u7684\u9a71\u52a8\u529b\u4e4b\u4e00\u3002\u5b83\u88ab\u6784\u5efa\u7528\u4e8e\u8bfb\u53d6\u624b\u5199\u6570\u5b57\u7684\u5c0f\u56fe\u50cf(MNIST \u6570\u636e\u96c6)\uff0c\u5e76\u6b63\u786e\u5206\u7c7b\u56fe\u50cf\u4e2d\u8868\u793a\u7684\u6570\u5b57\u3002\n\n\u5b83\u5de5\u4f5c\u539f\u7406\u7684\u7b80\u8ff0\u4e3a:\n\n-  \u5c42 C1 \u662f\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u5b83\u5728\u8f93\u5165\u56fe\u50cf\u4e2d\u626b\u63cf\u5b83\u5728\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u5230\u7684\u7279\u5f81\u3002\u5b83\u8f93\u51fa\u4e00\u4e2a\u7279\u5f81\u6fc0\u6d3b\u56fe\uff0c\n   \u63cf\u8ff0\u5b83\u5728\u56fe\u50cf\u4e2d\u770b\u5230\u6bcf\u4e2a\u5b66\u4e60\u5230\u7684\u7279\u5f81\u7684\u4f4d\u7f6e\u3002\u8fd9\u4e2a\"\u6fc0\u6d3b\u56fe\"\u5728\u5c42 S2 \u4e2d\u88ab\u4e0b\u91c7\u6837\u3002\n-  \u5c42 C3 \u662f\u53e6\u4e00\u4e2a\u5377\u79ef\u5c42\uff0c\u8fd9\u6b21\u626b\u63cf C1 \u7684\u6fc0\u6d3b\u56fe\u4ee5\u67e5\u627e\u7279\u5f81\u7ec4\u5408\u3002\u5b83\u4e5f\u8f93\u51fa\u4e00\u4e2a\u6fc0\u6d3b\u56fe\uff0c\n   \u63cf\u8ff0\u8fd9\u4e9b\u7279\u5f81\u7ec4\u5408\u7684\u7a7a\u95f4\u4f4d\u7f6e\uff0c\u8be5\u6fc0\u6d3b\u56fe\u5728\u5c42 S4 \u4e2d\u88ab\u4e0b\u91c7\u6837\u3002\n-  \u6700\u540e\uff0c\u6700\u540e\u7684\u5168\u8fde\u63a5\u5c42 F5\u3001F6 \u548c OUTPUT \u662f\u4e00\u4e2a\u5206\u7c7b\u5668\uff0c\u5b83\u5c06\u6700\u7ec8\u7684\u6fc0\u6d3b\u56fe\u5206\u7c7b\u4e3a 10 \u4e2a bin \u4e2d\u7684\u4e00\u4e2a\uff0c\n   \u8868\u793a 10 \u4e2a\u6570\u5b57\u3002\n\n\u6211\u4eec\u5982\u4f55\u5728\u4ee3\u7801\u4e2d\u8868\u793a\u8fd9\u4e2a\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u5462?\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class LeNet(nn.Module):\n\n    def __init__(self):\n        super(LeNet, self).__init__()\n        # 1 \u4e2a\u8f93\u5165\u56fe\u50cf\u901a\u9053(\u9ed1\u767d)\uff0c6 \u4e2a\u8f93\u51fa\u901a\u9053\uff0c5x5 \u7684\u6b63\u65b9\u5f62\u5377\u79ef\u6838\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # an affine operation: y = Wx + b\n        # \u4e00\u4e2a\u4eff\u5c04\u64cd\u4f5c: y = Wx + b\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # \u5728 (2, 2) \u7a97\u53e3\u4e0a\u8fdb\u884c\u6700\u5927\u6c60\u5316\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # \u5982\u679c\u5c3a\u5bf8\u662f\u6b63\u65b9\u5f62\uff0c\u4f60\u53ea\u9700\u6307\u5b9a\u4e00\u4e2a\u6570\u5b57\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # \u9664\u6279\u6b21\u7ef4\u5ea6\u5916\u7684\u6240\u6709\u7ef4\u5ea6\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u67e5\u770b\u8fd9\u6bb5\u4ee3\u7801\uff0c\u4f60\u5e94\u8be5\u80fd\u591f\u53d1\u73b0\u4e00\u4e9b\u4e0e\u4e0a\u56fe\u7ed3\u6784\u76f8\u4f3c\u7684\u5730\u65b9\u3002\n\n\u8fd9\u6f14\u793a\u4e86\u5178\u578b PyTorch \u6a21\u578b\u7684\u7ed3\u6784: \n\n-  \u5b83\u7ee7\u627f\u81ea ``torch.nn.Module`` - \u6a21\u5757\u53ef\u4ee5\u5d4c\u5957 - \u4e8b\u5b9e\u4e0a\uff0c\u5373\u4f7f ``Conv2d`` \u548c ``Linear`` \u5c42\u7c7b\u4e5f\u7ee7\u627f\u81ea ``torch.nn.Module``\u3002\n-  \u4e00\u4e2a\u6a21\u578b\u5c06\u6709\u4e00\u4e2a ``__init__()`` \u51fd\u6570\uff0c\u5728\u8fd9\u91cc\u5b83\u5b9e\u4f8b\u5316\u5176\u5c42\uff0c\u5e76\u52a0\u8f7d\u4efb\u4f55\u5b83\u53ef\u80fd\u9700\u8981\u7684\u6570\u636e\u7ec4\u4ef6(\u4f8b\u5982\uff0c\u4e00\u4e2a NLP \u6a21\u578b\u53ef\u80fd\u52a0\u8f7d\u8bcd\u6c47\u8868)\u3002\n-  \u4e00\u4e2a\u6a21\u578b\u5c06\u6709\u4e00\u4e2a ``forward()`` \u51fd\u6570\u3002\u8fd9\u662f\u5b9e\u9645\u8ba1\u7b97\u53d1\u751f\u7684\u5730\u65b9:\u8f93\u5165\u901a\u8fc7\u7f51\u7edc\u5c42\u548c\u5404\u79cd\u51fd\u6570\u751f\u6210\u8f93\u51fa\u3002\n-  \u9664\u6b64\u4e4b\u5916\uff0c\u4f60\u53ef\u4ee5\u50cf\u6784\u5efa\u4efb\u4f55\u5176\u4ed6 Python \u7c7b\u4e00\u6837\u6784\u5efa\u4f60\u7684\u6a21\u578b\u7c7b\uff0c\u6dfb\u52a0\u4efb\u4f55\u4f60\u9700\u8981\u652f\u6301\u6a21\u578b\u8ba1\u7b97\u7684\u5c5e\u6027\u548c\u65b9\u6cd5\u3002\n\n\u8ba9\u6211\u4eec\u5b9e\u4f8b\u5316\u8fd9\u4e2a\u5bf9\u8c61\u5e76\u8fd0\u884c\u4e00\u4e2a\u793a\u4f8b\u8f93\u5165\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = LeNet()\nprint(net)                         # \u5bf9\u8c61\u6253\u5370\u4e86\u4ec0\u4e48\u4fe1\u606f?\n\ninput = torch.rand(1, 1, 32, 32)   # 32x32 \u7684\u9ed1\u767d\u56fe\u50cf\nprint('\\nImage batch shape:')\nprint(input.shape)\n\noutput = net(input)                # \u4e0d\u76f4\u63a5\u8c03\u7528 forward()\nprint('\\nRaw output:')\nprint(output)\nprint(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u4e0a\u4ee3\u7801\u5b58\u5728\u4e00\u4e9b\u8981\u70b9:\n\n\u9996\u5148\uff0c\u6211\u4eec\u5b9e\u4f8b\u5316 ``LeNet`` \u7c7b\uff0c\u5e76\u6253\u5370 ``net`` \u5bf9\u8c61\u3002``torch.nn.Module`` \u7684\u5b50\u7c7b\u5c06\u62a5\u544a\u5b83\u521b\u5efa\u7684\u5c42\u53ca\u5176\u5f62\u72b6\u548c\u53c2\u6570\u3002\n\u8fd9\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u6a21\u578b\u7684\u6982\u89c8\uff0c\u5982\u679c\u4f60\u60f3\u4e86\u89e3\u5b83\u7684\u5904\u7406\u8fc7\u7a0b\u3002\n\n\u5728\u4e0b\u9762\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u865a\u62df\u8f93\u5165\uff0c\u8868\u793a\u4e00\u4e2a 32x32 \u7684\u5355\u901a\u9053\u56fe\u50cf\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0c\u4f60\u4f1a\u52a0\u8f7d\u4e00\u4e2a\u56fe\u50cf\u5207\u7247\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u8fd9\u79cd\u5f62\u72b6\u7684\u5f20\u91cf\u3002\n\n\u4f60\u53ef\u80fd\u5df2\u7ecf\u6ce8\u610f\u5230\u6211\u4eec\u7684\u5f20\u91cf\u6709\u4e00\u4e2a\u989d\u5916\u7684\u7ef4\u5ea6 - *\u6279\u6b21\u7ef4\u5ea6*\u3002PyTorch \u6a21\u578b\u5047\u8bbe\u5b83\u4eec\u6b63\u5728\u5904\u7406\u6570\u636e*\u6279\u6b21* \n- \u4f8b\u5982\uff0c\u5305\u542b 16 \u4e2a\u56fe\u50cf\u5207\u7247\u7684\u6279\u6b21\u5c06\u5177\u6709\u5f62\u72b6 ``(16, 1, 32, 32)``\u3002\n\u7531\u4e8e\u6211\u4eec\u53ea\u4f7f\u7528\u4e00\u4e2a\u56fe\u50cf\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5f62\u72b6\u4e3a ``(1, 1, 32, 32)`` \u7684\u6279\u6b21\u3002\n\n\u6211\u4eec\u901a\u8fc7\u50cf\u51fd\u6570\u4e00\u6837\u8c03\u7528\u5b83\u6765\u8981\u6c42\u6a21\u578b\u8fdb\u884c\u63a8\u7406: ``net(input)``\u3002\u8fd9\u4e2a\u8c03\u7528\u7684\u8f93\u51fa\u8868\u793a\u6a21\u578b\u5bf9\u8f93\u5165\u8868\u793a\u7279\u5b9a\u6570\u5b57\u7684\u7f6e\u4fe1\u5ea6\u3002\n(\u7531\u4e8e\u8fd9\u4e2a\u6a21\u578b\u5b9e\u4f8b\u8fd8\u6ca1\u6709\u5b66\u4e60\u4efb\u4f55\u4e1c\u897f\uff0c\u6211\u4eec\u4e0d\u5e94\u8be5\u671f\u671b\u5728\u8f93\u51fa\u4e2d\u770b\u5230\u4efb\u4f55\u4fe1\u53f7\u3002)\u67e5\u770b ``output`` \u7684\u5f62\u72b6\uff0c\n\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u5b83\u4e5f\u6709\u4e00\u4e2a\u6279\u6b21\u7ef4\u5ea6\uff0c\u5176\u5927\u5c0f\u5e94\u8be5\u59cb\u7ec8\u4e0e\u8f93\u5165\u6279\u6b21\u7ef4\u5ea6\u76f8\u5339\u914d\u3002\u5982\u679c\u6211\u4eec\u4f20\u5165\u4e86\u4e00\u4e2a\u5305\u542b 16 \u4e2a\u5b9e\u4f8b\u7684\u8f93\u5165\u6279\u6b21\uff0c\n``output`` \u5c06\u5177\u6709 ``(16, 10)`` \u7684\u5f62\u72b6\u3002\n\n## \u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\n\n\u4ece\u89c6\u9891\u7684 [14:00](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=840s)_ \u5f00\u59cb\u3002\n\n\u4e0b\u9762\uff0c\u6211\u4eec\u5c06\u6f14\u793a\u5982\u4f55\u4f7f\u7528 TorchVision \u4e2d\u7684\u4e00\u4e2a\u53ef\u4e0b\u8f7d\u7684\u5f00\u653e\u8bbf\u95ee\u6570\u636e\u96c6\uff0c\n\u5982\u4f55\u8f6c\u6362\u56fe\u50cf\u4ee5\u4f9b\u4f60\u7684\u6a21\u578b\u4f7f\u7528\uff0c\u4ee5\u53ca\u5982\u4f55\u4f7f\u7528 DataLoader \u5c06\u6570\u636e\u6279\u6b21\u63d0\u4f9b\u7ed9\u4f60\u7684\u6a21\u578b\u3002\n\n\u6211\u4eec\u9700\u8981\u505a\u7684\u7b2c\u4e00\u4ef6\u4e8b\u662f\u5c06\u4f20\u5165\u7684\u56fe\u50cf\u8f6c\u6362\u4e3a PyTorch \u5f20\u91cf\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u4e3a\u8f93\u5165\u6307\u5b9a\u4e86\u4e24\u79cd\u8f6c\u6362:\n\n-  ``transforms.ToTensor()`` \u5c06 Pillow \u52a0\u8f7d\u7684\u56fe\u50cf\u8f6c\u6362\u4e3a PyTorch \u5f20\u91cf\u3002\n-  ``transforms.Normalize()`` \u8c03\u6574\u5f20\u91cf\u7684\u503c\uff0c\u4f7f\u5176\u5e73\u5747\u503c\u4e3a\u96f6\uff0c\u6807\u51c6\u5dee\u4e3a 1.0\u3002\n   \u5927\u591a\u6570\u6fc0\u6d3b\u51fd\u6570\u5728 x = 0 \u9644\u8fd1\u5177\u6709\u6700\u5f3a\u68af\u5ea6\uff0c\u56e0\u6b64\u5c06\u6211\u4eec\u7684\u6570\u636e\u5c45\u4e2d\u53ef\u4ee5\u52a0\u5feb\u5b66\u4e60\u901f\u5ea6\u3002\n   \u4f20\u9012\u7ed9\u8f6c\u6362\u7684\u503c\u662f\u6570\u636e\u96c6\u4e2d\u56fe\u50cf\u7684 rgb \u503c\u7684\u5747\u503c(\u7b2c\u4e00\u4e2a\u5143\u7ec4)\u548c\u6807\u51c6\u5dee(\u7b2c\u4e8c\u4e2a\u5143\u7ec4)\u3002\n   \u4f60\u53ef\u4ee5\u901a\u8fc7\u8fd0\u884c\u4ee5\u4e0b\u51e0\u884c\u4ee3\u7801\u81ea\u5df1\u8ba1\u7b97\u8fd9\u4e9b\u503c:\n         ```\n          from torch.utils.data import ConcatDataset\n          transform = transforms.Compose([transforms.ToTensor()])\n          trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                       download=True, transform=transform)\n\n          #\u5c06\u6240\u6709\u8bad\u7ec3\u56fe\u50cf\u5806\u53e0\u6210\u5f62\u72b6\u4e3a (50000, 3, 32, 32) \u7684\u5f20\u91cf\n          x = torch.stack([sample[0] for sample in ConcatDataset([trainset])])\n\n          #\u83b7\u53d6\u6bcf\u4e2a\u901a\u9053\u7684\u5747\u503c\n          mean = torch.mean(x, dim=(0,2,3)) #tensor([0.4914, 0.4822, 0.4465])\n          std = torch.std(x, dim=(0,2,3)) #tensor([0.2470, 0.2435, 0.2616])\n\n         ```\n\n\u8fd8\u6709\u8bb8\u591a\u5176\u4ed6\u53ef\u7528\u7684\u8f6c\u6362\uff0c\u5305\u62ec\u88c1\u526a\u3001\u5c45\u4e2d\u3001\u65cb\u8f6c\u548c\u53cd\u5c04\u3002\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u521b\u5efa CIFAR10 \u6570\u636e\u96c6\u7684\u4e00\u4e2a\u5b9e\u4f8b\u3002\u8fd9\u662f\u4e00\u7ec4 32x32 \u7684\u5f69\u8272\u56fe\u50cf\u5207\u7247\uff0c\u4ee3\u8868 10 \u7c7b\u7269\u4f53: \n6 \u79cd\u52a8\u7269(\u9e1f\u3001\u732b\u3001\u9e7f\u3001\u72d7\u3001\u9752\u86d9\u3001\u9a6c)\u548c 4 \u79cd\u8f66\u8f86(\u98de\u673a\u3001\u6c7d\u8f66\u3001\u8239\u3001\u5361\u8f66):\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>\u5f53\u4f60\u8fd0\u884c\u4e0a\u9762\u7684\u5355\u5143\u683c\u65f6\uff0c\u5b83\u53ef\u80fd\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\u6765\u4e0b\u8f7d\u6570\u636e\u96c6\u3002</p></div>\n\n\u8fd9\u662f\u5728 PyTorch \u4e2d\u521b\u5efa\u6570\u636e\u96c6\u5bf9\u8c61\u7684\u4e00\u4e2a\u793a\u4f8b\u3002\u53ef\u4e0b\u8f7d\u7684\u6570\u636e\u96c6(\u5982\u4e0a\u9762\u7684 CIFAR-10)\u662f \n``torch.utils.data.Dataset`` \u7684\u5b50\u7c7b\u3002PyTorch \u4e2d\u7684 ``Dataset`` \u7c7b\u5305\u62ec \nTorchVision\u3001Torchtext \u548c TorchAudio \u4e2d\u7684\u53ef\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u8bf8\u5982 \n``torchvision.datasets.ImageFolder`` \u4e4b\u7c7b\u7684\u5b9e\u7528\u7a0b\u5e8f\u6570\u636e\u96c6\u7c7b\uff0c\u5b83\u5c06\u8bfb\u53d6\u4e00\u4e2a\u6807\u8bb0\u8fc7\u7684\u56fe\u50cf\u6587\u4ef6\u5939\u3002\n\u4f60\u4e5f\u53ef\u4ee5\u521b\u5efa ``Dataset`` \u7684\u81ea\u5df1\u7684\u5b50\u7c7b\u3002\n\n\u5f53\u6211\u4eec\u5b9e\u4f8b\u5316\u6211\u4eec\u7684\u6570\u636e\u96c6\u65f6\uff0c\u6211\u4eec\u9700\u8981\u544a\u8bc9\u5b83\u4e00\u4e9b\u4e8b\u60c5:\n\n-  \u6211\u4eec\u5e0c\u671b\u6570\u636e\u5b58\u653e\u7684\u6587\u4ef6\u7cfb\u7edf\u8def\u5f84\u3002\n-  \u6211\u4eec\u662f\u5426\u4f7f\u7528\u8fd9\u4e2a\u96c6\u5408\u8fdb\u884c\u8bad\u7ec3;\u5927\u591a\u6570\u6570\u636e\u96c6\u5c06\u88ab\u5206\u4e3a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5b50\u96c6\u3002\n-  \u5982\u679c\u6211\u4eec\u8fd8\u6ca1\u6709\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u6211\u4eec\u662f\u5426\u5e0c\u671b\u4e0b\u8f7d\u5b83\u3002\n-  \u6211\u4eec\u60f3\u5bf9\u6570\u636e\u5e94\u7528\u54ea\u4e9b\u8f6c\u6362\u3002\n\n\u4e00\u65e6\u4f60\u7684\u6570\u636e\u96c6\u51c6\u5907\u5c31\u7eea\uff0c\u4f60\u5c31\u53ef\u4ee5\u5c06\u5b83\u4ea4\u7ed9 ``DataLoader``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``Dataset`` \u7684\u5b50\u7c7b\u5305\u88c5\u4e86\u5bf9\u6570\u636e\u7684\u8bbf\u95ee\uff0c\u5e76\u4e13\u95e8\u9488\u5bf9\u5b83\u6b63\u5728\u670d\u52a1\u7684\u6570\u636e\u7c7b\u578b\u3002\n``DataLoader`` \u5bf9\u5b83\u6b63\u5728\u670d\u52a1\u7684\u6570\u636e\u4e00\u65e0\u6240\u77e5\uff0c\u4f46\u4f1a\u6839\u636e\u4f60\u6307\u5b9a\u7684\u53c2\u6570\u5c06 ``Dataset`` \u63d0\u4f9b\u7684\u8f93\u5165\u5f20\u91cf\u7ec4\u7ec7\u6210\u6279\u6b21\u3002\n\n\u5728\u4e0a\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\u6211\u4eec\u8981\u6c42\u4e00\u4e2a ``DataLoader`` \u4ece ``trainset`` \u4e2d\u7ed9\u6211\u4eec\u6279\u6b21\u5927\u5c0f\u4e3a 4 \u7684\u6279\u6b21\uff0c\n\u968f\u673a\u6253\u4e71\u5b83\u4eec\u7684\u987a\u5e8f(``shuffle=True``)\uff0c\u5e76\u544a\u8bc9\u5b83\u542f\u52a8\u4e24\u4e2a\u5de5\u4f5c\u8fdb\u7a0b\u4ece\u78c1\u76d8\u52a0\u8f7d\u6570\u636e\u3002\n\n\u53ef\u89c6\u5316\u4f60\u7684 ``DataLoader`` \u63d0\u4f9b\u7684\u6279\u6b21\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u505a\u6cd5:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\n# \u83b7\u53d6\u4e00\u4e9b\u968f\u673a\u8bad\u7ec3\u56fe\u50cf\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# \u663e\u793a\u56fe\u50cf\nimshow(torchvision.utils.make_grid(images))\n# \u6253\u5370\u6807\u7b7e\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd0\u884c\u4e0a\u9762\u7684\u5355\u5143\u683c\u5e94\u8be5\u4f1a\u663e\u793a\u4f60\u4e00\u6761\u56db\u5f20\u56fe\u50cf\u7684\u6761\u5e26,\u4ee5\u53ca\u6bcf\u5f20\u56fe\u50cf\u7684\u6b63\u786e\u6807\u7b7e\u3002\n\n## \u8bad\u7ec3\u4f60\u7684 PyTorch \u6a21\u578b\n\n\u4ece\u89c6\u9891\u7684 [17:10](https://www.youtube.com/watch?v=IC0_FRiX-sw&t=1030s)_ \u5f00\u59cb\u3002\n\n\u8ba9\u6211\u4eec\u628a\u6240\u6709\u7684\u90e8\u5206\u653e\u5728\u4e00\u8d77,\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u9996\u5148,\u6211\u4eec\u9700\u8981\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u3002\u5982\u679c\u4f60\u8fd8\u6ca1\u6709,\u8fd0\u884c\u4e0b\u9762\u7684\u5355\u5143\u683c\u6765\u786e\u4fdd\u6570\u636e\u96c6\u5df2\u4e0b\u8f7d\u3002(\u53ef\u80fd\u9700\u8981\u4e00\u5206\u949f)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=4,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd0\u884c\u5bf9 ``DataLoader`` \u8f93\u51fa\u7684\u68c0\u67e5:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# \u663e\u793a\u56fe\u50cf\nimshow(torchvision.utils.make_grid(images))\n# \u6253\u5370\u6807\u7b7e\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8fd9\u662f\u6211\u4eec\u5c06\u8981\u8bad\u7ec3\u7684\u6a21\u578b\u3002\u5982\u679c\u5b83\u770b\u8d77\u6765\u5f88\u719f\u6089,\u90a3\u662f\u56e0\u4e3a\u5b83\u662f LeNet \u7684\u4e00\u4e2a\u53d8\u4f53 \n- \u5728\u672c\u89c6\u9891\u524d\u9762\u8ba8\u8bba\u8fc7 - \u9002\u7528\u4e8e 3 \u8272\u56fe\u50cf\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6211\u4eec\u6700\u540e\u9700\u8981\u7684\u662f\u4e00\u4e2a\u635f\u5931\u51fd\u6570\u548c\u4e00\u4e2a\u4f18\u5316\u5668:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u635f\u5931\u51fd\u6570,\u5982\u672c\u89c6\u9891\u524d\u9762\u6240\u8ba8\u8bba\u7684,\u662f\u8861\u91cf\u6a21\u578b\u9884\u6d4b\u4e0e\u7406\u60f3\u8f93\u51fa\u4e4b\u95f4\u5dee\u8ddd\u7684\u6307\u6807\u3002\n\u4ea4\u53c9\u71b5\u635f\u5931\u662f\u50cf\u6211\u4eec\u8fd9\u6837\u7684\u5206\u7c7b\u6a21\u578b\u7684\u5178\u578b\u635f\u5931\u51fd\u6570\u3002\n\n**\u4f18\u5316\u5668**\u662f\u9a71\u52a8\u5b66\u4e60\u7684\u5173\u952e\u3002\u5728\u8fd9\u91cc,\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5b9e\u73b0 *\u968f\u673a\u68af\u5ea6\u4e0b\u964d* \u7684\u4f18\u5316\u5668\uff0c\n\u8fd9\u662f\u6700\u76f4\u63a5\u7684\u4f18\u5316\u7b97\u6cd5\u4e4b\u4e00\u3002\u9664\u4e86\u7b97\u6cd5\u7684\u53c2\u6570(\u5982\u5b66\u4e60\u7387 ``lr`` \u548c\u52a8\u91cf)\u4e4b\u5916\uff0c\n\u6211\u4eec\u8fd8\u4f20\u5165\u4e86 ``net.parameters()``\uff0c\u5b83\u662f\u6a21\u578b\u4e2d\u6240\u6709\u5b66\u4e60\u6743\u91cd\u7684\u96c6\u5408 - \u8fd9\u662f\u4f18\u5316\u5668\u8981\u8c03\u6574\u7684\u5bf9\u8c61\u3002\n\n\u6700\u540e,\u6240\u6709\u8fd9\u4e9b\u90fd\u88ab\u7ec4\u88c5\u5230\u8bad\u7ec3\u5faa\u73af\u4e2d\u3002\u7ee7\u7eed\u8fd0\u884c\u8fd9\u4e2a\u5355\u5143\u683c,\u5b83\u53ef\u80fd\u9700\u8981\u51e0\u5206\u949f\u624d\u80fd\u6267\u884c:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # \u5728\u6570\u636e\u96c6\u4e0a\u5faa\u73af\u591a\u6b21\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # \u83b7\u53d6\u8f93\u5165\n        inputs, labels = data\n\n        # \u5c06\u53c2\u6570\u68af\u5ea6\u5f52\u96f6\n        optimizer.zero_grad()\n\n        # \u524d\u5411 + \u53cd\u5411 + \u4f18\u5316\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # \u6253\u5370\u7edf\u8ba1\u4fe1\u606f\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # \u6bcf 2000 \u4e2a\u5c0f\u6279\u6b21\u6253\u5370\u4e00\u6b21\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u53ea\u8fdb\u884c\u4e86 **2 \u4e2a\u8bad\u7ec3\u8f6e\u6b21** (\u7b2c 1 \u884c) - \u4e5f\u5c31\u662f\u5728\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u4e24\u6b21\u5b8c\u6574\u904d\u5386\u3002\n\u6bcf\u6b21\u904d\u5386\u90fd\u6709\u4e00\u4e2a\u5185\u90e8\u5faa\u73af\uff0c**\u904d\u5386\u8bad\u7ec3\u6570\u636e** (\u7b2c 4 \u884c)\uff0c\u63d0\u4f9b\u7ecf\u8fc7\u8f6c\u6362\u7684\u8f93\u5165\u56fe\u50cf\u6279\u6b21\u53ca\u5176\u6b63\u786e\u6807\u7b7e\u3002\n\n**\u5c06\u68af\u5ea6\u5f52\u96f6** (\u7b2c 9 \u884c)\u662f\u4e00\u4e2a\u91cd\u8981\u6b65\u9aa4\u3002\u68af\u5ea6\u4f1a\u5728\u4e00\u4e2a\u6279\u6b21\u4e0a\u7d2f\u79ef\uff1b\u5982\u679c\u6211\u4eec\u4e0d\u4e3a\u6bcf\u4e2a\u6279\u6b21\u91cd\u7f6e\u5b83\u4eec\uff0c\n\u5b83\u4eec\u5c06\u7ee7\u7eed\u7d2f\u79ef\uff0c\u4ece\u800c\u63d0\u4f9b\u9519\u8bef\u7684\u68af\u5ea6\u503c\uff0c\u4f7f\u5b66\u4e60\u53d8\u5f97\u4e0d\u53ef\u80fd\u3002\n\n\u5728\u7b2c 12 \u884c,\u6211\u4eec**\u8981\u6c42\u6a21\u578b\u5bf9\u8fd9\u4e2a\u6279\u6b21\u8fdb\u884c\u9884\u6d4b**\u3002\u5728\u4e0b\u4e00\u884c(13)\u4e2d\uff0c\u6211\u4eec\u8ba1\u7b97\u635f\u5931 \n- ``outputs``(\u6a21\u578b\u9884\u6d4b)\u4e0e ``labels``(\u6b63\u786e\u8f93\u51fa)\u4e4b\u95f4\u7684\u5dee\u5f02\u3002\n\n\u5728\u7b2c 14 \u884c\uff0c\u6211\u4eec\u8fdb\u884c ``backward()`` \u4f20\u64ad\uff0c\u8ba1\u7b97\u5c06\u6307\u5bfc\u5b66\u4e60\u7684\u68af\u5ea6\u3002\n\n\u5728\u7b2c 15 \u884c\uff0c\u4f18\u5316\u5668\u6267\u884c\u4e00\u6b65\u5b66\u4e60 - \u5b83\u4f7f\u7528 ``backward()`` \u8c03\u7528\u5f97\u5230\u7684\u68af\u5ea6\u6765\u8c03\u6574\u5b66\u4e60\u6743\u91cd\uff0c\u4ee5\u51cf\u5c0f\u635f\u5931\u3002\n\n\u5faa\u73af\u7684\u5176\u4f59\u90e8\u5206\u5bf9\u8f6e\u6b21\u53f7\u3001\u5df2\u5b8c\u6210\u7684\u8bad\u7ec3\u5b9e\u4f8b\u6570\u4ee5\u53ca\u8bad\u7ec3\u5faa\u73af\u4e2d\u6536\u96c6\u7684\u635f\u5931\u8fdb\u884c\u4e86\u4e00\u4e9b\u8f7b\u91cf\u7ea7\u62a5\u544a\u3002\n\n**\u5f53\u4f60\u8fd0\u884c\u4e0a\u9762\u7684\u5355\u5143\u683c\u65f6**,\u4f60\u5e94\u8be5\u4f1a\u770b\u5230\u7c7b\u4f3c\u8fd9\u6837\u7684\u8f93\u51fa:\n\n```sh\n[1,  2000] loss: 2.235\n[1,  4000] loss: 1.940\n[1,  6000] loss: 1.713\n[1,  8000] loss: 1.573\n[1, 10000] loss: 1.507\n[1, 12000] loss: 1.442\n[2,  2000] loss: 1.378\n[2,  4000] loss: 1.364\n[2,  6000] loss: 1.349\n[2,  8000] loss: 1.319\n[2, 10000] loss: 1.284\n[2, 12000] loss: 1.267\nFinished Training\n```\n\u6ce8\u610f\u635f\u5931\u503c\u662f\u5355\u8c03\u4e0b\u964d\u7684\uff0c\u8868\u660e\u6211\u4eec\u7684\u6a21\u578b\u5728\u7ee7\u7eed\u63d0\u9ad8\u5176\u5728\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002\n\n\u4f5c\u4e3a\u6700\u540e\u4e00\u6b65\uff0c\u6211\u4eec\u5e94\u8be5\u68c0\u67e5\u6a21\u578b\u662f\u5426\u771f\u6b63\u505a\u5230\u4e86 *\u6cdb\u5316* \u5b66\u4e60\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\"\u8bb0\u4f4f\"\u4e86\u6570\u636e\u96c6\u3002\u8fd9\u88ab\u79f0\u4e3a **\u8fc7\u62df\u5408**\uff0c\n\u901a\u5e38\u8868\u660e\u6570\u636e\u96c6\u592a\u5c0f(\u6ca1\u6709\u8db3\u591f\u7684\u6837\u672c\u8fdb\u884c\u6cdb\u5316\u5b66\u4e60)\uff0c\u6216\u8005\u6a21\u578b\u7684\u5b66\u4e60\u53c2\u6570\u6bd4\u6b63\u786e\u5efa\u6a21\u6570\u636e\u96c6\u6240\u9700\u7684\u66f4\u591a\u3002\n\n\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48\u6570\u636e\u96c6\u88ab\u5206\u4e3a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5b50\u96c6\u7684\u539f\u56e0 - \u4e3a\u4e86\u6d4b\u8bd5\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b,\u6211\u4eec\u8981\u6c42\u5b83\u5bf9\u4ece\u672a\u8bad\u7ec3\u8fc7\u7684\u6570\u636e\u8fdb\u884c\u9884\u6d4b:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5982\u679c\u4f60\u4e00\u76f4\u8ddf\u968f\u4e0b\u6765,\u4f60\u5e94\u8be5\u4f1a\u770b\u5230\u6a21\u578b\u5728\u8fd9\u4e00\u70b9\u4e0a\u7684\u51c6\u786e\u7387\u5927\u7ea6\u4e3a 50%\u3002\u8fd9\u5e76\u4e0d\u662f\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\n\u4f46\u6bd4\u968f\u673a\u8f93\u51fa\u7684 10% \u51c6\u786e\u7387\u8981\u597d\u5f97\u591a\u3002\u8fd9\u8bc1\u660e\u4e86\u6a21\u578b\u786e\u5b9e\u53d1\u751f\u4e86\u4e00\u4e9b\u6cdb\u5316\u5b66\u4e60\u3002\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}