{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# \u5728 ``nn.Module`` \u4e2d\u4e3a ``load_state_dict`` \u548c\u5f20\u91cf\u5b50\u7c7b\u63d0\u4f9b\u6269\u5c55\u70b9\n**\u4f5c\u8005:** [Mikayla Gawarecki](https://github.com/mikaylagawarecki)\n\n\u672c\u6559\u7a0b\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u5b9e\u7528\u51fd\u6570 ``torch.utils.swap_tensors``\uff0c\n\u4ee5\u53ca\u5728 ``nn.Module`` \u4e2d\u96c6\u6210\u5b83\u7684\u4e24\u4e2a\u65b0\u6269\u5c55\u70b9:\n\n* ``nn.Module.to()`` \u548c\u76f8\u5173\u65b9\u6cd5\n* ``nn.Module.load_state_dict()``\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>\u672c\u6559\u7a0b\u9700\u8981 PyTorch 2.3.0 \u6216\u66f4\u9ad8\u7248\u672c\u3002</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``torch.utils.swap_tensors``\n``torch.utils.swap_tensors``(\u4ee5\u4e0b\u7b80\u79f0\u4e3a ``swap_tensors``) \u662f\u4e00\u4e2a\n\u5b9e\u7528\u51fd\u6570,\u5b83\u63a5\u53d7\u4e24\u4e2a Python \u5f20\u91cf\u5e76\u4ea4\u6362\u5b83\u4eec\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\n\nt1 = torch.arange(2)\nt2 = torch.arange(3)\nprint(f\"\u4ea4\u6362\u524d, t1: {t1}, t2: {t2}\")\ntorch.utils.swap_tensors(t1, t2)\nprint(f\"\u4ea4\u6362\u540e, t1: {t1}, t2: {t2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u66f4\u5177\u4f53\u5730\u8bf4, ``swap_tensors`` \u4ea4\u6362\u4e86\u4e24\u4e2a\u5f20\u91cf\u7684 Python ``__class__``\u3001``__dict__``\n\u548c ``__slots__``,\u4ee5\u53ca\u5b83\u4eec\u76f8\u5173\u7684 ``at::Tensor``\u3002\n\n\n## \u5e94\u7528\u4e8e ``nn.Module``\n\u5f53 ``nn.Module`` \u4e4b\u5916\u7684 Python \u5bf9\u8c61\u6301\u6709\u8be5\u6a21\u5757\u53c2\u6570\u7684\u5f15\u7528\u65f6,\u6b64\u5b9e\u7528\u51fd\u6570\u5c31\u5f88\u6709\u7528\u3002\n\u5982\u679c ``nn.Module`` \u5c31\u5730\u4fee\u6539\u4e86\u4efb\u4f55\u53c2\u6570,\u6301\u6709\u8fd9\u4e9b\u53c2\u6570\u5f15\u7528\u7684\u5bf9\u8c61\u5c06\u65e0\u6cd5\u770b\u5230\u66f4\u6539\u3002\n\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\u662f\u4f18\u5316\u5668,\u5b83\u6301\u6709 ``nn.Module`` \u53c2\u6570\u7684\u5f15\u7528\u3002\n\u8fd9\u4f1a\u5bfc\u81f4\u4e00\u4e2a\u6f5c\u5728\u7684\u6b63\u786e\u6027\u95ee\u9898,\u5373 ``optimizer.step()`` \u4f1a\u65e0\u9519\u8bef\u8fd0\u884c,\n\u4f46 ``nn.Module`` \u7684\u6743\u91cd\u4e0d\u4f1a\u88ab\u66f4\u65b0\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mod = torch.nn.Linear(1, 2, bias=False)\noptimizer = torch.optim.SGD(mod.parameters())\nprint(f\"mod \u4e2d\u7684\u6743\u91cd: {mod.weight}\")\nprint(f\"\u4f18\u5316\u5668\u4e2d\u7684\u6743\u91cd: {optimizer.param_groups[0]['params']}\")\nmod.weight = torch.nn.Parameter(2 * mod.weight)\nprint(f\"mod \u4e2d\u7684\u6743\u91cd: {mod.weight}\")\nprint(f\"\u4f18\u5316\u5668\u4e2d\u7684\u6743\u91cd: {optimizer.param_groups[0]['params']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``nn.Module.to()`` \u548c\u76f8\u5173\u65b9\u6cd5\n\u8fd9\u5305\u62ec\u6539\u53d8\u6a21\u5757\u8bbe\u5907\u7684\u65b9\u6cd5(\u5982 ``nn.Module.cpu()``)\u3001\n\u6539\u53d8\u6a21\u5757 ``dtype`` \u7684\u65b9\u6cd5(\u5982 ``nn.Module.float()``)\u3001\n\u4ee5\u53ca\u5141\u8bb8\u6a21\u5757\u5b9e\u4f8b\u5316\u7684\u65b9\u6cd5(\u5982 ``nn.Module.to_empty()``)\u3002\n\n\u4e4d\u4e00\u770b,\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u5c31\u5730\u4fee\u6539\u6a21\u5757\u7684\u53c2\u6570\u53ef\u80fd\u770b\u8d77\u6765\u4e0d\u592a\u76f4\u89c2\u3002\n\u73b0\u6709\u7684\u65b9\u6cd5\u662f\u4f7f\u7528\u4e00\u79cd\u8ffd\u6eaf\u5230 PyTorch \u6700\u521d\u51e0\u5929\u7684\u4e11\u964b\u9ed1\u5ba2\u624b\u6bb5\u3002\n\n\u503c\u5f97\u6ce8\u610f\u7684\u662f,\u73b0\u6709\u65b9\u6cd5\u5728\u4ee5\u4e0b\u60c5\u51b5\u4e0b\u65e0\u6cd5\u5de5\u4f5c:\n\n* \u4f7f\u7528 ``__torch_dispatch__`` \u5b50\u7c7b\n* ``param`` \u548c ``new_param`` \u7684 Python ``type()`` \u4e0d\u540c\n* \u5bf9\u4e8e\u5177\u6709\u7279\u6b8a C++ \u8868\u793a\u7684\u5f20\u91cf(\u5982\u7a00\u758f\u5f20\u91cf\u548c ``XLA`` \u5f20\u91cf)\n\n\u5728\u672c\u6559\u7a0b\u7684\u4e0b\u4e00\u90e8\u5206,\u6211\u4eec\u5c06\u5b9a\u4e49\u4e00\u4e2a\u73a9\u5177 ``__torch_dispatch__`` \u5b50\u7c7b ``MyQuantizedLinearWeight``\n\u6765\u8868\u793a\u91cf\u5316\u7684\u7ebf\u6027\u6743\u91cd\u3002\u5728\u672c\u6559\u7a0b\u7684\u5269\u4f59\u90e8\u5206,\u6211\u4eec\u5c06\u4f7f\u7528\u8fd9\u4e2a\u5b50\u7c7b\u8fdb\u884c\u8bf4\u660e\u3002\n\u4e3a\u7b80\u6d01\u8d77\u89c1,\u6211\u4eec\u7701\u7565\u4e86\u5927\u90e8\u5206 ``__torch_dispatch__`` \u5b9e\u73b0\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aten = torch.ops.aten\n\n\nclass MyQuantizedLinearWeight(torch.Tensor):\n    @staticmethod\n    def __new__(cls, elem, scale):\n        return torch.Tensor._make_wrapper_subclass(\n            cls,\n            elem.shape,\n            dtype=elem.dtype,\n            layout=elem.layout,\n            device=elem.device,\n            strides=elem.stride(),\n            storage_offset=elem.storage_offset(),\n        )\n\n    def __init__(self, elem: torch.Tensor, scale: float):\n        self.elem = elem\n        self.scale = scale\n\n    def __repr__(self):\n        return f\"MyQuantizedLinearWeight({self.elem}, scale={self.scale})\"\n\n    @classmethod\n    def __torch_dispatch__(cls, func, types, args, kwargs):\n        if func in (aten.detach.default, aten._to_copy.default):\n            new_elem = func(args[0].elem, *args[1:], **kwargs)\n            return cls(new_elem, args[0].scale)\n        # \u67d0\u4e9b\u64cd\u4f5c\u7684\u5b9e\u73b0\u5c06\u6dfb\u52a0\u5230 ``OP_TABLE``\u3002\n        # \u4e3a\u7b80\u6d01\u8d77\u89c1,\u6211\u4eec\u5728\u6b64\u7701\u7565\u3002\n        OP_TABLE = dict()\n        if func in OP_TABLE:\n            return OP_TABLE[func](func, args, kwargs)\n        raise NotImplementedError(f\"\u4e0d\u652f\u6301\u7684\u51fd\u6570 {func}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8ba9\u6211\u4eec\u521b\u5efa\u4e00\u4e2a ``dtype`` \u4e3a ``torch.float32`` \u7684 ``nn.Linear`` \u5c42,\n\u5176\u6743\u91cd\u662f ``MyQuantizedLinearWeight``\u3002\u7136\u540e\u5c1d\u8bd5\u5c06\u5176\u8f6c\u6362\u4e3a ``torch.bfloat16``\u3002\n\u89c2\u5bdf\u5230\u6743\u91cd\u7684 ``dtype`` \u5982\u9884\u671f\u822c\u6539\u53d8\u4e86\u3002\u4f46\u662f\u5b50\u7c7b\u7684\u6709\u6548\u8f7d\u8377(``elem``)\u7684 ``dtype`` \u6ca1\u6709\u6539\u53d8\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m = nn.Linear(3, 5, dtype=torch.float32)\nm.weight = torch.nn.Parameter(MyQuantizedLinearWeight(m.weight, 0.5))\nprint(f\"\u4e4b\u524d: id(m.weight)={id(m.weight)}, id(m.bias)={id(m.bias)}\")\nm.bfloat16()\nprint(f\"\u4e4b\u540e: id(m.weight)={id(m.weight)}, id(m.bias)={id(m.bias)}\")\nprint(f\"m.weight.dtype: {m.weight.dtype}\")\nprint(f\"m.weight.elem.dtype: {m.weight.elem.dtype}\")\nprint(f\"m.bias.dtype: {m.bias.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e3a\u6b64,\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u5168\u5c40\u914d\u7f6e ``torch.__future__.set_swap_module_params_on_conversion``\n\u5b83\u5c06\u4f7f\u7528 ``swap_tensors`` \u4ea4\u6362\u6a21\u5757\u7684\u53c2\u6570,\u540c\u65f6\u4fdd\u7559 ``.data`` \u8bbe\u7f6e\u4e2d\u7684\u5f15\u7528\u3002\n\u8bbe\u7f6e\u6b64\u914d\u7f6e\u540e,\u5728\u8f6c\u6362\u671f\u95f4\u5c06\u4f7f\u7528 ``swap_tensors``,\u4ece\u800c\u786e\u4fdd\u6709\u6548\u8f7d\u8377\u7684 ``dtype`` \u6b63\u786e\u8f6c\u6362\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.__future__.set_swap_module_params_on_conversion(True)\nm = nn.Linear(3, 5, dtype=torch.float32)\nm.weight = torch.nn.Parameter(MyQuantizedLinearWeight(m.weight, 0.5))\nprint(f\"\u4e4b\u524d: id(m.weight)={id(m.weight)}, id(m.bias)={id(m.bias)}\")\nm.bfloat16()\nprint(f\"\u4e4b\u540e: id(m.weight)={id(m.weight)}, id(m.bias)={id(m.bias)}\")\nprint(f\"m.weight.dtype: {m.weight.dtype}\")\nprint(f\"m.weight.elem.dtype: {m.weight.elem.dtype}\")\nprint(f\"m.bias.dtype: {m.bias.dtype}\")\ntorch.__future__.set_swap_module_params_on_conversion(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``nn.Module.load_state_dict()``\n\u6839\u636e\u4f20\u9012\u7ed9 ``load_state_dict()`` \u7684 ``assign`` \u5173\u952e\u5b57\u53c2\u6570\u7684\u503c,\n\u6709\u4e24\u79cd\u65b9\u5f0f\u52a0\u8f7d ``state_dict``\uff1a\n\n* ``assign=False``: \u4fdd\u7559 ``module.param`` \u7684\u5c5e\u6027,\u53ea\u4ece ``state_dict['param_name']`` \u4e2d\u83b7\u53d6\u503c\n* ``assign=True``: \u4fdd\u7559 ``state_dict['param_name']`` \u7684\u5c5e\u6027\u548c\u503c\u3002\n\n\n\u4e4b\u524d,\u8fd9\u4e9b\u5206\u522b\u662f\u901a\u8fc7\u5c31\u5730 ``copy_`` \u548c ``__setattr__`` \u5b9e\u73b0\u7684\u3002\n\u5728\u73b0\u6709\u5b9e\u73b0\u4e2d,\u6bcf\u79cd\u65b9\u6cd5\u90fd\u6709\u81ea\u5df1\u7684\u9650\u5236 - ``assign=False`` \u8981\u6c42 ``state_dict`` \u4e2d\u7684\u53c2\u6570\u7c7b\u578b\n\u5fc5\u987b\u4e0e\u6a21\u5757\u4e2d\u7684\u53c2\u6570\u7c7b\u578b\u76f8\u540c,\u800c ``assign=True`` \u8981\u6c42\u5728 ``nn.Module.load_state_dict()`` \u4e4b\u540e\n\u521d\u59cb\u5316\u4efb\u4f55\u6301\u6709\u6a21\u5757\u53c2\u6570\u5f15\u7528\u7684\u5bf9\u8c61\u3002\n\n\u73b0\u5728,\u6211\u4eec\u901a\u8fc7\u5728 ``load_state_dict()`` \u4e2d\u6dfb\u52a0 ``swap_tensors`` \u8def\u5f84\u5e76\u5f15\u5165\u65b0\u7684\u6269\u5c55\u70b9\n``torch.Tensor.module_load(self, other, assign=False)`` \u6765\u89e3\u51b3\u8fd9\u4e24\u4e2a\u9650\u5236\u3002\n\u5f53\u542f\u7528\u4e0a\u8ff0 ``__future__`` \u65f6,\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 ``module_load`` \u7684 ``__torch_function__`` \u5904\u7406\u7a0b\u5e8f\n\u5bf9 ``state_dict`` \u4e2d\u7684\u503c\u5e94\u7528\u81ea\u5b9a\u4e49\u8f6c\u6362\u3002\u8f6c\u6362\u7684\u7ed3\u679c\u5c06\u4e0e\u6a21\u5757\u4e2d\u7684\u53c2\u6570\u4ea4\u6362\u3002\n\n\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d,\u6211\u4eec\u5c06\u4f7f\u7528\u4e0a\u9762\u5b9a\u4e49\u7684 ``MyQuantizedLinearWeight`` \u5b50\u7c7b\n\u6765\u8bf4\u660e\u5982\u4f55\u4f7f\u7528\u8fd9\u4e9b\u529f\u80fd\u5728\u52a0\u8f7d ``state_dict`` \u65f6\u5bf9\u7ebf\u6027\u5c42\u7684\u6743\u91cd\u5e94\u7528\u81ea\u5b9a\u4e49\u91cf\u5316\u65b9\u6848\u3002\n\n\u56de\u987e\u4e00\u4e0b,\u5982\u679c ``self`` \u6216 ``other``(\u5728\u672c\u4f8b\u4e2d\u662f ``param`` \u6216 ``state_dict[param_key]``)\n\u662f ``MyQuantizedLinearWeight`` \u5b50\u7c7b,\u5219\u4f1a\u8c03\u7528 ``module_load`` \u7684 ``__torch_function__`` \u5904\u7406\u7a0b\u5e8f\u3002\n\n\u5047\u8bbe\u6211\u4eec\u671f\u671b ``state_dict`` \u5305\u542b\u666e\u901a\u5f20\u91cf,\u800c\u6a21\u5757\u5305\u542b ``MyQuantizedLinearWeight`` \u53c2\u6570,\n\u6211\u4eec\u5e0c\u671b\u5c06 ``state_dict`` \u4e2d\u7684\u5f20\u91cf\u8f6c\u6362\u4e3a\u5b50\u7c7b\u3002\u90a3\u4e48\u6211\u4eec\u53ef\u4ee5\u4e3a ``torch.Tensor.module_load`` \u5b9a\u4e49\n\u4e00\u4e2a ``__torch_function__`` \u5904\u7406\u7a0b\u5e8f,\u5982\u4e0b\u6240\u793a:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@classmethod\ndef custom_torch_function(cls, func, types, args=(), kwargs=None):\n    kwargs = {} if kwargs is None else kwargs\n\n    if func is torch.Tensor.module_load:\n        dest, src = args[0], args[1]\n        assert type(dest) == cls and type(src) == torch.Tensor\n        return MyQuantizedLinearWeight(src, dest.scale)\n    else:\n        with torch._C.DisableTorchFunctionSubclass():\n            return func(*args, **kwargs)\n\n\nMyQuantizedLinearWeight.__torch_function__ = custom_torch_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u9996\u5148,\u8ba9\u6211\u4eec\u5728 meta \u8bbe\u5907\u4e0a\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u6846\u67b6,\u4ee5\u907f\u514d\u5b9e\u4f8b\u5316\u5b58\u50a8\u3002\n\u6211\u4eec\u5c06\u6a21\u5757\u4e2d\u7684\u6240\u6709\u6743\u91cd\u8f6c\u6362\u4e3a ``MyQuantizedLinearWeight`` \u5b50\u7c7b,\u540c\u65f6\u4fdd\u7559\u504f\u7f6e\u4e0d\u53d8\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def fn(m):\n    if isinstance(m, nn.Linear):\n        requires_grad = m.weight.requires_grad\n        m.weight = torch.nn.Parameter(\n            MyQuantizedLinearWeight(m.weight, 0.5), requires_grad=requires_grad\n        )\n\n\nwith torch.device(\"meta\"):\n    m = nn.Linear(3, 5)\n    m.apply(fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u7136\u540e\u6211\u4eec\u53ef\u4ee5\u52a0\u8f7d ``state_dict``\u3002\u6ce8\u610f\u6211\u4eec\u4f7f\u7528 ``assign=True``\uff0c\u56e0\u4e3a\u5bf9\u4e8e\u504f\u7f6e,\n\u6211\u4eec\u5e0c\u671b\u4fdd\u7559 ``state_dict`` \u4e2d\u5f20\u91cf\u7684\u5c5e\u6027(\u4f8b\u5982,\u6211\u4eec\u4e0d\u5e0c\u671b\u504f\u7f6e\u5728\u52a0\u8f7d\u540e\u4f4d\u4e8e ``meta`` \u8bbe\u5907\u4e0a)\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.__future__.set_swap_module_params_on_conversion(True)\nprint(f\"\u4e4b\u524d: id(weight)={id(m.weight)}, id(bias)={id(m.bias)}\")\nprint(f\"load_state_dict() \u4e4b\u524d\u7684 m.state_dict():\\n {m.state_dict()}\")\nstate_dict = nn.Linear(3, 5).state_dict()\nprint(f\"state_dict:\\n {state_dict}\")\nm.load_state_dict(state_dict, assign=True)\nprint(f\"\u4e4b\u540e: id(weight)={id(m.weight)}, id(bias)={id(m.bias)}\")\nprint(f\"load_state_dict() \u4e4b\u540e\u7684 m.state_dict():\\n {m.state_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u4e0a\u9762\u662f\u4e00\u4e2a\u5982\u4f55\u4f7f\u7528 ``nn.Module.load_state_dict()`` \u4e2d\u7684\u65b0\u6269\u5c55\u70b9\u7684\u73a9\u5177\u793a\u4f8b\u3002\n\u6211\u4eec\u8fd8\u53ef\u4ee5\u60f3\u8c61\u5176\u4ed6\u573a\u666f,\u4f8b\u5982\u5f53 ``state_dict`` \u4e2d\u6709\u5f20\u91cf\u5b50\u7c7b\u800c\u6a21\u5757\u4e2d\u6709\u666e\u901a ``nn.Parameters``/\u5f20\u91cf\u65f6,\n\u6216\u8005\u4e24\u8005\u90fd\u662f\u5f20\u91cf\u5b50\u7c7b\u65f6\u3002\u6839\u636e\u4f7f\u7528\u573a\u666f,\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49 ``module_load`` \u7684 ``__torch_function__`` \u5904\u7406\u7a0b\u5e8f\n\u6765\u5e94\u7528\u6240\u9700\u7684\u8f6c\u6362\u3002\n\n## \u7ed3\u8bba\n\u5728\u672c\u6559\u7a0b\u4e2d,\u6211\u4eec\u5b66\u4e60\u4e86 ``swap_tensors``\u3001\u5728 ``nn.Module`` \u4e2d\u4fdd\u7559\u53c2\u6570\u5f15\u7528\u7684\u91cd\u8981\u6027,\n\u4ee5\u53ca\u5982\u4f55\u4f7f\u7528\u7531 ``torch.__future__.set_swap_module_params_on_conversion`` \u63a7\u5236\u7684\u4e24\u4e2a\u65b0\u6269\u5c55\u70b9\u3002\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}