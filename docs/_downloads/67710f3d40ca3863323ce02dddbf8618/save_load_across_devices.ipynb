{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# PyTorch \u4e2d\u8de8\u8bbe\u5907\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\n\n\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b,\u60a8\u53ef\u80fd\u9700\u8981\u5728\u4e0d\u540c\u7684\u8bbe\u5907\u4e4b\u95f4\u4fdd\u5b58\u548c\u52a0\u8f7d\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002\n\n## \u7b80\u4ecb\n\n\u4f7f\u7528PyTorch\u5728\u4e0d\u540c\u8bbe\u5907\u4e4b\u95f4\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u662f\u76f8\u5bf9\u76f4\u63a5\u7684\u3002\u5728\u672c\u6559\u7a0b\u4e2d,\u6211\u4eec\u5c06\u5c1d\u8bd5\u5728CPU\u548cGPU\u4e4b\u95f4\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u3002\n\n## \u73af\u5883\u8bbe\u7f6e\n\n\u4e3a\u4e86\u8ba9\u672c\u6559\u7a0b\u4e2d\u7684\u6bcf\u4e2a\u4ee3\u7801\u5757\u90fd\u80fd\u6b63\u786e\u8fd0\u884c,\u60a8\u5fc5\u987b\u5148\u5c06\u8fd0\u884c\u73af\u5883\u5207\u6362\u5230\"GPU\"\u6216\u66f4\u9ad8\u3002\n\u5b8c\u6210\u540e,\u5982\u679c\u8fd8\u6ca1\u6709\u5b89\u88c5`torch`,\u6211\u4eec\u9700\u8981\u5b89\u88c5\u5b83\u3002\n\n\n```sh\npip install torch\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5177\u4f53\u6b65\u9aa4\n\n1. \u5bfc\u5165\u52a0\u8f7d\u6570\u636e\u6240\u9700\u7684\u6240\u6709\u5fc5\u8981\u5e93\n2. \u5b9a\u4e49\u5e76\u521d\u59cb\u5316\u795e\u7ecf\u7f51\u7edc\n3. \u5728GPU\u4e0a\u4fdd\u5b58,CPU\u4e0a\u52a0\u8f7d\n4. \u5728GPU\u4e0a\u4fdd\u5b58,GPU\u4e0a\u52a0\u8f7d\n5. \u5728CPU\u4e0a\u4fdd\u5b58,GPU\u4e0a\u52a0\u8f7d\n6. \u4fdd\u5b58\u548c\u52a0\u8f7d`DataParallel`\u6a21\u578b\n\n### 1. \u5bfc\u5165\u52a0\u8f7d\u6570\u636e\u6240\u9700\u7684\u5fc5\u8981\u5e93\n\n\u5728\u672c\u6559\u7a0b\u4e2d,\u6211\u4eec\u5c06\u4f7f\u7528`torch`\u53ca\u5176\u5b50\u6a21\u5757`torch.nn`\u548c`torch.optim`\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. \u5b9a\u4e49\u5e76\u521d\u59cb\u5316\u795e\u7ecf\u7f51\u7edc\n\n\u4e3a\u4e86\u6f14\u793a,\u6211\u4eec\u5c06\u521b\u5efa\u4e00\u4e2a\u7528\u4e8e\u8bad\u7ec3\u56fe\u50cf\u7684\u795e\u7ecf\u7f51\u7edc\u3002\n\u8981\u4e86\u89e3\u66f4\u591a\u4fe1\u606f,\u8bf7\u53c2\u9605\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u6559\u7a0b\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nprint(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. \u5728GPU\u4e0a\u4fdd\u5b58,CPU\u4e0a\u52a0\u8f7d\n\n\u5f53\u5728CPU\u4e0a\u52a0\u8f7d\u4f7f\u7528GPU\u8bad\u7ec3\u7684\u6a21\u578b\u65f6,\u8bf7\u5c06`torch.device('cpu')`\u4f20\u9012\u7ed9`torch.load()`\u51fd\u6570\u7684`map_location`\u53c2\u6570\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u6307\u5b9a\u4fdd\u5b58\u8def\u5f84\nPATH = \"model.pt\"\n\n# \u4fdd\u5b58\ntorch.save(net.state_dict(), PATH)\n\n# \u52a0\u8f7d\ndevice = torch.device('cpu')\nmodel = Net()\nmodel.load_state_dict(torch.load(PATH, map_location=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b,\u5f20\u91cf\u5e95\u5c42\u7684\u5b58\u50a8\u5c06\u4f7f\u7528`map_location`\u53c2\u6570\u52a8\u6001\u91cd\u65b0\u6620\u5c04\u5230CPU\u8bbe\u5907\u3002\n\n### 4. \u5728GPU\u4e0a\u4fdd\u5b58,GPU\u4e0a\u52a0\u8f7d\n\n\u5f53\u5728GPU\u4e0a\u52a0\u8f7d\u4f7f\u7528GPU\u8bad\u7ec3\u548c\u4fdd\u5b58\u7684\u6a21\u578b\u65f6,\u53ea\u9700\u4f7f\u7528`model.to(torch.device('cuda'))`\u5c06\u521d\u59cb\u5316\u7684\u6a21\u578b\u8f6c\u6362\u4e3aCUDA\u4f18\u5316\u6a21\u578b\u3002\n\n\u8bf7\u786e\u4fdd\u5bf9\u6240\u6709\u6a21\u578b\u8f93\u5165\u4f7f\u7528`.to(torch.device('cuda'))`\u51fd\u6570,\u4e3a\u6a21\u578b\u51c6\u5907\u6570\u636e\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u4fdd\u5b58\ntorch.save(net.state_dict(), PATH)\n\n# \u52a0\u8f7d\ndevice = torch.device(\"cuda\")\nmodel = Net()\nmodel.load_state_dict(torch.load(PATH))\nmodel.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u6ce8\u610f,\u8c03\u7528`my_tensor.to(device)`\u4f1a\u8fd4\u56de`my_tensor`\u5728GPU\u4e0a\u7684\u65b0\u526f\u672c\u3002\u5b83\u4e0d\u4f1a\u8986\u76d6`my_tensor`\u3002\n\u56e0\u6b64,\u8bf7\u8bb0\u4f4f\u624b\u52a8\u8986\u76d6\u5f20\u91cf:\n`my_tensor = my_tensor.to(torch.device('cuda'))`\u3002\n\n### 5. \u5728CPU\u4e0a\u4fdd\u5b58,\u5728GPU\u4e0a\u52a0\u8f7d\n\n\u5f53\u5728GPU\u4e0a\u52a0\u8f7d\u4f7f\u7528CPU\u8bad\u7ec3\u548c\u4fdd\u5b58\u7684\u6a21\u578b\u65f6,\u8bf7\u5728`torch.load()`\u51fd\u6570\u4e2d\u5c06`map_location`\u53c2\u6570\u8bbe\u7f6e\u4e3a`cuda:device_id`,\n\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u7ed9\u5b9a\u7684GPU\u8bbe\u5907\u3002\n\n\u8bf7\u786e\u4fdd\u8c03\u7528`model.to(torch.device('cuda'))`\u5c06\u6a21\u578b\u7684\u53c2\u6570\u5f20\u91cf\u8f6c\u6362\u4e3aCUDA\u5f20\u91cf\u3002\n\n\u6700\u540e,\u8fd8\u8981\u786e\u4fdd\u5bf9\u6240\u6709\u6a21\u578b\u8f93\u5165\u4f7f\u7528`.to(torch.device('cuda'))`\u51fd\u6570,\u4e3aCUDA\u4f18\u5316\u7684\u6a21\u578b\u51c6\u5907\u6570\u636e\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u4fdd\u5b58\ntorch.save(net.state_dict(), PATH)\n\n# \u52a0\u8f7d\ndevice = torch.device(\"cuda\")\nmodel = Net()\n# \u9009\u62e9\u60a8\u60f3\u7528\u7684GPU\u8bbe\u5907\u7f16\u53f7\nmodel.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\nmodel.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Saving ``torch.nn.DataParallel`` Models\n\n``torch.nn.DataParallel`` is a model wrapper that enables parallel GPU\nutilization.\n\nTo save a ``DataParallel`` model generically, save the\n``model.module.state_dict()``. This way, you have the flexibility to\nload the model any way you want to any device you want.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Save\n# 6. \u4fdd\u5b58`torch.nn.DataParallel`\u6a21\u578b\n# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n#\n# `torch.nn.DataParallel`\u662f\u4e00\u4e2a\u6a21\u578b\u5305\u88c5\u5668,\u53ef\u4ee5\u542f\u7528\u5e76\u884cGPU\u5229\u7528\u3002\n#\n# \u8981\u901a\u7528\u5730\u4fdd\u5b58`DataParallel`\u6a21\u578b,\u8bf7\u4fdd\u5b58`model.module.state_dict()`\u3002\n# \u8fd9\u6837,\u60a8\u5c31\u53ef\u4ee5\u7075\u6d3b\u5730\u5c06\u6a21\u578b\u52a0\u8f7d\u5230\u4efb\u4f55\u8bbe\u5907\u3002\n#\n\n# \u4fdd\u5b58\ntorch.save(net.module.state_dict(), PATH)\n\n# \u52a0\u8f7d\u5230\u4efb\u4f55\u60a8\u60f3\u8981\u7684\u8bbe\u5907"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u795d\u8d3a\u60a8!\u60a8\u5df2\u6210\u529f\u5728PyTorch\u4e2d\u8de8\u8bbe\u5907\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b\u3002\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}