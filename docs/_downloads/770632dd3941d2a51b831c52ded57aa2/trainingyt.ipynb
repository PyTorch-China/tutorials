{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\u7b80\u4ecb](introyt1_tutorial.html) ||\n[\u5f20\u91cf](tensors_deeper_tutorial.html) ||\n[\u81ea\u52a8\u5fae\u5206](autogradyt_tutorial.html) ||\n[\u6784\u5efa\u6a21\u578b](modelsyt_tutorial.html) ||\n[TensorBoard\u652f\u6301](tensorboardyt_tutorial.html) ||\n**\u8bad\u7ec3\u6a21\u578b** ||\n[\u6a21\u578b\u7406\u89e3](captumyt.html)\n\n# \u4f7f\u7528 PyTorch \u8bad\u7ec3\u6a21\u578b\n\n\u8ddf\u968f\u4e0b\u9762\u7684\u89c6\u9891\u6216\u5728 [youtube](https://www.youtube.com/watch?v=jF43_wj_DCQ)_ \u4e0a\u89c2\u770b\u3002\n\n.. raw:: html\n\n   <div style=\"margin-top:10px; margin-bottom:10px;\">\n     <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/jF43_wj_DCQ\" frameborder=\"0\" allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n   </div>\n\n## \u7b80\u4ecb\n\n\u5728\u8fc7\u53bb\u7684\u89c6\u9891\u4e2d,\u6211\u4eec\u8ba8\u8bba\u5e76\u6f14\u793a\u4e86:\n\n- \u4f7f\u7528 torch.nn \u6a21\u5757\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u548c\u51fd\u6570\u6784\u5efa\u6a21\u578b\n- \u81ea\u52a8\u68af\u5ea6\u8ba1\u7b97\u7684\u673a\u5236,\u8fd9\u662f\u57fa\u4e8e\u68af\u5ea6\u7684\u6a21\u578b\u8bad\u7ec3\u7684\u6838\u5fc3\n- \u4f7f\u7528 TensorBoard \u53ef\u89c6\u5316\u8bad\u7ec3\u8fdb\u5ea6\u548c\u5176\u4ed6\u6d3b\u52a8\n\n\u5728\u672c\u89c6\u9891\u4e2d,\u6211\u4eec\u5c06\u4e3a\u60a8\u7684\u5e93\u5b58\u6dfb\u52a0\u4e00\u4e9b\u65b0\u5de5\u5177:\n\n- \u6211\u4eec\u5c06\u719f\u6089\u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\u62bd\u8c61,\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u7b80\u5316\u5411\u6a21\u578b\u8bad\u7ec3\u5faa\u73af\u63d0\u4f9b\u6570\u636e\u7684\u8fc7\u7a0b\n- \u6211\u4eec\u5c06\u8ba8\u8bba\u7279\u5b9a\u7684\u635f\u5931\u51fd\u6570\u4ee5\u53ca\u4f55\u65f6\u4f7f\u7528\u5b83\u4eec\n- \u6211\u4eec\u5c06\u4e86\u89e3 PyTorch \u4f18\u5316\u5668,\u5b83\u4eec\u5b9e\u73b0\u4e86\u6839\u636e\u635f\u5931\u51fd\u6570\u7684\u7ed3\u679c\u8c03\u6574\u6a21\u578b\u6743\u91cd\u7684\u7b97\u6cd5\n\n\u6700\u540e,\u6211\u4eec\u5c06\u628a\u6240\u6709\u8fd9\u4e9b\u7ed3\u5408\u8d77\u6765,\u770b\u4e00\u4e2a\u5b8c\u6574\u7684 PyTorch \u8bad\u7ec3\u5faa\u73af\u7684\u5b9e\u9645\u8fd0\u884c\u3002\n\n\n## \u6570\u636e\u96c6\u548c\u6570\u636e\u52a0\u8f7d\u5668\n \n``Dataset`` \u548c ``DataLoader`` \u7c7b\u5c01\u88c5\u4e86\u4ece\u5b58\u50a8\u4e2d\u63d0\u53d6\u6570\u636e\u5e76\u4ee5\u6279\u6b21\u5f62\u5f0f\u66b4\u9732\u7ed9\u8bad\u7ec3\u5faa\u73af\u7684\u8fc7\u7a0b\u3002\n\n``Dataset`` \u8d1f\u8d23\u8bbf\u95ee\u548c\u5904\u7406\u5355\u4e2a\u6570\u636e\u5b9e\u4f8b\u3002\n \n``DataLoader`` \u4ece ``Dataset`` \u4e2d\u63d0\u53d6\u6570\u636e\u5b9e\u4f8b(\u65e0\u8bba\u662f\u81ea\u52a8\u63d0\u53d6\u8fd8\u662f\u4f7f\u7528\u60a8\u5b9a\u4e49\u7684\u91c7\u6837\u5668),\u5c06\u5b83\u4eec\u6536\u96c6\u5230\u6279\u6b21\u4e2d,\u5e76\u8fd4\u56de\u7ed9\u60a8\u7684\u8bad\u7ec3\u5faa\u73af\u8fdb\u884c\u6d88\u8d39\u3002``DataLoader`` \u53ef\u4ee5\u4e0e\u6240\u6709\u7c7b\u578b\u7684\u6570\u636e\u96c6\u4e00\u8d77\u4f7f\u7528,\u65e0\u8bba\u5b83\u4eec\u5305\u542b\u4ec0\u4e48\u7c7b\u578b\u7684\u6570\u636e\u3002\n \n\u5bf9\u4e8e\u672c\u6559\u7a0b,\u6211\u4eec\u5c06\u4f7f\u7528 TorchVision \u63d0\u4f9b\u7684 Fashion-MNIST \u6570\u636e\u96c6\u3002\u6211\u4eec\u4f7f\u7528 ``torchvision.transforms.Normalize()`` \u6765\u96f6\u4e2d\u5fc3\u548c\u6807\u51c6\u5316\u56fe\u50cf\u74e6\u7247\u5185\u5bb9\u7684\u5206\u5e03,\u5e76\u4e0b\u8f7d\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u5206\u5272\u3002\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# PyTorch TensorBoard \u652f\u6301\nfrom torch.utils.tensorboard import SummaryWriter\nfrom datetime import datetime\n\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))])\n\n# \u521b\u5efa\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6570\u636e\u96c6,\u5982\u679c\u9700\u8981\u5219\u4e0b\u8f7d\ntraining_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\nvalidation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n\n# \u4e3a\u6211\u4eec\u7684\u6570\u636e\u96c6\u521b\u5efa\u6570\u636e\u52a0\u8f7d\u5668;\u8bad\u7ec3\u65f6\u6253\u4e71,\u9a8c\u8bc1\u65f6\u4e0d\u6253\u4e71\ntraining_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n\n# \u7c7b\u522b\u6807\u7b7e\nclasses = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n\n# \u62a5\u544a\u5206\u5272\u5927\u5c0f\nprint('\u8bad\u7ec3\u96c6\u6709 {} \u4e2a\u5b9e\u4f8b'.format(len(training_set)))\nprint('\u9a8c\u8bc1\u96c6\u6709 {} \u4e2a\u5b9e\u4f8b'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u50cf\u5f80\u5e38\u4e00\u6837,\u8ba9\u6211\u4eec\u53ef\u89c6\u5316\u6570\u636e\u4f5c\u4e3a\u5065\u5168\u6027\u68c0\u67e5:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\n# \u5185\u8054\u56fe\u50cf\u663e\u793a\u7684\u8f85\u52a9\u51fd\u6570\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5     # \u53cd\u6807\u51c6\u5316\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\ndataiter = iter(training_loader)\nimages, labels = next(dataiter)\n\n# \u4ece\u56fe\u50cf\u521b\u5efa\u7f51\u683c\u5e76\u663e\u793a\u5b83\u4eec\nimg_grid = torchvision.utils.make_grid(images)\nmatplotlib_imshow(img_grid, one_channel=True)\nprint('  '.join(classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u6a21\u578b\n\n\u6211\u4eec\u5728\u672c\u4f8b\u4e2d\u4f7f\u7528\u7684\u6a21\u578b\u662f LeNet-5 \u7684\u53d8\u4f53 - \u5982\u679c\u60a8\u89c2\u770b\u4e86\u672c\u7cfb\u5217\u7684\u524d\u51e0\u4e2a\u89c6\u9891,\u5e94\u8be5\u4f1a\u5f88\u719f\u6089\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch.nn.functional as F\n\n# PyTorch \u6a21\u578b\u7ee7\u627f\u81ea torch.nn.Module\nclass GarmentClassifier(nn.Module):\n    def __init__(self):\n        super(GarmentClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \n\nmodel = GarmentClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u635f\u5931\u51fd\u6570\n\n\u5bf9\u4e8e\u672c\u4f8b,\u6211\u4eec\u5c06\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u3002\u4e3a\u4e86\u6f14\u793a\u76ee\u7684,\u6211\u4eec\u5c06\u521b\u5efa\u865a\u62df\u8f93\u51fa\u548c\u6807\u7b7e\u503c\u7684\u6279\u6b21,\u5c06\u5b83\u4eec\u901a\u8fc7\u635f\u5931\u51fd\u6570,\u5e76\u68c0\u67e5\u7ed3\u679c\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n\n# \u6ce8\u610f:\u635f\u5931\u51fd\u6570\u671f\u671b\u6570\u636e\u4ee5\u6279\u6b21\u5f62\u5f0f,\u6240\u4ee5\u6211\u4eec\u521b\u5efa\u4e86 4 \u4e2a\u6279\u6b21\n# \u8868\u793a\u6a21\u578b\u5bf9\u7ed9\u5b9a\u8f93\u5165\u7684 10 \u4e2a\u7c7b\u522b\u4e2d\u6bcf\u4e00\u4e2a\u7684\u7f6e\u4fe1\u5ea6\ndummy_outputs = torch.rand(4, 10)\n# \u8868\u793a\u6b63\u786e\u7684\u7c7b\u522b\u5728\u6d4b\u8bd5\u7684 10 \u4e2a\u7c7b\u522b\u4e2d\ndummy_labels = torch.tensor([1, 5, 3, 7])\n    \nprint(dummy_outputs)\nprint(dummy_labels)\n\nloss = loss_fn(dummy_outputs, dummy_labels)\nprint('\u6b64\u6279\u6b21\u7684\u603b\u635f\u5931: {}'.format(loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f18\u5316\u5668\n\n\u5bf9\u4e8e\u672c\u4f8b,\u6211\u4eec\u5c06\u4f7f\u7528\u5e26\u52a8\u91cf\u7684\u7b80\u5355\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002\n\n\u5c1d\u8bd5\u4e00\u4e9b\u4f18\u5316\u65b9\u6848\u7684\u53d8\u4f53\u4f1a\u5f88\u6709\u542f\u53d1\u6027:\n\n- \u5b66\u4e60\u7387\u51b3\u5b9a\u4e86\u4f18\u5316\u5668\u91c7\u53d6\u7684\u6b65\u957f\u5927\u5c0f\u3002\u4e0d\u540c\u7684\u5b66\u4e60\u7387\u5bf9\u60a8\u7684\u8bad\u7ec3\u7ed3\u679c\u6709\u4f55\u5f71\u54cd,\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u65f6\u95f4\u65b9\u9762?\n- \u52a8\u91cf\u5728\u591a\u4e2a\u6b65\u9aa4\u4e2d\u5c06\u4f18\u5316\u5668\u63a8\u5411\u6700\u5f3a\u68af\u5ea6\u7684\u65b9\u5411\u3002\u6539\u53d8\u8fd9\u4e2a\u503c\u4f1a\u5bf9\u7ed3\u679c\u4ea7\u751f\u4ec0\u4e48\u5f71\u54cd?\n- \u5c1d\u8bd5\u4e00\u4e9b\u4e0d\u540c\u7684\u4f18\u5316\u7b97\u6cd5,\u5982\u5e73\u5747 SGD\u3001Adagrad \u6216 Adam\u3002\u60a8\u7684\u7ed3\u679c\u6709\u4f55\u4e0d\u540c?\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u5728 torch.optim \u5305\u4e2d\u6307\u5b9a\u4f18\u5316\u5668\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u8bad\u7ec3\u5faa\u73af\n\n\u4e0b\u9762,\u6211\u4eec\u6709\u4e00\u4e2a\u6267\u884c\u4e00\u4e2a\u8bad\u7ec3\u5468\u671f\u7684\u51fd\u6570\u3002\u5b83\n\u4ece DataLoader \u679a\u4e3e\u6570\u636e,\u5e76\u5728\u5faa\u73af\u7684\u6bcf\u4e00\u6b21\u901a\u8fc7\u65f6\u6267\u884c\u4ee5\u4e0b\u64cd\u4f5c:\n\n- \u4ece DataLoader \u83b7\u53d6\u4e00\u6279\u8bad\u7ec3\u6570\u636e\n- \u5c06\u4f18\u5316\u5668\u7684\u68af\u5ea6\u5f52\u96f6\n- \u6267\u884c\u63a8\u7406 - \u4e5f\u5c31\u662f\u4ece\u6a21\u578b\u83b7\u53d6\u8f93\u5165\u6279\u6b21\u7684\u9884\u6d4b\n- \u8ba1\u7b97\u8be5\u7ec4\u9884\u6d4b\u4e0e\u6570\u636e\u96c6\u4e0a\u7684\u6807\u7b7e\u4e4b\u95f4\u7684\u635f\u5931\n- \u8ba1\u7b97\u5b66\u4e60\u6743\u91cd\u7684\u53cd\u5411\u68af\u5ea6\n- \u544a\u8bc9\u4f18\u5316\u5668\u6267\u884c\u4e00\u4e2a\u5b66\u4e60\u6b65\u9aa4 - \u4e5f\u5c31\u662f\u6839\u636e\u6211\u4eec\u9009\u62e9\u7684\u4f18\u5316\u7b97\u6cd5,\u57fa\u4e8e\u8be5\u6279\u6b21\u89c2\u5bdf\u5230\u7684\u68af\u5ea6\u6765\u8c03\u6574\u6a21\u578b\u7684\u5b66\u4e60\u6743\u91cd\n- \u5b83\u6bcf 1000 \u4e2a\u6279\u6b21\u62a5\u544a\u4e00\u6b21\u635f\u5931\u3002\n- \u6700\u540e,\u5b83\u62a5\u544a\u6700\u540e 1000 \u4e2a\u6279\u6b21\u7684\u5e73\u5747\u6bcf\u6279\u6b21\u635f\u5931,\u4ee5\u4fbf\u4e0e\u9a8c\u8bc1\u8fd0\u884c\u8fdb\u884c\u6bd4\u8f83\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n    running_loss = 0.\n    last_loss = 0.\n    \n    # \u8fd9\u91cc,\u6211\u4eec\u4f7f\u7528 enumerate(training_loader) \u800c\u4e0d\u662f\n    # iter(training_loader),\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u8ddf\u8e2a\u6279\u6b21\u7d22\u5f15\u5e76\u8fdb\u884c\u4e00\u4e9b\u5468\u671f\u5185\u62a5\u544a\n    for i, data in enumerate(training_loader):\n        # \u6bcf\u4e2a\u6570\u636e\u5b9e\u4f8b\u90fd\u662f\u4e00\u4e2a\u8f93\u5165 + \u6807\u7b7e\u5bf9\n        inputs, labels = data\n        \n        # \u5bf9\u4e8e\u6bcf\u4e2a\u6279\u6b21,\u5c06\u68af\u5ea6\u5f52\u96f6!\n        optimizer.zero_grad()\n        \n        # \u5bf9\u8be5\u6279\u6b21\u8fdb\u884c\u9884\u6d4b\n        outputs = model(inputs)\n        \n        # \u8ba1\u7b97\u635f\u5931\u53ca\u5176\u68af\u5ea6\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        \n        # \u8c03\u6574\u5b66\u4e60\u6743\u91cd\n        optimizer.step()\n        \n        # \u6536\u96c6\u6570\u636e\u5e76\u62a5\u544a\n        running_loss += loss.item()\n        if i % 1000 == 999:\n            last_loss = running_loss / 1000 # \u6bcf\u6279\u6b21\u635f\u5931\n            print('  \u6279\u6b21 {} \u635f\u5931: {}'.format(i + 1, last_loss))\n            tb_x = epoch_index * len(training_loader) + i + 1\n            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n            running_loss = 0.\n            \n    return last_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u6bcf\u5468\u671f\u6d3b\u52a8\n\n\u6211\u4eec\u6bcf\u4e2a\u5468\u671f\u9700\u8981\u505a\u7684\u4e8b\u60c5\u6709:\n\n- \u901a\u8fc7\u68c0\u67e5\u672a\u7528\u4e8e\u8bad\u7ec3\u7684\u4e00\u7ec4\u6570\u636e\u4e0a\u7684\u76f8\u5bf9\u635f\u5931\u6765\u6267\u884c\u9a8c\u8bc1,\u5e76\u62a5\u544a\u8fd9\u4e00\u70b9\n- \u4fdd\u5b58\u6a21\u578b\u7684\u526f\u672c\n\n\u5728\u8fd9\u91cc,\u6211\u4eec\u5c06\u5728 TensorBoard \u4e2d\u8fdb\u884c\u62a5\u544a\u3002\u8fd9\u9700\u8981\u8f6c\u5230\u547d\u4ee4\u884c\u542f\u52a8 TensorBoard,\u5e76\u5728\u53e6\u4e00\u4e2a\u6d4f\u89c8\u5668\u9009\u9879\u5361\u4e2d\u6253\u5f00\u5b83\u3002\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u5728\u5355\u72ec\u7684\u5355\u5143\u683c\u4e2d\u521d\u59cb\u5316,\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u8f7b\u677e\u5730\u5c06\u66f4\u591a\u5468\u671f\u6dfb\u52a0\u5230\u540c\u4e00\u8fd0\u884c\u4e2d\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\nwriter = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\nepoch_number = 0\n\nEPOCHS = 5\n\nbest_vloss = 1_000_000.\n\nfor epoch in range(EPOCHS):\n    print('\u5468\u671f {}:'.format(epoch_number + 1))\n    \n    # \u786e\u4fdd\u68af\u5ea6\u8ddf\u8e2a\u5df2\u6253\u5f00,\u5e76\u5bf9\u6570\u636e\u8fdb\u884c\u4e00\u6b21\u4f20\u9012\n    model.train(True)\n    avg_loss = train_one_epoch(epoch_number, writer)\n    \n\n    running_vloss = 0.0\n    # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f,\u7981\u7528 dropout \u5e76\u4f7f\u7528\u6279\u91cf\u89c4\u8303\u5316\u7684\u7fa4\u4f53\u7edf\u8ba1\u6570\u636e\u3002\n    model.eval()\n\n    # \u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u5e76\u51cf\u5c11\u5185\u5b58\u6d88\u8017\u3002\n    with torch.no_grad():\n        for i, vdata in enumerate(validation_loader):\n            vinputs, vlabels = vdata\n            voutputs = model(vinputs)\n            vloss = loss_fn(voutputs, vlabels)\n            running_vloss += vloss\n    \n    avg_vloss = running_vloss / (i + 1)\n    print('\u635f\u5931 \u8bad\u7ec3 {} \u6709\u6548 {}'.format(avg_loss, avg_vloss))\n    \n    # \u8bb0\u5f55\u6bcf\u6279\u6b21\u5e73\u5747\u7684\u8fd0\u884c\u635f\u5931\n    # \u5bf9\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\n    writer.add_scalars('\u8bad\u7ec3\u4e0e\u9a8c\u8bc1\u635f\u5931',\n                    { '\u8bad\u7ec3' : avg_loss, '\u9a8c\u8bc1' : avg_vloss },\n                    epoch_number + 1)\n    writer.flush()\n    \n    # \u8ddf\u8e2a\u6700\u4f73\u6027\u80fd,\u5e76\u4fdd\u5b58\u6a21\u578b\u7684\u72b6\u6001\n    if avg_vloss < best_vloss:\n        best_vloss = avg_vloss\n        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n        torch.save(model.state_dict(), model_path)\n    \n    epoch_number += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u8981\u52a0\u8f7d\u4fdd\u5b58\u7684\u6a21\u578b\u7248\u672c:\n\n.. code:: python\n\n    saved_model = GarmentClassifier()\n    saved_model.load_state_dict(torch.load(PATH))\n\n\u4e00\u65e6\u52a0\u8f7d\u4e86\u6a21\u578b,\u5b83\u5c31\u53ef\u4ee5\u7528\u4e8e\u60a8\u9700\u8981\u7684\u4efb\u4f55\u4e8b\u60c5 -\n\u66f4\u591a\u8bad\u7ec3\u3001\u63a8\u7406\u6216\u5206\u6790\u3002\n\n\u8bf7\u6ce8\u610f,\u5982\u679c\u60a8\u7684\u6a21\u578b\u6709\u5f71\u54cd\u6a21\u578b\u7ed3\u6784\u7684\u6784\u9020\u51fd\u6570\u53c2\u6570,\u60a8\u9700\u8981\u63d0\u4f9b\u5b83\u4eec\u5e76\u4ee5\u4e0e\u4fdd\u5b58\u65f6\u76f8\u540c\u7684\u65b9\u5f0f\u914d\u7f6e\u6a21\u578b\u3002\n\n## \u5176\u4ed6\u8d44\u6e90\n\n-  pytorch.org \u4e0a\u7684\u6570\u636e\u5de5\u5177\u6587\u6863,\u5305\u62ec Dataset \u548c DataLoader\n-  \u5173\u4e8e\u4f7f\u7528\u56fa\u5b9a\u5185\u5b58\u8fdb\u884c GPU \u8bad\u7ec3\u7684\u8bf4\u660e\n-  TorchVision\u3001TorchText \u548c TorchAudio \u4e2d\u53ef\u7528\u6570\u636e\u96c6\u7684\u6587\u6863\n-  PyTorch \u4e2d\u53ef\u7528\u635f\u5931\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}