{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[\u57fa\u7840\u77e5\u8bc6](intro.html) ||\n[\u5feb\u901f\u5165\u95e8](quickstart_tutorial.html) ||\n[\u5f20\u91cf](tensorqs_tutorial.html) ||\n**\u6570\u636e\u96c6\u4e0e\u6570\u636e\u52a0\u8f7d\u5668** ||\n[Transforms](transforms_tutorial.html) ||\n[\u6784\u5efa\u795e\u7ecf\u7f51\u7edc](buildmodel_tutorial.html) ||\n[\u81ea\u52a8\u5fae\u5206](autogradqs_tutorial.html) ||\n[\u4f18\u5316\u6a21\u578b\u53c2\u6570](optimization_tutorial.html) ||\n[\u4fdd\u5b58\u548c\u52a0\u8f7d\u6a21\u578b](saveloadrun_tutorial.html)\n\n# \u6570\u636e\u96c6\u4e0e\u6570\u636e\u52a0\u8f7d\u5668\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\u5904\u7406\u6570\u636e\u6837\u672c\u7684\u4ee3\u7801\u53ef\u80fd\u4f1a\u53d8\u5f97\u6df7\u4e71\u4e14\u96be\u4ee5\u7ef4\u62a4\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5e0c\u671b\u6570\u636e\u96c6\u4ee3\u7801\u4e0e\u6a21\u578b\u8bad\u7ec3\u4ee3\u7801\u89e3\u8026\uff0c\n\u4ee5\u63d0\u9ad8\u53ef\u8bfb\u6027\u548c\u6a21\u5757\u5316\u3002PyTorch \u63d0\u4f9b\u4e86\u4e24\u4e2a\u6570\u636e\u5904\u7406\u7684\u57fa\u672c\u5de5\u5177\uff1a`torch.utils.data.DataLoader` \u548c `torch.utils.data.Dataset`\uff0c\n\u5b83\u4eec\u5141\u8bb8\u60a8\u4f7f\u7528\u9884\u52a0\u8f7d\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u60a8\u81ea\u5df1\u7684\u6570\u636e\u3002`Dataset` \u5b58\u50a8\u6837\u672c\u53ca\u5176\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\n\u800c `DataLoader` \u5219\u4e3a `Dataset` \u5305\u88c5\u4e86\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u4ee5\u4fbf\u4e8e\u8bbf\u95ee\u6837\u672c\u3002\n\nPyTorch \u57df\u5e93\u63d0\u4f9b\u4e86\u8bb8\u591a\u9884\u52a0\u8f7d\u7684\u6570\u636e\u96c6\uff08\u4f8b\u5982 FashionMNIST\uff09\uff0c\n\u8fd9\u4e9b\u6570\u636e\u96c6\u662f `torch.utils.data.Dataset` \u7684\u5b50\u7c7b\uff0c\u5e76\u5b9e\u73b0\u4e86\u7279\u5b9a\u4e8e\u8be5\u6570\u636e\u7684\u51fd\u6570\u3002\n\u5b83\u4eec\u53ef\u4ee5\u7528\u4e8e\u6a21\u578b\u7684\u539f\u578b\u8bbe\u8ba1\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002\u60a8\u53ef\u4ee5\u5728\u4ee5\u4e0b\u94fe\u63a5\u627e\u5230\u8fd9\u4e9b\u6570\u636e\u96c6\uff1a\n`\u56fe\u50cf\u6570\u636e\u96c6 <https://pytorch.org/vision/stable/datasets.html`\u3001\n`\u6587\u672c\u6570\u636e\u96c6 <https://pytorch.org/text/stable/datasets.html>` \u548c\n`\u97f3\u9891\u6570\u636e\u96c6 <https://pytorch.org/audio/stable/datasets.html>`\u3002\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u52a0\u8f7d\u6570\u636e\u96c6\n\n\u4e0b\u9762\u662f\u4e00\u4e2a\u4ece TorchVision \u52a0\u8f7d [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist/) \u6570\u636e\u96c6\u7684\u793a\u4f8b\u3002\nFashion-MNIST \u662f Zalando \u7684\u5546\u54c1\u56fe\u7247\u6570\u636e\u96c6\uff0c\u5305\u62ec 60,000 \u4e2a\u8bad\u7ec3\u6837\u672c\u548c 10,000 \u4e2a\u6d4b\u8bd5\u6837\u672c\u3002\u6bcf\u4e2a\u6837\u672c\u5305\u542b\u4e00\u4e2a 28\u00d728 \u7684\u7070\u5ea6\u56fe\u50cf\u548c\u4e00\u4e2a\u6765\u81ea 10 \u4e2a\u7c7b\u522b\u4e4b\u4e00\u7684\u6807\u7b7e\u3002\n\n\u6211\u4eec\u4f7f\u7528\u4ee5\u4e0b\u53c2\u6570\u52a0\u8f7d [FashionMNIST \u6570\u636e\u96c6](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)\uff1a\n\n- ``root`` \u662f\u5b58\u50a8\u8bad\u7ec3/\u6d4b\u8bd5\u6570\u636e\u7684\u8def\u5f84\uff0c\n- ``train`` \u6307\u5b9a\u662f\u8bad\u7ec3\u96c6\u8fd8\u662f\u6d4b\u8bd5\u96c6\uff0c\n- ``download=True`` \u8868\u793a\u5982\u679c\u6570\u636e\u5728 ``root`` \u8def\u5f84\u4e2d\u4e0d\u53ef\u7528\uff0c\u5219\u4ece\u4e92\u8054\u7f51\u4e0b\u8f7d\u6570\u636e\uff0c\n- ``transform`` \u548c ``target_transform`` \u6307\u5b9a\u7279\u5f81\u548c\u6807\u7b7e\u7684\u8f6c\u6362\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\nfrom torchvision.io import read_image\nimport pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\n\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor()\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor()\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u8fed\u4ee3\u548c\u53ef\u89c6\u5316\u6570\u636e\u96c6\n\n\u6211\u4eec\u53ef\u4ee5\u50cf\u5217\u8868\u4e00\u6837\u624b\u52a8\u7d22\u5f15 ``Datasets``\uff1a``training_data[index]``\u3002\n\u4f7f\u7528 `matplotlib` \u6765\u53ef\u89c6\u5316\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e00\u4e9b\u6837\u672c\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "labels_map = {\n    0: \"T-Shirt\",\n    1: \"Trouser\",\n    2: \"Pullover\",\n    3: \"Dress\",\n    4: \"Coat\",\n    5: \"Sandal\",\n    6: \"Shirt\",\n    7: \"Sneaker\",\n    8: \"Bag\",\n    9: \"Ankle Boot\",\n}\nfigure = plt.figure(figsize=(8, 8))\ncols, rows = 3, 3\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n    img, label = training_data[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(labels_map[label])\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "..\n .. figure:: /_static/img/basics/fashion_mnist.png\n   :alt: fashion_mnist\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\n\n\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7c7b\u5fc5\u987b\u5b9e\u73b0\u4e09\u4e2a\u51fd\u6570\uff1a`__init__`\u3001`__len__` \u548c `__getitem__`\u3002\u8bf7\u770b\u8fd9\u4e2a\u5b9e\u73b0\u793a\u4f8b\uff1bFashionMNIST \u56fe\u50cf\u5b58\u50a8\u5728\u76ee\u5f55 `img_dir` \u4e2d\uff0c\u5b83\u4eec\u7684\u6807\u7b7e\u5355\u72ec\u5b58\u50a8\u5728 CSV \u6587\u4ef6 ``annotations_file`` \u4e2d\u3002\n\n\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u5982\u4e0b\uff1a\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``__init__``\n\n__init__ \u51fd\u6570\u5728\u5b9e\u4f8b\u5316\u6570\u636e\u96c6\u5bf9\u8c61\u65f6\u8fd0\u884c\u4e00\u6b21\u3002\u6211\u4eec\u521d\u59cb\u5316\u5305\u542b\u56fe\u50cf\u7684\u76ee\u5f55\u3001\u6ce8\u91ca\u6587\u4ef6\u548c\u4e24\u79cd\u8f6c\u6362\uff08\u5728\u4e0b\u4e00\u90e8\u5206\u4e2d\u5c06\u66f4\u8be6\u7ec6\u5730\u4ecb\u7ecd\uff09\u3002\n\nlabels.csv \u6587\u4ef6\u7684\u5185\u5bb9\u5982\u4e0b: ::\n\n    tshirt1.jpg, 0\n    tshirt2.jpg, 0\n    ......\n    ankleboot999.jpg, 9\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n    self.img_labels = pd.read_csv(annotations_file)\n    self.img_dir = img_dir\n    self.transform = transform\n    self.target_transform = target_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``__len__``\n\n__len__ \u51fd\u6570\u8fd4\u56de\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u6570\u91cf\u3002\n\nExample:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def __len__(self):\n    return len(self.img_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ``__getitem__``\n\n__getitem__ \u51fd\u6570\u52a0\u8f7d\u5e76\u8fd4\u56de\u6570\u636e\u96c6\u4e2d\u7ed9\u5b9a\u7d22\u5f15 ``idx`` \u7684\u6837\u672c\u3002\u6839\u636e\u7d22\u5f15\uff0c\u5b83\u786e\u5b9a\u56fe\u50cf\u5728\u78c1\u76d8\u4e0a\u7684\u4f4d\u7f6e\uff0c\n\u4f7f\u7528 ``read_image`` \u5c06\u5176\u8f6c\u6362\u4e3a\u5f20\u91cf\uff0c\u4ece ``self.img_labels`` \u4e2d\u7684 CSV \u6570\u636e\u4e2d\u68c0\u7d22\u76f8\u5e94\u7684\u6807\u7b7e\uff0c\n\u5bf9\u5b83\u4eec\u8c03\u7528\u8f6c\u6362\u51fd\u6570\uff08\u5982\u679c\u9002\u7528\uff09\uff0c\u5e76\u4ee5\u5143\u7ec4\u5f62\u5f0f\u8fd4\u56de\u5f20\u91cf\u56fe\u50cf\u548c\u76f8\u5e94\u7684\u6807\u7b7e\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def __getitem__(self, idx):\n    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n    image = read_image(img_path)\n    label = self.img_labels.iloc[idx, 1]\n    if self.transform:\n        image = self.transform(image)\n    if self.target_transform:\n        label = self.target_transform(label)\n    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u4f7f\u7528\u6570\u636e\u52a0\u8f7d\u5668\u4e3a\u8bad\u7ec3\u51c6\u5907\u6570\u636e\n``Dataset`` \u4e00\u6b21\u68c0\u7d22\u6211\u4eec\u6570\u636e\u96c6\u7684\u4e00\u4e2a\u6837\u672c\u7684\u7279\u5f81\u548c\u6807\u7b7e\u3002\u5728\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u6211\u4eec\u901a\u5e38\u5e0c\u671b\u4ee5\u201c\u5c0f\u6279\u91cf\u201d\u7684\u65b9\u5f0f\u4f20\u9012\u6837\u672c\uff0c\u5728\u6bcf\u4e2a\u5468\u671f\u91cd\u65b0\u968f\u673a\u6392\u5217\u6570\u636e\u4ee5\u51cf\u5c11\u6a21\u578b\u8fc7\u62df\u5408\uff0c\u5e76\u4f7f\u7528 Python \u7684 ``multiprocessing`` \u52a0\u901f\u6570\u636e\u68c0\u7d22\u3002\n\n``DataLoader`` \u662f\u4e00\u4e2a\u53ef\u8fed\u4ee3\u5bf9\u8c61\uff0c\u5b83\u901a\u8fc7\u7b80\u5355\u7684 API \u4e3a\u6211\u4eec\u62bd\u8c61\u4e86\u8fd9\u4e9b\u590d\u6742\u6027\u3002\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u901a\u8fc7 DataLoader \u8fdb\u884c\u8fed\u4ee3\n\nWe have loaded that dataset into the ``DataLoader`` and can iterate through the dataset as needed.\nEach iteration below returns a batch of ``train_features`` and ``train_labels`` (containing ``batch_size=64`` features and labels respectively).\nBecause we specified ``shuffle=True``, after we iterate over all batches the data is shuffled (for finer-grained control over\nthe data loading order, take a look at [Samplers](https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler)).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# \u6211\u4eec\u5df2\u7ecf\u5c06\u6570\u636e\u96c6\u52a0\u8f7d\u5230 ``DataLoader`` \u4e2d\uff0c\u5e76\u53ef\u4ee5\u6839\u636e\u9700\u8981\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u8fed\u4ee3\u3002\n# \u4e0b\u9762\u7684\u6bcf\u6b21\u8fed\u4ee3\u90fd\u4f1a\u8fd4\u56de\u4e00\u4e2a\u6279\u6b21\u7684 ``train_features`` \u548c ``train_labels``\n# \uff08\u5206\u522b\u5305\u542b ``batch_size=64`` \u4e2a\u7279\u5f81\u548c\u6807\u7b7e\uff09\u3002\u56e0\u4e3a\u6211\u4eec\u6307\u5b9a\u4e86 ``shuffle=True``\uff0c\n# \u6240\u4ee5\u5728\u8fed\u4ee3\u5b8c\u6240\u6709\u6279\u6b21\u540e\u6570\u636e\u4f1a\u88ab\u91cd\u65b0\u6d17\u724c\uff08\u5982\u679c\u60f3\u5bf9\u6570\u636e\u52a0\u8f7d\u987a\u5e8f\u8fdb\u884c\u66f4\u7cbe\u7ec6\u7684\u63a7\u5236\uff0c\n# \u8bf7\u67e5\u770b `Samplers <https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler>`_\uff09\u3002\n\n# Display image and label.\ntrain_features, train_labels = next(iter(train_dataloader))\nprint(f\"Feature batch shape: {train_features.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_features[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img, cmap=\"gray\")\nplt.show()\nprint(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u5ef6\u4f38\u9605\u8bfb\n- [torch.utils.data API](https://pytorch.org/docs/stable/data.html)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}