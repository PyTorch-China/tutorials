


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>性能调优指南 &mdash; PyTorch Tutorials 2.3.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom2.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="(beta) Compiling the optimizer with torch.compile" href="../compiling_optimizer.html" />
    <link rel="prev" title="自动混合精度" href="amp_recipe.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  2.3.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">PyTorch 示例</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../recipes_index.html">所有示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prototype/prototype_index.html">原型示例</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch 入门</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/intro.html">基础知识</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/quickstart_tutorial.html">快速入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/tensorqs_tutorial.html">张量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/data_tutorial.html">数据集与数据加载器</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/buildmodel_tutorial.html">构建神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/autogradqs_tutorial.html">自动微分</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/optimization_tutorial.html">优化模型参数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/basics/saveloadrun_tutorial.html">保存和加载模型</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch 视频教程</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt.html">PyTorch 介绍 - YouTube</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/introyt1_tutorial.html">PyTorch 简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/tensors_deeper_tutorial.html">PyTorch Tensors 介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/autogradyt_tutorial.html">自动微分基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/modelsyt_tutorial.html">使用 PyTorch 构建模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard 支持</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/trainingyt.html">使用 PyTorch 训练模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/introyt/captumyt.html">使用 Captum 进行模型理解</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">学习 PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/deep_learning_60min_blitz.html">PyTorch 深度学习：60分钟入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/pytorch_with_examples.html">跟着示例学习 PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/nn_tutorial.html"><cite>torch.nn</cite> 具体是什么?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tensorboard_tutorial.html">TensorBoard 可视化模型、数据和训练</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">图片与视频</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchvision_tutorial.html">TorchVision 对象检测微调教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/transfer_learning_tutorial.html">计算机视觉迁移学习教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/fgsm_tutorial.html">对抗样本生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dcgan_faces_tutorial.html">DCGAN 教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks 教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/vt_tutorial.html">优化视觉 Transformer 模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tiatoolbox_tutorial.html">PyTorch 和 TIAToolbox 进行全切片图像分类</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">音频</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_io_tutorial.html">音频 I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_resampling_tutorial.html">Audio 重采样</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_data_augmentation_tutorial.html">音频数据增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_feature_extractions_tutorial.html">音频特征提取</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_feature_augmentation_tutorial.html">音频特征增强</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/audio_datasets_tutorial.html">音频数据集</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/speech_recognition_pipeline_tutorial.html">Wav2Vec2 进行语音识别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/text_to_speech_with_torchaudio.html">Tacotron2 文本转语音</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/forced_alignment_with_torchaudio_tutorial.html">Wav2Vec2 强制对齐</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">文本</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/bettertransformer_tutorial.html">使用 Better Transformer 进行快速 Transformer 推断</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/char_rnn_classification_tutorial.html">从零开始的自然语言处理：字符级 RNN 进行姓名分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/char_rnn_generation_tutorial.html">从零开始的自然语言处理：字符级 RNN 生成姓名</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/seq2seq_translation_tutorial.html">从零开始的自然语言处理：序列到序列网络和注意力机制进行翻译</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/text_sentiment_ngrams_tutorial.html">torchtext 文本分类</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/translation_transformer.html">数据获取和处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/translation_transformer.html#transformer-seq2seq-network">使用 Transformer 的 Seq2Seq Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/translation_transformer.html#id2">数据整理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/translation_transformer.html#id3">引用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/torchtext_custom_dataset_tutorial.html">Torchtext 预处理自定义文本数据集</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">后端</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/onnx/intro_onnx.html">ONNX 介绍</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">强化学习</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/reinforcement_q_learning.html">强化学习 (DQN) 教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/reinforcement_ppo.html">使用 TorchRL 强化学习 (PPO) 教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/mario_rl_tutorial.html">训练一个马里奥游戏的 RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/pendulum.html">Pendulum：使用 TorchRL 编写环境和transforms</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">部署 PyTorch 模型</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/onnx/intro_onnx.html">ONNX 介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/flask_rest_api_tutorial.html">API 定义</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/flask_rest_api_tutorial.html#id1">依赖</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/flask_rest_api_tutorial.html#web-server">简单的 Web Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/flask_rest_api_tutorial.html#id2">推理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/Intro_to_TorchScript_tutorial.html">TorchScript 介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_export.html">在 C++ 中加载 TorchScript 模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/super_resolution_with_onnxruntime.html">(optional) PyTorch 模型导出到 ONNX 并使用 ONNX Runtime 运行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/realtime_rpi.html">在 Raspberry Pi 4 上进行实时推理 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分析 PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/profiler.html">PyTorch 模型分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/hta_intro_tutorial.html">Holistic Trace Analysis 介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/hta_trace_diff_tutorial.html">Holistic Trace Analysis 差异分析</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FX 代码转换</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">前端 APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch 扩展</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">优化模型</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/profiler.html">PyTorch 模型分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/hyperparameter_tuning_tutorial.html">Ray Tune 超参数调优</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/vt_tutorial.html">优化视觉 Transformer 模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-torch-compile">Using SDPA with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-attn-bias-subclasses">Using SDPA with attn_bias subclasses`</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/knowledge_distillation_tutorial.html">Knowledge Distillation 教程</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">分布式并行训练</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/dist_overview.html">PyTorch 分布式概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/ddp_series_intro.html">PyTorch 分布式并行 - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/ddp_pipeline.html">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Edge with ExecuTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html">导出到 ExecuTorch 教程</a></li>
<li class="toctree-l1"><a class="reference external" href=" https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html">使用C++运行 ExecuTorch 教程</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html">使用 ExecuTorch SDK 分析模型</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-ios.html">构建 ExecuTorch iOS Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-android.html">构建 ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html">Lowering a Model as a Delegate</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">推荐系统</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">多模态</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginner/flava_finetuning_tutorial.html">TorchMultimodal 教程：微调 FLAVA</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
          <li><a href="../recipes_index.html">PyTorch 示例</a> &gt;</li>
        
      <li>性能调优指南</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/recipes/recipes/tuning_guide.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">recipes/recipes/tuning_guide</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-recipes-recipes-tuning-guide-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="sphx-glr-recipes-recipes-tuning-guide-py">
<span id="id1"></span><h1>性能调优指南<a class="headerlink" href="#sphx-glr-recipes-recipes-tuning-guide-py" title="Permalink to this heading">¶</a></h1>
<p><strong>作者</strong>: <a class="reference external" href="https://github.com/szmigacz">Szymon Migacz</a></p>
<p>性能调优指南是一组优化和最佳实践,可以加速PyTorch中深度学习模型的训练和推理。
提出的技术通常只需要更改几行代码,就可以应用于各个领域的广泛深度学习模型。</p>
<div class="section" id="id2">
<h2>一般优化<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h2>
<div class="section" id="id3">
<h3>启用异步数据加载和数据增强<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<p><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">torch.utils.data.DataLoader</a>
支持在单独的工作子进程中异步加载数据和进行数据增强。
<code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> 的默认设置是 <code class="docutils literal notranslate"><span class="pre">num_workers=0</span></code>，
这意味着数据加载是同步的,并在主进程中完成。
因此,主训练进程必须等待数据可用才能继续执行。</p>
<p>设置 <code class="docutils literal notranslate"><span class="pre">num_workers</span> <span class="pre">&gt;</span> <span class="pre">0</span></code> 可启用异步数据加载,并实现训练和数据加载之间的重叠。
<code class="docutils literal notranslate"><span class="pre">num_workers</span></code> 应根据工作负载、CPU、GPU 和训练数据的位置进行调整。</p>
<p><code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> 接受 <code class="docutils literal notranslate"><span class="pre">pin_memory</span></code> 参数,默认为 <code class="docutils literal notranslate"><span class="pre">False</span></code>。
在使用 GPU 时,最好设置 <code class="docutils literal notranslate"><span class="pre">pin_memory=True</span></code>,这会指示 <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> 使用锁页内存,
并启用从主机到 GPU 的更快和异步内存复制。</p>
</div>
<div class="section" id="id4">
<h3>对于验证或推理,禁用梯度计算<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>PyTorch 会保存涉及需要梯度的张量的所有操作的中间缓冲区。
通常在验证或推理时不需要梯度。
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad">torch.no_grad()</a>
上下文管理器可应用于禁用指定代码块内的梯度计算,这可加快执行速度并减少所需内存量。
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad">torch.no_grad()</a>
也可以用作函数装饰器。</p>
</div>
<div class="section" id="id6">
<h3>对于直接后跟批量归一化的卷积,禁用偏置<a class="headerlink" href="#id6" title="Permalink to this heading">¶</a></h3>
<p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">torch.nn.Conv2d()</a>
具有 <code class="docutils literal notranslate"><span class="pre">bias</span></code> 参数,默认为 <a href="#id7"><span class="problematic" id="id8">``</span></a>True``(对于
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d</a>
和
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d">Conv3d</a>
也是如此)。</p>
<p>如果 <code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> 层直接后跟 <code class="docutils literal notranslate"><span class="pre">nn.BatchNorm2d</span></code> 层,
则卷积中的偏置是不需要的,请改用
<code class="docutils literal notranslate"><span class="pre">nn.Conv2d(...,</span> <span class="pre">bias=False,</span> <span class="pre">....)</span></code>。不需要偏置,因为在第一步中 <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> 会减去均值,
这实际上会抵消偏置的效果。</p>
<p>只要 <a href="#id9"><span class="problematic" id="id10">``</span></a>BatchNorm``(或其他归一化层)在与卷积偏置相同的维度上进行归一化,
这也适用于1d和3d卷积。</p>
<p><a class="reference external" href="https://github.com/pytorch/vision">torchvision</a>
中可用的模型已经实现了这种优化。</p>
</div>
<div class="section" id="parameter-grad-none-model-zero-grad-optimizer-zero-grad">
<h3>使用 parameter.grad = None 而不是 model.zero_grad() 或 optimizer.zero_grad()<a class="headerlink" href="#parameter-grad-none-model-zero-grad-optimizer-zero-grad" title="Permalink to this heading">¶</a></h3>
<p>不要调用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="c1"># 或</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</div>
<p>而是使用以下方法清零梯度:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
<p>第二段代码不会清零每个参数的内存,
而且在后续的反向传播过程中使用赋值而不是累加来存储梯度,这减少了内存操作的数量。</p>
<p>将梯度设置为 <code class="docutils literal notranslate"><span class="pre">None</span></code> 与将其设置为零有略微不同的数值行为,
更多详细信息请参阅
<a class="reference external" href="https://pytorch.org/docs/master/optim.html#torch.optim.Optimizer.zero_grad">文档</a>。</p>
<p>或者,从 PyTorch 1.7 开始,调用 <code class="docutils literal notranslate"><span class="pre">model</span></code> 或
<code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad(set_to_none=True)</span></code>。</p>
</div>
<div class="section" id="id12">
<h3>融合点运算<a class="headerlink" href="#id12" title="Permalink to this heading">¶</a></h3>
<p>点运算 (元素级加法、乘法、数学函数 - <code class="docutils literal notranslate"><span class="pre">sin()</span></code>、<code class="docutils literal notranslate"><span class="pre">cos()</span></code>、<code class="docutils literal notranslate"><span class="pre">sigmoid()</span></code> 等) 可以融合为单个内核,
从而分摊内存访问时间和内核启动时间。</p>
<p><a class="reference external" href="https://pytorch.org/docs/stable/jit.html">PyTorch JIT</a> 可以自动融合内核,
尽管编译器中可能还有未实现的其他融合机会,并且并非所有设备类型都得到同等支持。</p>
<p>点运算是内存密集型的,PyTorch 会为每个操作启动单独的内核。
每个内核都会从内存加载数据、执行计算(这一步通常是廉价的)并将结果存储回内存。</p>
<p>融合的算子只为多个融合的点运算启动一个内核,并且只需要一次从内存加载/存储数据。
这使得 JIT 非常适用于激活函数、优化器、自定义 RNN 单元等。</p>
<p>在最简单的情况下,可以通过将
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script">torch.jit.script</a>
装饰器应用于函数定义来启用融合,例如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">fused_gelu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="mf">1.41421</span><span class="p">))</span>
</pre></div>
</div>
<p>有关更高级用法,请参阅
<a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript 文档</a>。</p>
</div>
<div class="section" id="channels-last">
<h3>为计算机视觉模型启用 channels_last 内存格式<a class="headerlink" href="#channels-last" title="Permalink to this heading">¶</a></h3>
<p>PyTorch 1.5 引入了对卷积网络 <code class="docutils literal notranslate"><span class="pre">channels_last</span></code> 内存格式的支持。
此格式旨在与
<a class="reference external" href="https://pytorch.org/docs/stable/amp.html">AMP</a> 结合使用,
进一步加速使用
<a class="reference external" href="https://www.nvidia.com/en-us/data-center/tensor-cores/">Tensor Cores</a> 的卷积神经网络。</p>
<p>对 <code class="docutils literal notranslate"><span class="pre">channels_last</span></code> 的支持是实验性的,但预计可以用于标准计算机视觉模型(例如 ResNet-50、SSD)。
要将模型转换为 <code class="docutils literal notranslate"><span class="pre">channels_last</span></code> 格式,请按照
<a class="reference external" href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html">Channels Last Memory Format Tutorial</a> 中的说明操作。
该教程包括一节关于
<a class="reference external" href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html#converting-existing-models">转换现有模型</a>。</p>
</div>
<div class="section" id="id14">
<h3>检查点中间缓冲区<a class="headerlink" href="#id14" title="Permalink to this heading">¶</a></h3>
<p>缓冲区检查点是一种技术,用于缓解模型训练的内存容量负担。
与存储所有层的输入以计算反向传播中的上游梯度不同,
它存储少数几层的输入,其余层的输入在反向传播过程中重新计算。
减少的内存需求使得可以增加批量大小,从而提高利用率。</p>
<p>应谨慎选择检查点目标。最好不要存储具有小重新计算成本的大型层输出。
示例目标层包括激活函数(例如 <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>、<code class="docutils literal notranslate"><span class="pre">Sigmoid</span></code>、<code class="docutils literal notranslate"><span class="pre">Tanh</span></code>)、
上/下采样以及具有小累积深度的矩阵-向量运算。</p>
<p>PyTorch 支持原生
<a class="reference external" href="https://pytorch.org/docs/stable/checkpoint.html">torch.utils.checkpoint</a>
自动执行检查点和重新计算的API。</p>
</div>
<div class="section" id="api">
<h3>禁用调试API<a class="headerlink" href="#api" title="Permalink to this heading">¶</a></h3>
<p>许多PyTorch API旨在用于调试,在常规训练运行时应该禁用:</p>
<ul class="simple">
<li><p>异常检测:
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.detect_anomaly">torch.autograd.detect_anomaly</a>
或
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.set_detect_anomaly">torch.autograd.set_detect_anomaly(True)</a></p></li>
<li><p>与profiler相关:
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.profiler.emit_nvtx">torch.autograd.profiler.emit_nvtx</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.profiler.profile">torch.autograd.profiler.profile</a></p></li>
<li><p>autograd <cite>gradcheck</cite>:
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.gradcheck">torch.autograd.gradcheck</a>
或
<a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#torch.autograd.gradgradcheck">torch.autograd.gradgradcheck</a></p></li>
</ul>
</div>
</div>
<div class="section" id="cpu">
<h2>CPU特定优化<a class="headerlink" href="#cpu" title="Permalink to this heading">¶</a></h2>
<div class="section" id="numa">
<h3>利用非均匀内存访问(NUMA)控制<a class="headerlink" href="#numa" title="Permalink to this heading">¶</a></h3>
<p>NUMA或非均匀内存访问是一种内存布局设计,用于多内存控制器和内存块的多套接字机器中,旨在利用本地内存的局部性。一般来说,所有深度学习工作负载(训练或推理)都能从不跨NUMA节点访问硬件资源中获得更好的性能。因此,可以使用多个实例运行推理,每个实例在一个套接字上运行,以提高吞吐量。对于单节点上的训练任务,建议使用分布式训练,使每个训练进程在一个套接字上运行。</p>
<p>通常,以下命令仅在第N个节点上的核心上执行PyTorch脚本,并避免跨套接字内存访问,从而减少内存访问开销。</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>numactl<span class="w"> </span>--cpunodebind<span class="o">=</span>N<span class="w"> </span>--membind<span class="o">=</span>N<span class="w"> </span>python<span class="w"> </span>&lt;pytorch_script&gt;
</pre></div>
</div>
<p>更详细的描述可以在 <a class="reference external" href="https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/tuning_guide.html">这里</a> 找到。</p>
</div>
<div class="section" id="openmp">
<h3>利用OpenMP<a class="headerlink" href="#openmp" title="Permalink to this heading">¶</a></h3>
<p>OpenMP用于为并行计算任务带来更好的性能。
<cite>OMP_NUM_THREADS</cite> 是可用于加速计算的最简单开关,它决定了用于OpenMP计算的线程数。
CPU亲和性设置控制如何在多个核心上分配工作负载。它会影响通信开销、缓存行失效开销或页面抖动,因此正确设置CPU亲和性会带来性能优势。<cite>GOMP_CPU_AFFINITY</cite> 或 <cite>KMP_AFFINITY</cite> 决定如何将OpenMP线程绑定到物理处理单元。详细信息可以在 <a class="reference external" href="https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/tuning_guide.html">这里</a> 找到。</p>
<p>使用以下命令,PyTorch将在N个OpenMP线程上运行任务。</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span>N
</pre></div>
</div>
<p>通常,使用以下环境变量来设置GNU OpenMP实现的CPU亲和性。<cite>OMP_PROC_BIND</cite> 指定线程是否可以在处理器之间移动。将其设置为CLOSE可以使OpenMP线程靠近主线程在连续的分区中。<cite>OMP_SCHEDULE</cite> 决定了OpenMP线程的调度方式。<cite>GOMP_CPU_AFFINITY</cite> 将线程绑定到特定的CPU。</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">OMP_SCHEDULE</span><span class="o">=</span>STATIC
<span class="nb">export</span><span class="w"> </span><span class="nv">OMP_PROC_BIND</span><span class="o">=</span>CLOSE
<span class="nb">export</span><span class="w"> </span><span class="nv">GOMP_CPU_AFFINITY</span><span class="o">=</span><span class="s2">&quot;N-M&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="intel-openmp-libiomp">
<h3>Intel OpenMP运行时库 (<cite>libiomp</cite>)<a class="headerlink" href="#intel-openmp-libiomp" title="Permalink to this heading">¶</a></h3>
<p>默认情况下,PyTorch使用GNU OpenMP (GNU <cite>libgomp</cite>)进行并行计算。在Intel平台上,Intel OpenMP运行时库(<cite>libiomp</cite>)提供了OpenMP API规范支持。与`libgomp`相比,它有时会带来更多的性能优势。利用环境变量`LD_PRELOAD`可以将OpenMP库切换到`libiomp`:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span>&lt;path&gt;/libiomp5.so:<span class="nv">$LD_PRELOAD</span>
</pre></div>
</div>
<p>与GNU OpenMP中的CPU亲和性设置类似,`libiomp`中也提供了环境变量来控制CPU亲和性设置。
<cite>KMP_AFFINITY</cite> 将OpenMP线程绑定到物理处理单元。<cite>KMP_BLOCKTIME</cite> 设置线程在完成并行区域执行后等待睡眠之前的时间(以毫秒为单位)。在大多数情况下,将`KMP_BLOCKTIME`设置为1或0可以获得良好的性能。
以下命令显示了使用Intel OpenMP运行时库的常见设置。</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">KMP_AFFINITY</span><span class="o">=</span><span class="nv">granularity</span><span class="o">=</span>fine,compact,1,0
<span class="nb">export</span><span class="w"> </span><span class="nv">KMP_BLOCKTIME</span><span class="o">=</span><span class="m">1</span>
</pre></div>
</div>
</div>
<div class="section" id="id17">
<h3>切换内存分配器<a class="headerlink" href="#id17" title="Permalink to this heading">¶</a></h3>
<p>对于深度学习工作负载,与默认的`malloc`函数相比,`Jemalloc`或`TCMalloc`可以通过尽可能重用内存获得更好的性能。<a class="reference external" href="https://github.com/jemalloc/jemalloc">Jemalloc</a> 是一个通用的`malloc`实现,强调避免碎片和可扩展的并发支持。<a class="reference external" href="https://google.github.io/tcmalloc/overview.html">TCMalloc</a> 也具有一些优化,可以加速程序执行。其中一个优化是在缓存中保存内存,以加快常用对象的访问速度。即使在释放内存后,保持这些缓存也有助于避免昂贵的系统调用,如果稍后重新分配这些内存。
使用环境变量`LD_PRELOAD`来利用其中之一。</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LD_PRELOAD</span><span class="o">=</span>&lt;jemalloc.so/tcmalloc.so&gt;:<span class="nv">$LD_PRELOAD</span>
</pre></div>
</div>
</div>
<div class="section" id="onednn-graphtorchscript">
<h3>使用oneDNN Graph与TorchScript进行推理<a class="headerlink" href="#onednn-graphtorchscript" title="Permalink to this heading">¶</a></h3>
<p>oneDNN Graph可以显著提高推理性能。它将一些计算密集型操作(如卷积、矩阵乘法)与其相邻操作融合。
在PyTorch 2.0中,它作为测试版功能支持`Float32`和`BFloat16`数据类型。
oneDNN Graph接收模型的图形,并根据示例输入的形状识别运算符融合的候选对象。
模型应该使用示例输入进行JIT跟踪。
对于与示例输入具有相同形状的输入,在几次热身迭代后就会观察到加速。
下面的代码片段是针对resnet50的,但它们也可以很好地扩展到使用自定义模型的oneDNN Graph。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 只需要这一行额外的代码即可使用oneDNN Graph</span>
<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">enable_onednn_fusion</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>使用oneDNN Graph API进行Float32推理只需要一行额外的代码。
如果您正在使用oneDNN Graph,请避免调用 <cite>torch.jit.optimize_for_inference</cite> 。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 示例输入应该与预期输入具有相同的形状</span>
<span class="n">sample_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)]</span>
<span class="c1"># 在此示例中使用torchvision中的resnet50进行说明,</span>
<span class="c1"># 但下面的代码确实可以修改为使用自定义模型。</span>
<span class="n">model</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="p">,</span> <span class="s2">&quot;resnet50&quot;</span><span class="p">)()</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># 使用示例输入跟踪模型</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sample_input</span><span class="p">)</span>
<span class="c1"># 调用torch.jit.freeze</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">traced_model</span><span class="p">)</span>
</pre></div>
</div>
<p>一旦使用示例输入对模型进行了JIT跟踪,就可以在几次热身运行后用于推理。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># 几次热身运行</span>
    <span class="n">traced_model</span><span class="p">(</span><span class="o">*</span><span class="n">sample_input</span><span class="p">)</span>
    <span class="n">traced_model</span><span class="p">(</span><span class="o">*</span><span class="n">sample_input</span><span class="p">)</span>
    <span class="c1"># 在热身运行后会观察到加速</span>
    <span class="n">traced_model</span><span class="p">(</span><span class="o">*</span><span class="n">sample_input</span><span class="p">)</span>
</pre></div>
</div>
<p>虽然oneDNN Graph的JIT融合器也支持`BFloat16`数据类型的推理,
但只有具有AVX512_BF16指令集架构(ISA)的机器才能从oneDNN Graph中获得性能优势。
以下代码片段是使用`BFloat16`数据类型进行oneDNN Graph推理的示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># JIT模式下的AMP默认启用,并且与其eager模式对应版本不同</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_set_autocast_mode</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">amp</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">):</span>
    <span class="c1"># 当使用AMP时,应使用`torch.fx.experimental.optimization.fuse`进行基于CNN的视觉模型的Conv-BatchNorm折叠</span>
    <span class="kn">import</span> <span class="nn">torch.fx.experimental.optimization</span> <span class="k">as</span> <span class="nn">optimization</span>
    <span class="c1"># 请注意,当不使用AMP时,无需调用optimization.fuse</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">fuse</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">example_input</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># 几次热身运行</span>
    <span class="n">model</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
    <span class="n">model</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
    <span class="c1"># 在后续运行中会观察到加速。</span>
    <span class="n">model</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="pytorch-distributeddataparallel-ddp-cpu">
<h3>使用PyTorch <cite>DistributedDataParallel</cite> (DDP)功能在CPU上训练模型<a class="headerlink" href="#pytorch-distributeddataparallel-ddp-cpu" title="Permalink to this heading">¶</a></h3>
<p>对于小型模型或内存限制型模型(如DLRM),在CPU上进行训练也是一个不错的选择。在具有多个套接字的机器上,
分布式训练可以带来高效的硬件资源使用,从而加速训练过程。
<a class="reference external" href="https://github.com/intel/torch-ccl">Torch-ccl</a> 使用Intel(R) <cite>oneCCL</cite> (集体通信库)进行了优化,
用于高效的分布式深度学习训练,实现了诸如 <cite>allreduce</cite>、<cite>allgather</cite>、<cite>alltoall</cite> 等集体操作,
实现了PyTorch C10D <cite>ProcessGroup</cite> API,并可以作为外部 <cite>ProcessGroup</cite> 动态加载。
在PyTorch DDP模块中实现的优化之上, <cite>torch-ccl</cite> 加速了通信操作。
除了对通信内核进行优化外, <cite>torch-ccl</cite> 还支持同步计算和通信功能。</p>
</div>
</div>
<div class="section" id="gpu">
<h2>GPU 特定优化<a class="headerlink" href="#gpu" title="Permalink to this heading">¶</a></h2>
<div class="section" id="cudnn">
<h3>启用 cuDNN 自动调优器<a class="headerlink" href="#cudnn" title="Permalink to this heading">¶</a></h3>
<p><a class="reference external" href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a> 支持许多算法来计算卷积。
自动调优器会运行一个简短的基准测试,并为给定的硬件和输入大小选择性能最佳的内核。</p>
<p>对于卷积网络(目前其他类型尚不支持),可以在启动训练循环之前启用 cuDNN 自动调优器,方法是设置:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
<ul class="simple">
<li><p>自动调优器的决策可能是非确定性的;不同的算法可能会在不同的运行中被选择。
有关更多详细信息,请参阅 <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html?highlight=determinism">PyTorch: 可重复性</a></p></li>
<li><p>在某些罕见的情况下,例如输入大小高度可变时,最好在禁用自动调优器的情况下运行卷积网络,
以避免为每个输入大小选择算法所带来的开销。</p></li>
</ul>
</div>
<div class="section" id="cpu-gpu">
<h3>避免不必要的 CPU-GPU 同步<a class="headerlink" href="#cpu-gpu" title="Permalink to this heading">¶</a></h3>
<p>避免不必要的同步,尽可能让 CPU 领先于加速器运行,以确保加速器工作队列中包含许多操作。</p>
<p>如果可能,请避免需要同步的操作,例如:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">print(cuda_tensor)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cuda_tensor.item()</span></code></p></li>
<li><p>内存复制: <code class="docutils literal notranslate"><span class="pre">tensor.cuda()</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda_tensor.cpu()</span></code> 和等效的 <code class="docutils literal notranslate"><span class="pre">tensor.to(device)</span></code> 调用</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cuda_tensor.nonzero()</span></code></p></li>
<li><p>依赖于在 CUDA 张量上执行的操作结果的 python 控制流,例如 <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">(cuda_tensor</span> <span class="pre">!=</span> <span class="pre">0).all()</span></code></p></li>
</ul>
</div>
<div class="section" id="id18">
<h3>直接在目标设备上创建张量<a class="headerlink" href="#id18" title="Permalink to this heading">¶</a></h3>
<p>不要调用 <code class="docutils literal notranslate"><span class="pre">torch.rand(size).cuda()</span></code> 来生成随机张量,而是直接在目标设备上生成输出:
<code class="docutils literal notranslate"><span class="pre">torch.rand(size,</span> <span class="pre">device='cuda')</span></code>。</p>
<p>这适用于所有创建新张量并接受 <code class="docutils literal notranslate"><span class="pre">device</span></code> 参数的函数:
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand">torch.rand()</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros">torch.zeros()</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.full.html#torch.full">torch.full()</a>
和类似函数。</p>
</div>
<div class="section" id="id19">
<h3>使用混合精度和 AMP<a class="headerlink" href="#id19" title="Permalink to this heading">¶</a></h3>
<p>混合精度利用 <a class="reference external" href="https://www.nvidia.com/en-us/data-center/tensor-cores/">Tensor Cores</a>,
在 Volta 及更新的 GPU 架构上可提供高达 3 倍的整体加速。要使用 Tensor Cores,需要启用 AMP,
并且矩阵/张量的维度需要满足调用使用 Tensor Cores 的内核的要求。</p>
<p>要使用 Tensor Cores:</p>
<ul class="simple">
<li><p>将大小设置为 8 的倍数(以映射到 Tensor Cores 的维度)</p>
<ul>
<li><p>请参阅 <a class="reference external" href="https://docs.nvidia.com/deeplearning/performance/index.html#optimizing-performance">深度学习性能文档</a>
以获取更多详细信息和特定于层类型的指南</p></li>
<li><p>如果层大小是由其他参数而不是固定值派生的,它仍然可以显式填充,例如 NLP 模型中的词汇量大小</p></li>
</ul>
</li>
<li><p>启用 AMP</p>
<ul>
<li><p>混合精度训练和 AMP 介绍:
<a class="reference external" href="https://www.youtube.com/watch?v=jF4-_ZK_tyc&amp;feature=youtu.be">视频</a>,
<a class="reference external" href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/dusan_stosic-training-neural-networks-with-tensor-cores.pdf">幻灯片</a></p></li>
<li><p>PyTorch 从 1.6 版本开始提供原生 AMP 支持:
<a class="reference external" href="https://pytorch.org/docs/stable/amp.html">文档</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples">示例</a>,
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html">教程</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id27">
<h3>在输入长度可变的情况下预分配内存<a class="headerlink" href="#id27" title="Permalink to this heading">¶</a></h3>
<p>用于语音识别或 NLP 的模型通常在具有可变序列长度的输入张量上进行训练。
可变长度可能会对 PyTorch 缓存分配器造成问题,并导致性能降低或意外的内存不足错误。
如果一个短序列长度的批次后面紧跟着另一个长序列长度的批次,那么 PyTorch 就被迫释放前一次迭代的中间缓冲区,
并重新分配新的缓冲区。这个过程是耗时的,并会在缓存分配器中造成碎片,从而可能导致内存不足错误。</p>
<p>一个典型的解决方案是实现预分配。它包括以下步骤:</p>
<ol class="arabic simple">
<li><p>生成一个(通常是随机的)具有最大序列长度的输入批次(要么对应于训练数据集中的最大长度,
要么对应于某个预定义的阈值)</p></li>
<li><p>使用生成的批次执行前向和后向传递,不执行优化器或学习率调度器,这一步预分配了最大大小的缓冲区,
可在后续训练迭代中重用</p></li>
<li><p>将梯度归零</p></li>
<li><p>继续常规训练</p></li>
</ol>
</div>
</div>
<div class="section" id="id28">
<h2>分布式优化<a class="headerlink" href="#id28" title="Permalink to this heading">¶</a></h2>
<div class="section" id="id29">
<h3>使用高效的数据并行后端<a class="headerlink" href="#id29" title="Permalink to this heading">¶</a></h3>
<p>PyTorch 有两种方式来实现数据并行训练:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel">torch.nn.DataParallel</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">torch.nn.parallel.DistributedDataParallel</a></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 提供了更好的性能和多 GPU 扩展能力。
有关更多信息,请参阅 PyTorch 文档中 <a class="reference external" href="https://pytorch.org/docs/stable/notes/cuda.html#use-nn-parallel-distributeddataparallel-instead-of-multiprocessing-or-nn-dataparallel">相关 CUDA 最佳实践部分</a>。</p>
</div>
<div class="section" id="distributeddataparallel-all-reduce">
<h3>如果在使用 <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 和梯度累积进行训练时,跳过不必要的 all-reduce<a class="headerlink" href="#distributeddataparallel-all-reduce" title="Permalink to this heading">¶</a></h3>
<p>默认情况下,
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">torch.nn.parallel.DistributedDataParallel</a>
在每次反向传播后执行梯度 all-reduce,以计算参与训练的所有工作进程上的平均梯度。
如果训练使用了 N 步梯度累积,那么在每个训练步骤后都不需要执行 all-reduce,
只需在最后一次调用 backward 之后,在执行优化器之前执行 all-reduce。</p>
<p><code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 提供了
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync">no_sync()</a>
上下文管理器,用于在特定迭代中禁用梯度 all-reduce。
<code class="docutils literal notranslate"><span class="pre">no_sync()</span></code> 应该应用于梯度累积的前 <code class="docutils literal notranslate"><span class="pre">N-1</span></code> 次迭代,最后一次迭代应该遵循默认执行,并执行所需的梯度 all-reduce。</p>
</div>
<div class="section" id="distributeddataparallel-find-unused-parameters-true">
<h3>如果使用 <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel(find_unused_parameters=True)</span></code>,则在构造函数和执行期间匹配层的顺序<a class="headerlink" href="#distributeddataparallel-find-unused-parameters-true" title="Permalink to this heading">¶</a></h3>
<p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">torch.nn.parallel.DistributedDataParallel</a>
使用 <code class="docutils literal notranslate"><span class="pre">find_unused_parameters=True</span></code> 时,会根据模型构造函数中层和参数的顺序来构建 <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 梯度 all-reduce 的桶。
<code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 会与反向传播重叠 all-reduce。只有当给定桶中的所有参数的梯度都可用时,
才会异步触发该桶的 all-reduce。</p>
<p>为了最大化重叠量,模型构造函数中的顺序应该大致与执行期间的顺序相匹配。
如果顺序不匹配,那么整个桶的 all-reduce 将等待最后到达的梯度,这可能会减少反向传播和 all-reduce 之间的重叠,
all-reduce 可能会暴露出来,从而减慢训练速度。</p>
<p><code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 使用 <code class="docutils literal notranslate"><span class="pre">find_unused_parameters=False</span></code> (这是默认设置)
依赖于基于反向传播期间遇到的操作顺序的自动桶形成。
使用 <code class="docutils literal notranslate"><span class="pre">find_unused_parameters=False</span></code> 时,无需重新排列层或参数即可获得最佳性能。</p>
</div>
<div class="section" id="id32">
<h3>在分布式设置中平衡工作负载<a class="headerlink" href="#id32" title="Permalink to this heading">¶</a></h3>
<p>对于处理序列数据的模型(语音识别、翻译、语言模型等),通常可能会发生负载不均衡。
如果一个设备收到的批次数据的序列长度比其他设备长,那么所有设备都要等待完成最后的工作进程。
在使用 <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel</a> 后端的分布式设置中,
反向传播函数作为一个隐式的同步点。</p>
<p>有多种方法可以解决负载平衡问题。核心思想是在每个全局批次中尽可能均匀地将工作负载分布到所有工作进程。
例如,Transformer 通过形成具有大约恒定令牌数(而不是序列数)的批次来解决不平衡问题,
其他模型通过对具有相似序列长度的样本进行分桶或甚至对数据集按序列长度进行排序来解决不平衡问题。</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-recipes-tuning-guide-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8c82db84c10318a94cbe213adb618139/tuning_guide.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tuning_guide.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/38991cbc7763ed7e0f1b711da737b391/tuning_guide.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tuning_guide.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../compiling_optimizer.html" class="btn btn-neutral float-right" title="(beta) Compiling the optimizer with torch.compile" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="amp_recipe.html" class="btn btn-neutral" title="自动混合精度" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr class="rating-hr hr-top">
      <div class="rating-container">
        <div class="rating-prompt">Rate this Tutorial</div>
        <div class="stars-outer">
          <i class="far fa-star" title="1 Star" data-behavior="tutorial-rating" data-count="1"></i>
          <i class="far fa-star" title="2 Stars" data-behavior="tutorial-rating" data-count="2"></i>
          <i class="far fa-star" title="3 Stars" data-behavior="tutorial-rating" data-count="3"></i>
          <i class="far fa-star" title="4 Stars" data-behavior="tutorial-rating" data-count="4"></i>
          <i class="far fa-star" title="5 Stars" data-behavior="tutorial-rating" data-count="5"></i>
        </div>
      </div>
    <hr class="rating-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024, PyTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">性能调优指南</a><ul>
<li><a class="reference internal" href="#id2">一般优化</a><ul>
<li><a class="reference internal" href="#id3">启用异步数据加载和数据增强</a></li>
<li><a class="reference internal" href="#id4">对于验证或推理,禁用梯度计算</a></li>
<li><a class="reference internal" href="#id6">对于直接后跟批量归一化的卷积,禁用偏置</a></li>
<li><a class="reference internal" href="#parameter-grad-none-model-zero-grad-optimizer-zero-grad">使用 parameter.grad = None 而不是 model.zero_grad() 或 optimizer.zero_grad()</a></li>
<li><a class="reference internal" href="#id12">融合点运算</a></li>
<li><a class="reference internal" href="#channels-last">为计算机视觉模型启用 channels_last 内存格式</a></li>
<li><a class="reference internal" href="#id14">检查点中间缓冲区</a></li>
<li><a class="reference internal" href="#api">禁用调试API</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cpu">CPU特定优化</a><ul>
<li><a class="reference internal" href="#numa">利用非均匀内存访问(NUMA)控制</a></li>
<li><a class="reference internal" href="#openmp">利用OpenMP</a></li>
<li><a class="reference internal" href="#intel-openmp-libiomp">Intel OpenMP运行时库 (<cite>libiomp</cite>)</a></li>
<li><a class="reference internal" href="#id17">切换内存分配器</a></li>
<li><a class="reference internal" href="#onednn-graphtorchscript">使用oneDNN Graph与TorchScript进行推理</a></li>
<li><a class="reference internal" href="#pytorch-distributeddataparallel-ddp-cpu">使用PyTorch <cite>DistributedDataParallel</cite> (DDP)功能在CPU上训练模型</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gpu">GPU 特定优化</a><ul>
<li><a class="reference internal" href="#cudnn">启用 cuDNN 自动调优器</a></li>
<li><a class="reference internal" href="#cpu-gpu">避免不必要的 CPU-GPU 同步</a></li>
<li><a class="reference internal" href="#id18">直接在目标设备上创建张量</a></li>
<li><a class="reference internal" href="#id19">使用混合精度和 AMP</a></li>
<li><a class="reference internal" href="#id27">在输入长度可变的情况下预分配内存</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id28">分布式优化</a><ul>
<li><a class="reference internal" href="#id29">使用高效的数据并行后端</a></li>
<li><a class="reference internal" href="#distributeddataparallel-all-reduce">如果在使用 <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> 和梯度累积进行训练时,跳过不必要的 all-reduce</a></li>
<li><a class="reference internal" href="#distributeddataparallel-find-unused-parameters-true">如果使用 <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel(find_unused_parameters=True)</span></code>,则在构造函数和执行期间匹配层的顺序</a></li>
<li><a class="reference internal" href="#id32">在分布式设置中平衡工作负载</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
         <script src="../../_static/katex.min.js"></script>
         <script src="../../_static/auto-render.min.js"></script>
         <script src="../../_static/katex_autorenderer.js"></script>
         <script src="../../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });
    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count"),
      'customEvent:Rating': $(this).attr("data-count") // send to GA custom dimension customEvent:Rating.
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Profiling PyTorch', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Edge with ExecuTorch', 'Recommendation Systems', 'Multimodality'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>